{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models, datasets, transforms\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "import codecarbon\n",
        "from thop import profile\n",
        "\n",
        "# Check if GPU is available and set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define data augmentations for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Split training data into training and validation sets (80% train, 20% validation)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Define Custom ResNet-50 Model\n",
        "class CustomResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=10, dropout_rate=0.5):\n",
        "        super(CustomResNet50, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(2048, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "# Initialize model\n",
        "teacher_model = CustomResNet50().to(device)\n",
        "\n",
        "# Define loss function, optimizer, and learning rate scheduler\n",
        "criterion_ce = nn.CrossEntropyLoss()\n",
        "optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer_teacher, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "# Use CodeCarbon for energy consumption tracking\n",
        "tracker = codecarbon.EmissionsTracker()\n",
        "tracker.start()\n",
        "\n",
        "# Function to get GPU power consumption using nvidia-smi\n",
        "def get_gpu_power():\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,nounits,noheader'],\n",
        "            stdout=subprocess.PIPE, text=True\n",
        "        )\n",
        "        power_draws = [float(p) for p in result.stdout.strip().split('\\n')]\n",
        "        return sum(power_draws) / len(power_draws) if power_draws else 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting GPU power: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "gpu_power_readings = []\n",
        "\n",
        "# Training loop\n",
        "num_epochs_teacher = 80\n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies, val_accuracies = [], []\n",
        "best_val_accuracy = 0.0\n",
        "best_val_loss = float('inf')\n",
        "start_training_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs_teacher):\n",
        "    teacher_model.train()\n",
        "    running_loss, correct_train, total_train = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, desc=f'Epoch [{epoch+1}/{num_epochs_teacher}] - Training'):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer_teacher.zero_grad()\n",
        "        outputs = teacher_model(inputs)\n",
        "        loss = criterion_ce(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_teacher.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "        total_train += labels.size(0)\n",
        "        gpu_power_readings.append(get_gpu_power())\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    teacher_model.eval()\n",
        "    running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = teacher_model(inputs)\n",
        "            loss = criterion_ce(outputs, labels)\n",
        "            running_val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            total_val += labels.size(0)\n",
        "\n",
        "    val_loss = running_val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs_teacher}], Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        torch.save(teacher_model.state_dict(), 'best_teacher_model.pth')\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "training_time = time.time() - start_training_time\n",
        "\n",
        "# Stop the CodeCarbon tracker\n",
        "emissions = tracker.stop()\n",
        "\n",
        "# Model analysis metrics\n",
        "param_count = sum(p.numel() for p in teacher_model.parameters() if p.requires_grad)\n",
        "model_size = os.path.getsize('best_teacher_model.pth') / (1024 * 1024)\n",
        "\n",
        "# FLOPs calculation\n",
        "example_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "flops, params = profile(teacher_model, inputs=(example_input,), verbose=False)\n",
        "\n",
        "# Inference time calculation\n",
        "teacher_model.eval()\n",
        "inference_start = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):  # Measure inference time over 100 iterations\n",
        "        _ = teacher_model(example_input)\n",
        "inference_time = (time.time() - inference_start) / 100  # Average inference time per run\n",
        "\n",
        "# Report energy and performance metrics\n",
        "avg_gpu_power = sum(gpu_power_readings) / len(gpu_power_readings) if gpu_power_readings else 0.0\n",
        "energy_consumption_gpu = (avg_gpu_power * num_epochs_teacher * len(train_loader) / 1000)\n",
        "\n",
        "# Final results\n",
        "print(\"\\n--- Model Analysis ---\")\n",
        "print(f\"Parameter Count: {param_count}\")\n",
        "print(f\"Model Size: {model_size:.2f} MB\")\n",
        "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Average Inference Time: {inference_time:.6f} seconds\")\n",
        "\n",
        "print(\"\\n--- Energy and Emissions Report ---\")\n",
        "print(f\"CO2 Emissions: {emissions:.6f} kg\")\n",
        "print(f\"Average GPU Power Consumption: {avg_gpu_power:.2f} W\")\n",
        "print(f\"Total GPU Energy Consumption: {energy_consumption_gpu:.6f} kWh\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyO8H9ybsO-i",
        "outputId": "4b3ec492-9bd5-47ba-f4c1-50bc080b7d16"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:23:11] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 01:23:11] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 01:23:11] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 01:23:11] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 01:23:11] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 01:23:12] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 01:23:12] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 01:23:12] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 01:23:12]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 01:23:12]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 01:23:12]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 01:23:12]   Available RAM : 12.675 GB\n",
            "[codecarbon INFO @ 01:23:12]   CPU count: 2\n",
            "[codecarbon INFO @ 01:23:12]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 01:23:12]   GPU count: 1\n",
            "[codecarbon INFO @ 01:23:12]   GPU model: 1 x Tesla T4\n",
            "[codecarbon INFO @ 01:23:12] Saving emissions data to file /content/emissions.csv\n",
            "Epoch [1/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch [1/80] - Training:  28%|██▊       | 89/313 [00:14<00:41,  5.46it/s][codecarbon INFO @ 01:23:27] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:23:27] Energy consumed for all GPUs : 0.000212 kWh. Total GPU Power : 50.83780396290514 W\n",
            "[codecarbon INFO @ 01:23:27] Energy consumed for all CPUs : 0.000178 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:23:27] 0.000409 kWh of electricity used since the beginning.\n",
            "Epoch [1/80] - Training:  56%|█████▌    | 175/313 [00:29<00:28,  4.80it/s][codecarbon INFO @ 01:23:42] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:23:42] Energy consumed for all GPUs : 0.000422 kWh. Total GPU Power : 50.51464354064898 W\n",
            "[codecarbon INFO @ 01:23:42] Energy consumed for all CPUs : 0.000354 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:23:42] 0.000816 kWh of electricity used since the beginning.\n",
            "Epoch [1/80] - Training:  86%|████████▌ | 268/313 [00:44<00:09,  4.78it/s][codecarbon INFO @ 01:23:57] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:23:57] Energy consumed for all GPUs : 0.000645 kWh. Total GPU Power : 53.370221805598156 W\n",
            "[codecarbon INFO @ 01:23:57] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:23:57] 0.001236 kWh of electricity used since the beginning.\n",
            "Epoch [1/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.02it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:24:12] Energy consumed for RAM : 0.000079 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:24:12] Energy consumed for all GPUs : 0.000826 kWh. Total GPU Power : 43.57087267909356 W\n",
            "[codecarbon INFO @ 01:24:12] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:24:12] 0.001614 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/80], Train Loss: 1.2898, Train Acc: 55.48%, Val Loss: 1.1446, Val Acc: 60.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/80] - Training:  23%|██▎       | 73/313 [00:12<00:55,  4.29it/s][codecarbon INFO @ 01:24:27] Energy consumed for RAM : 0.000099 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:24:27] Energy consumed for all GPUs : 0.001037 kWh. Total GPU Power : 50.69144286276493 W\n",
            "[codecarbon INFO @ 01:24:27] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:24:27] 0.002022 kWh of electricity used since the beginning.\n",
            "Epoch [2/80] - Training:  53%|█████▎    | 166/313 [00:27<00:33,  4.44it/s][codecarbon INFO @ 01:24:42] Energy consumed for RAM : 0.000119 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:24:42] Energy consumed for all GPUs : 0.001268 kWh. Total GPU Power : 55.286366791853794 W\n",
            "[codecarbon INFO @ 01:24:42] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:24:42] 0.002449 kWh of electricity used since the beginning.\n",
            "Epoch [2/80] - Training:  81%|████████▏ | 255/313 [00:42<00:13,  4.32it/s][codecarbon INFO @ 01:24:57] Energy consumed for RAM : 0.000139 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:24:57] Energy consumed for all GPUs : 0.001492 kWh. Total GPU Power : 53.919694949760746 W\n",
            "[codecarbon INFO @ 01:24:57] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:24:57] 0.002871 kWh of electricity used since the beginning.\n",
            "Epoch [2/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.12it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:25:12] Energy consumed for RAM : 0.000158 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:25:12] Energy consumed for all GPUs : 0.001695 kWh. Total GPU Power : 48.80286975712229 W\n",
            "[codecarbon INFO @ 01:25:12] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:25:12] 0.003271 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:25:12] 0.003779 g.CO2eq/s mean an estimation of 119.16112292953845 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/80], Train Loss: 1.1287, Train Acc: 61.80%, Val Loss: 1.3379, Val Acc: 62.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/80] - Training:  18%|█▊        | 56/313 [00:10<01:01,  4.15it/s][codecarbon INFO @ 01:25:27] Energy consumed for RAM : 0.000178 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:25:27] Energy consumed for all GPUs : 0.001897 kWh. Total GPU Power : 48.32903499783744 W\n",
            "[codecarbon INFO @ 01:25:27] Energy consumed for all CPUs : 0.001595 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:25:27] 0.003670 kWh of electricity used since the beginning.\n",
            "Epoch [3/80] - Training:  47%|████▋     | 146/313 [00:25<00:38,  4.34it/s][codecarbon INFO @ 01:25:42] Energy consumed for RAM : 0.000198 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:25:42] Energy consumed for all GPUs : 0.002128 kWh. Total GPU Power : 55.70756473136611 W\n",
            "[codecarbon INFO @ 01:25:42] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:25:42] 0.004097 kWh of electricity used since the beginning.\n",
            "Epoch [3/80] - Training:  76%|███████▌  | 237/313 [00:40<00:17,  4.35it/s][codecarbon INFO @ 01:25:57] Energy consumed for RAM : 0.000218 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:25:57] Energy consumed for all GPUs : 0.002355 kWh. Total GPU Power : 54.650786361896664 W\n",
            "[codecarbon INFO @ 01:25:57] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:25:57] 0.004522 kWh of electricity used since the beginning.\n",
            "Epoch [3/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.07it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:26:12] Energy consumed for RAM : 0.000237 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:26:12] Energy consumed for all GPUs : 0.002576 kWh. Total GPU Power : 53.01334742048145 W\n",
            "[codecarbon INFO @ 01:26:12] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:26:12] 0.004939 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/80], Train Loss: 1.0075, Train Acc: 65.91%, Val Loss: 0.8632, Val Acc: 70.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/80] - Training:  12%|█▏        | 39/313 [00:08<00:54,  5.04it/s][codecarbon INFO @ 01:26:27] Energy consumed for RAM : 0.000257 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:26:27] Energy consumed for all GPUs : 0.002754 kWh. Total GPU Power : 42.79935460845958 W\n",
            "[codecarbon INFO @ 01:26:27] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:26:27] 0.005314 kWh of electricity used since the beginning.\n",
            "Epoch [4/80] - Training:  41%|████      | 129/313 [00:23<00:30,  6.13it/s][codecarbon INFO @ 01:26:42] Energy consumed for RAM : 0.000277 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:26:42] Energy consumed for all GPUs : 0.002985 kWh. Total GPU Power : 55.264604688211065 W\n",
            "[codecarbon INFO @ 01:26:42] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:26:42] 0.005742 kWh of electricity used since the beginning.\n",
            "Epoch [4/80] - Training:  70%|██████▉   | 219/313 [00:38<00:15,  6.06it/s][codecarbon INFO @ 01:26:57] Energy consumed for RAM : 0.000297 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:26:57] Energy consumed for all GPUs : 0.003220 kWh. Total GPU Power : 56.33583515127362 W\n",
            "[codecarbon INFO @ 01:26:57] Energy consumed for all CPUs : 0.002658 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:26:57] 0.006174 kWh of electricity used since the beginning.\n",
            "Epoch [4/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.87it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:27:12] Energy consumed for RAM : 0.000317 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:27:12] Energy consumed for all GPUs : 0.003452 kWh. Total GPU Power : 55.72119792302213 W\n",
            "[codecarbon INFO @ 01:27:12] Energy consumed for all CPUs : 0.002835 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:27:12] 0.006604 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:27:12] 0.003848 g.CO2eq/s mean an estimation of 121.34816948070844 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/80], Train Loss: 0.9478, Train Acc: 68.34%, Val Loss: 0.8524, Val Acc: 70.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/80] - Training:   7%|▋         | 23/313 [00:06<00:45,  6.44it/s][codecarbon INFO @ 01:27:27] Energy consumed for RAM : 0.000336 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:27:27] Energy consumed for all GPUs : 0.003621 kWh. Total GPU Power : 40.55636116648439 W\n",
            "[codecarbon INFO @ 01:27:27] Energy consumed for all CPUs : 0.003012 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:27:27] 0.006969 kWh of electricity used since the beginning.\n",
            "Epoch [5/80] - Training:  36%|███▌      | 113/313 [00:20<00:32,  6.21it/s][codecarbon INFO @ 01:27:42] Energy consumed for RAM : 0.000356 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:27:42] Energy consumed for all GPUs : 0.003848 kWh. Total GPU Power : 54.67914663885241 W\n",
            "[codecarbon INFO @ 01:27:42] Energy consumed for all CPUs : 0.003189 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:27:42] 0.007393 kWh of electricity used since the beginning.\n",
            "Epoch [5/80] - Training:  65%|██████▌   | 204/313 [00:35<00:16,  6.61it/s][codecarbon INFO @ 01:27:57] Energy consumed for RAM : 0.000376 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:27:57] Energy consumed for all GPUs : 0.004079 kWh. Total GPU Power : 55.27337600914141 W\n",
            "[codecarbon INFO @ 01:27:57] Energy consumed for all CPUs : 0.003366 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:27:57] 0.007821 kWh of electricity used since the beginning.\n",
            "Epoch [5/80] - Training:  94%|█████████▍| 295/313 [00:50<00:02,  6.64it/s][codecarbon INFO @ 01:28:12] Energy consumed for RAM : 0.000396 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:28:12] Energy consumed for all GPUs : 0.004306 kWh. Total GPU Power : 54.46503814095773 W\n",
            "[codecarbon INFO @ 01:28:12] Energy consumed for all CPUs : 0.003543 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:28:12] 0.008244 kWh of electricity used since the beginning.\n",
            "Epoch [5/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.88it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/80], Train Loss: 0.8144, Train Acc: 72.13%, Val Loss: 0.7685, Val Acc: 73.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/80] - Training:   3%|▎         | 10/313 [00:02<00:48,  6.22it/s][codecarbon INFO @ 01:28:27] Energy consumed for RAM : 0.000416 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:28:27] Energy consumed for all GPUs : 0.004483 kWh. Total GPU Power : 42.5227116175515 W\n",
            "[codecarbon INFO @ 01:28:27] Energy consumed for all CPUs : 0.003720 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:28:27] 0.008619 kWh of electricity used since the beginning.\n",
            "Epoch [6/80] - Training:  32%|███▏      | 100/313 [00:17<00:31,  6.86it/s][codecarbon INFO @ 01:28:42] Energy consumed for RAM : 0.000435 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:28:42] Energy consumed for all GPUs : 0.004712 kWh. Total GPU Power : 54.92529352633517 W\n",
            "[codecarbon INFO @ 01:28:42] Energy consumed for all CPUs : 0.003897 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:28:43] 0.009044 kWh of electricity used since the beginning.\n",
            "Epoch [6/80] - Training:  61%|██████    | 190/313 [00:32<00:18,  6.82it/s][codecarbon INFO @ 01:28:57] Energy consumed for RAM : 0.000455 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:28:57] Energy consumed for all GPUs : 0.004943 kWh. Total GPU Power : 55.51032806971453 W\n",
            "[codecarbon INFO @ 01:28:57] Energy consumed for all CPUs : 0.004074 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:28:57] 0.009472 kWh of electricity used since the beginning.\n",
            "Epoch [6/80] - Training:  90%|█████████ | 282/313 [00:47<00:04,  7.37it/s][codecarbon INFO @ 01:29:13] Energy consumed for RAM : 0.000475 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:29:13] Energy consumed for all GPUs : 0.005175 kWh. Total GPU Power : 55.68499442422636 W\n",
            "[codecarbon INFO @ 01:29:13] Energy consumed for all CPUs : 0.004252 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:29:13] 0.009901 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:29:13] 0.003811 g.CO2eq/s mean an estimation of 120.19637060720332 kg.CO2eq/year\n",
            "Epoch [6/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.09it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/80], Train Loss: 0.7945, Train Acc: 72.92%, Val Loss: 0.7850, Val Acc: 73.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [7/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s][codecarbon INFO @ 01:29:28] Energy consumed for RAM : 0.000495 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:29:28] Energy consumed for all GPUs : 0.005359 kWh. Total GPU Power : 44.167001431865565 W\n",
            "[codecarbon INFO @ 01:29:28] Energy consumed for all CPUs : 0.004429 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:29:28] 0.010283 kWh of electricity used since the beginning.\n",
            "Epoch [7/80] - Training:  27%|██▋       | 86/313 [00:15<00:33,  6.68it/s][codecarbon INFO @ 01:29:43] Energy consumed for RAM : 0.000515 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:29:43] Energy consumed for all GPUs : 0.005579 kWh. Total GPU Power : 52.76317614385036 W\n",
            "[codecarbon INFO @ 01:29:43] Energy consumed for all CPUs : 0.004606 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:29:43] 0.010700 kWh of electricity used since the beginning.\n",
            "Epoch [7/80] - Training:  56%|█████▌    | 174/313 [00:30<00:20,  6.79it/s][codecarbon INFO @ 01:29:58] Energy consumed for RAM : 0.000534 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:29:58] Energy consumed for all GPUs : 0.005807 kWh. Total GPU Power : 54.73903324077716 W\n",
            "[codecarbon INFO @ 01:29:58] Energy consumed for all CPUs : 0.004784 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:29:58] 0.011125 kWh of electricity used since the beginning.\n",
            "Epoch [7/80] - Training:  84%|████████▍ | 263/313 [00:45<00:07,  6.81it/s][codecarbon INFO @ 01:30:13] Energy consumed for RAM : 0.000554 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:30:13] Energy consumed for all GPUs : 0.006033 kWh. Total GPU Power : 54.30952355541413 W\n",
            "[codecarbon INFO @ 01:30:13] Energy consumed for all CPUs : 0.004960 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:30:13] 0.011548 kWh of electricity used since the beginning.\n",
            "Epoch [7/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.99it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:30:28] Energy consumed for RAM : 0.000574 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:30:28] Energy consumed for all GPUs : 0.006234 kWh. Total GPU Power : 48.18898603081047 W\n",
            "[codecarbon INFO @ 01:30:28] Energy consumed for all CPUs : 0.005138 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:30:28] 0.011946 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/80], Train Loss: 0.7627, Train Acc: 73.94%, Val Loss: 0.8039, Val Acc: 73.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/80] - Training:  20%|██        | 63/313 [00:12<00:34,  7.29it/s][codecarbon INFO @ 01:30:43] Energy consumed for RAM : 0.000594 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:30:43] Energy consumed for all GPUs : 0.006431 kWh. Total GPU Power : 47.32976420312806 W\n",
            "[codecarbon INFO @ 01:30:43] Energy consumed for all CPUs : 0.005315 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:30:43] 0.012340 kWh of electricity used since the beginning.\n",
            "Epoch [8/80] - Training:  49%|████▉     | 154/313 [00:27<00:22,  6.92it/s][codecarbon INFO @ 01:30:58] Energy consumed for RAM : 0.000614 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:30:58] Energy consumed for all GPUs : 0.006661 kWh. Total GPU Power : 55.11352974818235 W\n",
            "[codecarbon INFO @ 01:30:58] Energy consumed for all CPUs : 0.005492 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:30:58] 0.012766 kWh of electricity used since the beginning.\n",
            "Epoch [8/80] - Training:  78%|███████▊  | 244/313 [00:42<00:10,  6.88it/s][codecarbon INFO @ 01:31:13] Energy consumed for RAM : 0.000633 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:31:13] Energy consumed for all GPUs : 0.006890 kWh. Total GPU Power : 55.12699362265698 W\n",
            "[codecarbon INFO @ 01:31:13] Energy consumed for all CPUs : 0.005669 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:31:13] 0.013193 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:31:13] 0.003802 g.CO2eq/s mean an estimation of 119.90352331988281 kg.CO2eq/year\n",
            "Epoch [8/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.86it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:31:28] Energy consumed for RAM : 0.000653 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:31:28] Energy consumed for all GPUs : 0.007109 kWh. Total GPU Power : 52.269181298823554 W\n",
            "[codecarbon INFO @ 01:31:28] Energy consumed for all CPUs : 0.005847 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:31:28] 0.013609 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/80], Train Loss: 0.7561, Train Acc: 74.51%, Val Loss: 0.7345, Val Acc: 74.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/80] - Training:  14%|█▍        | 45/313 [00:09<00:39,  6.78it/s][codecarbon INFO @ 01:31:43] Energy consumed for RAM : 0.000673 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [9/80] - Training:  15%|█▍        | 46/313 [00:09<00:40,  6.51it/s][codecarbon INFO @ 01:31:43] Energy consumed for all GPUs : 0.007285 kWh. Total GPU Power : 42.31149273212766 W\n",
            "[codecarbon INFO @ 01:31:43] Energy consumed for all CPUs : 0.006024 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:31:43] 0.013982 kWh of electricity used since the beginning.\n",
            "Epoch [9/80] - Training:  43%|████▎     | 135/313 [00:24<00:26,  6.82it/s][codecarbon INFO @ 01:31:58] Energy consumed for RAM : 0.000693 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:31:58] Energy consumed for all GPUs : 0.007508 kWh. Total GPU Power : 53.639664254394425 W\n",
            "[codecarbon INFO @ 01:31:58] Energy consumed for all CPUs : 0.006201 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:31:58] 0.014401 kWh of electricity used since the beginning.\n",
            "Epoch [9/80] - Training:  72%|███████▏  | 225/313 [00:39<00:12,  7.01it/s][codecarbon INFO @ 01:32:13] Energy consumed for RAM : 0.000712 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:32:13] Energy consumed for all GPUs : 0.007739 kWh. Total GPU Power : 55.60037762939052 W\n",
            "[codecarbon INFO @ 01:32:13] Energy consumed for all CPUs : 0.006378 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:32:13] 0.014829 kWh of electricity used since the beginning.\n",
            "Epoch [9/80] - Training: 100%|██████████| 313/313 [00:54<00:00,  5.79it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:32:28] Energy consumed for RAM : 0.000732 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:32:28] Energy consumed for all GPUs : 0.007968 kWh. Total GPU Power : 54.956130105854946 W\n",
            "[codecarbon INFO @ 01:32:28] Energy consumed for all CPUs : 0.006555 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:32:28] 0.015256 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/80], Train Loss: 0.6979, Train Acc: 76.19%, Val Loss: 0.7145, Val Acc: 75.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/80] - Training:   8%|▊         | 25/313 [00:04<00:44,  6.52it/s][codecarbon INFO @ 01:32:43] Energy consumed for RAM : 0.000752 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:32:43] Energy consumed for all GPUs : 0.008141 kWh. Total GPU Power : 41.452450256209886 W\n",
            "[codecarbon INFO @ 01:32:43] Energy consumed for all CPUs : 0.006732 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:32:43] 0.015626 kWh of electricity used since the beginning.\n",
            "Epoch [10/80] - Training:  37%|███▋      | 115/313 [00:19<00:27,  7.10it/s][codecarbon INFO @ 01:32:58] Energy consumed for RAM : 0.000772 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:32:58] Energy consumed for all GPUs : 0.008366 kWh. Total GPU Power : 53.84487775041982 W\n",
            "[codecarbon INFO @ 01:32:58] Energy consumed for all CPUs : 0.006910 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:32:58] 0.016048 kWh of electricity used since the beginning.\n",
            "Epoch [10/80] - Training:  65%|██████▍   | 203/313 [00:34<00:16,  6.67it/s][codecarbon INFO @ 01:33:13] Energy consumed for RAM : 0.000792 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:33:13] Energy consumed for all GPUs : 0.008592 kWh. Total GPU Power : 54.21724654463739 W\n",
            "[codecarbon INFO @ 01:33:13] Energy consumed for all CPUs : 0.007088 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:33:13] 0.016472 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:33:13] 0.003784 g.CO2eq/s mean an estimation of 119.34632647459586 kg.CO2eq/year\n",
            "Epoch [10/80] - Training:  94%|█████████▎| 293/313 [00:49<00:03,  6.51it/s][codecarbon INFO @ 01:33:28] Energy consumed for RAM : 0.000811 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:33:28] Energy consumed for all GPUs : 0.008821 kWh. Total GPU Power : 55.02558011832542 W\n",
            "[codecarbon INFO @ 01:33:28] Energy consumed for all CPUs : 0.007264 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:33:28] 0.016897 kWh of electricity used since the beginning.\n",
            "Epoch [10/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.99it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/80], Train Loss: 0.7009, Train Acc: 76.14%, Val Loss: 0.7642, Val Acc: 74.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11/80] - Training:   2%|▏         | 7/313 [00:01<01:02,  4.87it/s][codecarbon INFO @ 01:33:43] Energy consumed for RAM : 0.000831 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:33:43] Energy consumed for all GPUs : 0.008995 kWh. Total GPU Power : 41.84458019878304 W\n",
            "[codecarbon INFO @ 01:33:43] Energy consumed for all CPUs : 0.007442 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:33:43] 0.017268 kWh of electricity used since the beginning.\n",
            "Epoch [11/80] - Training:  32%|███▏      | 99/313 [00:16<00:30,  7.07it/s][codecarbon INFO @ 01:33:58] Energy consumed for RAM : 0.000851 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:33:58] Energy consumed for all GPUs : 0.009219 kWh. Total GPU Power : 53.6390859394046 W\n",
            "[codecarbon INFO @ 01:33:58] Energy consumed for all CPUs : 0.007618 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:33:58] 0.017688 kWh of electricity used since the beginning.\n",
            "Epoch [11/80] - Training:  61%|██████    | 191/313 [00:31<00:17,  6.94it/s][codecarbon INFO @ 01:34:13] Energy consumed for RAM : 0.000871 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:34:13] Energy consumed for all GPUs : 0.009448 kWh. Total GPU Power : 55.07277021708046 W\n",
            "[codecarbon INFO @ 01:34:13] Energy consumed for all CPUs : 0.007796 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:34:13] 0.018115 kWh of electricity used since the beginning.\n",
            "Epoch [11/80] - Training:  91%|█████████▏| 286/313 [00:46<00:03,  7.12it/s][codecarbon INFO @ 01:34:28] Energy consumed for RAM : 0.000891 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:34:28] Energy consumed for all GPUs : 0.009679 kWh. Total GPU Power : 55.418172780364515 W\n",
            "[codecarbon INFO @ 01:34:28] Energy consumed for all CPUs : 0.007973 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:34:28] 0.018542 kWh of electricity used since the beginning.\n",
            "Epoch [11/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.23it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/80], Train Loss: 0.6862, Train Acc: 76.83%, Val Loss: 0.8005, Val Acc: 72.89%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [12/80] - Training:   1%|          | 2/313 [00:00<02:15,  2.30it/s][codecarbon INFO @ 01:34:43] Energy consumed for RAM : 0.000910 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:34:43] Energy consumed for all GPUs : 0.009859 kWh. Total GPU Power : 43.13084502337169 W\n",
            "[codecarbon INFO @ 01:34:43] Energy consumed for all CPUs : 0.008150 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:34:43] 0.018919 kWh of electricity used since the beginning.\n",
            "Epoch [12/80] - Training:  29%|██▉       | 90/313 [00:15<00:33,  6.71it/s][codecarbon INFO @ 01:34:58] Energy consumed for RAM : 0.000930 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:34:58] Energy consumed for all GPUs : 0.010081 kWh. Total GPU Power : 53.437697290590854 W\n",
            "[codecarbon INFO @ 01:34:58] Energy consumed for all CPUs : 0.008327 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:34:58] 0.019339 kWh of electricity used since the beginning.\n",
            "Epoch [12/80] - Training:  57%|█████▋    | 179/313 [00:31<00:18,  7.10it/s][codecarbon INFO @ 01:35:13] Energy consumed for RAM : 0.000950 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:35:13] Energy consumed for all GPUs : 0.010307 kWh. Total GPU Power : 54.10460716956987 W\n",
            "[codecarbon INFO @ 01:35:13] Energy consumed for all CPUs : 0.008504 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:35:13] 0.019762 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:35:13] 0.003802 g.CO2eq/s mean an estimation of 119.88802412894401 kg.CO2eq/year\n",
            "Epoch [12/80] - Training:  86%|████████▌ | 269/313 [00:46<00:06,  6.98it/s][codecarbon INFO @ 01:35:28] Energy consumed for RAM : 0.000970 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:35:28] Energy consumed for all GPUs : 0.010537 kWh. Total GPU Power : 55.09120182167232 W\n",
            "[codecarbon INFO @ 01:35:28] Energy consumed for all CPUs : 0.008682 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:35:28] 0.020188 kWh of electricity used since the beginning.\n",
            "Epoch [12/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.81it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:35:43] Energy consumed for RAM : 0.000990 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:35:43] Energy consumed for all GPUs : 0.010726 kWh. Total GPU Power : 45.43604370790056 W\n",
            "[codecarbon INFO @ 01:35:43] Energy consumed for all CPUs : 0.008859 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:35:43] 0.020575 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/80], Train Loss: 0.6810, Train Acc: 76.98%, Val Loss: 0.6875, Val Acc: 76.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [13/80] - Training:  22%|██▏       | 70/313 [00:13<00:36,  6.68it/s][codecarbon INFO @ 01:35:58] Energy consumed for RAM : 0.001009 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:35:58] Energy consumed for all GPUs : 0.010925 kWh. Total GPU Power : 47.69368300951959 W\n",
            "[codecarbon INFO @ 01:35:58] Energy consumed for all CPUs : 0.009036 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:35:58] 0.020970 kWh of electricity used since the beginning.\n",
            "Epoch [13/80] - Training:  51%|█████     | 159/313 [00:27<00:21,  7.02it/s][codecarbon INFO @ 01:36:13] Energy consumed for RAM : 0.001029 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:36:13] Energy consumed for all GPUs : 0.011152 kWh. Total GPU Power : 54.62316404391203 W\n",
            "[codecarbon INFO @ 01:36:13] Energy consumed for all CPUs : 0.009213 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:36:13] 0.021395 kWh of electricity used since the beginning.\n",
            "Epoch [13/80] - Training:  80%|███████▉  | 249/313 [00:42<00:09,  6.77it/s][codecarbon INFO @ 01:36:28] Energy consumed for RAM : 0.001049 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:36:28] Energy consumed for all GPUs : 0.011384 kWh. Total GPU Power : 55.488518107010776 W\n",
            "[codecarbon INFO @ 01:36:28] Energy consumed for all CPUs : 0.009391 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:36:28] 0.021823 kWh of electricity used since the beginning.\n",
            "Epoch [13/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.84it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:36:43] Energy consumed for RAM : 0.001069 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:36:43] Energy consumed for all GPUs : 0.011592 kWh. Total GPU Power : 50.09296091336536 W\n",
            "[codecarbon INFO @ 01:36:43] Energy consumed for all CPUs : 0.009568 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:36:43] 0.022229 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/80], Train Loss: 0.6580, Train Acc: 77.85%, Val Loss: 0.6597, Val Acc: 77.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [14/80] - Training:  16%|█▋        | 51/313 [00:08<00:38,  6.75it/s][codecarbon INFO @ 01:36:58] Energy consumed for RAM : 0.001089 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:36:58] Energy consumed for all GPUs : 0.011786 kWh. Total GPU Power : 46.366586704737216 W\n",
            "[codecarbon INFO @ 01:36:58] Energy consumed for all CPUs : 0.009745 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:36:58] 0.022619 kWh of electricity used since the beginning.\n",
            "Epoch [14/80] - Training:  46%|████▋     | 145/313 [00:23<00:22,  7.35it/s][codecarbon INFO @ 01:37:13] Energy consumed for RAM : 0.001108 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:37:13] Energy consumed for all GPUs : 0.012017 kWh. Total GPU Power : 55.50087070395553 W\n",
            "[codecarbon INFO @ 01:37:13] Energy consumed for all CPUs : 0.009922 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:37:13] 0.023047 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:37:13] 0.003795 g.CO2eq/s mean an estimation of 119.68450295091723 kg.CO2eq/year\n",
            "Epoch [14/80] - Training:  77%|███████▋  | 241/313 [00:38<00:09,  7.69it/s][codecarbon INFO @ 01:37:28] Energy consumed for RAM : 0.001128 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:37:28] Energy consumed for all GPUs : 0.012256 kWh. Total GPU Power : 57.51454332673444 W\n",
            "[codecarbon INFO @ 01:37:28] Energy consumed for all CPUs : 0.010099 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:37:28] 0.023484 kWh of electricity used since the beginning.\n",
            "Epoch [14/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.27it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:37:43] Energy consumed for RAM : 0.001148 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:37:43] Energy consumed for all GPUs : 0.012472 kWh. Total GPU Power : 51.82772788184383 W\n",
            "[codecarbon INFO @ 01:37:43] Energy consumed for all CPUs : 0.010276 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:37:43] 0.023897 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/80], Train Loss: 0.6453, Train Acc: 78.30%, Val Loss: 0.6665, Val Acc: 77.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [15/80] - Training:  11%|█         | 34/313 [00:06<00:53,  5.18it/s][codecarbon INFO @ 01:37:58] Energy consumed for RAM : 0.001168 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:37:58] Energy consumed for all GPUs : 0.012645 kWh. Total GPU Power : 41.248657468168304 W\n",
            "[codecarbon INFO @ 01:37:58] Energy consumed for all CPUs : 0.010454 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:37:58] 0.024267 kWh of electricity used since the beginning.\n",
            "Epoch [15/80] - Training:  39%|███▉      | 123/313 [00:21<00:37,  5.01it/s][codecarbon INFO @ 01:38:13] Energy consumed for RAM : 0.001188 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:38:13] Energy consumed for all GPUs : 0.012865 kWh. Total GPU Power : 53.152370211672455 W\n",
            "[codecarbon INFO @ 01:38:13] Energy consumed for all CPUs : 0.010631 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:38:13] 0.024684 kWh of electricity used since the beginning.\n",
            "Epoch [15/80] - Training:  69%|██████▊   | 215/313 [00:36<00:19,  5.05it/s][codecarbon INFO @ 01:38:28] Energy consumed for RAM : 0.001207 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:38:28] Energy consumed for all GPUs : 0.013094 kWh. Total GPU Power : 54.7675270853228 W\n",
            "[codecarbon INFO @ 01:38:28] Energy consumed for all CPUs : 0.010808 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:38:28] 0.025109 kWh of electricity used since the beginning.\n",
            "Epoch [15/80] - Training:  98%|█████████▊| 306/313 [00:51<00:01,  5.50it/s][codecarbon INFO @ 01:38:43] Energy consumed for RAM : 0.001227 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:38:43] Energy consumed for all GPUs : 0.013324 kWh. Total GPU Power : 55.194589591429 W\n",
            "[codecarbon INFO @ 01:38:43] Energy consumed for all CPUs : 0.010985 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:38:43] 0.025536 kWh of electricity used since the beginning.\n",
            "Epoch [15/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.91it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/80], Train Loss: 0.6246, Train Acc: 78.81%, Val Loss: 0.6393, Val Acc: 78.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [16/80] - Training:   6%|▌         | 18/313 [00:04<01:07,  4.38it/s][codecarbon INFO @ 01:38:58] Energy consumed for RAM : 0.001247 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:38:58] Energy consumed for all GPUs : 0.013500 kWh. Total GPU Power : 42.18191260708424 W\n",
            "[codecarbon INFO @ 01:38:58] Energy consumed for all CPUs : 0.011163 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:38:58] 0.025910 kWh of electricity used since the beginning.\n",
            "Epoch [16/80] - Training:  35%|███▍      | 108/313 [00:18<00:44,  4.63it/s][codecarbon INFO @ 01:39:13] Energy consumed for RAM : 0.001267 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:39:13] Energy consumed for all GPUs : 0.013727 kWh. Total GPU Power : 54.54356770546818 W\n",
            "[codecarbon INFO @ 01:39:13] Energy consumed for all CPUs : 0.011340 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:39:13] 0.026333 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:39:13] 0.003795 g.CO2eq/s mean an estimation of 119.68561783007516 kg.CO2eq/year\n",
            "Epoch [16/80] - Training:  64%|██████▎   | 199/313 [00:34<00:21,  5.39it/s][codecarbon INFO @ 01:39:28] Energy consumed for RAM : 0.001287 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:39:28] Energy consumed for all GPUs : 0.013955 kWh. Total GPU Power : 54.78447191702951 W\n",
            "[codecarbon INFO @ 01:39:28] Energy consumed for all CPUs : 0.011518 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:39:28] 0.026760 kWh of electricity used since the beginning.\n",
            "Epoch [16/80] - Training:  93%|█████████▎| 290/313 [00:48<00:04,  5.09it/s][codecarbon INFO @ 01:39:43] Energy consumed for RAM : 0.001306 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:39:43] Energy consumed for all GPUs : 0.014187 kWh. Total GPU Power : 55.73746499750004 W\n",
            "[codecarbon INFO @ 01:39:43] Energy consumed for all CPUs : 0.011694 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:39:43] 0.027188 kWh of electricity used since the beginning.\n",
            "Epoch [16/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.87it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/80], Train Loss: 0.6081, Train Acc: 79.21%, Val Loss: 0.6673, Val Acc: 77.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17/80] - Training:   2%|▏         | 5/313 [00:01<01:34,  3.27it/s][codecarbon INFO @ 01:39:58] Energy consumed for RAM : 0.001326 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:39:58] Energy consumed for all GPUs : 0.014361 kWh. Total GPU Power : 41.66450099372745 W\n",
            "[codecarbon INFO @ 01:39:58] Energy consumed for all CPUs : 0.011871 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:39:58] 0.027558 kWh of electricity used since the beginning.\n",
            "Epoch [17/80] - Training:  30%|██▉       | 93/313 [00:16<00:46,  4.74it/s][codecarbon INFO @ 01:40:13] Energy consumed for RAM : 0.001346 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:40:13] Energy consumed for all GPUs : 0.014578 kWh. Total GPU Power : 52.09911696824401 W\n",
            "[codecarbon INFO @ 01:40:13] Energy consumed for all CPUs : 0.012049 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:40:13] 0.027972 kWh of electricity used since the beginning.\n",
            "Epoch [17/80] - Training:  58%|█████▊    | 182/313 [00:31<00:24,  5.36it/s][codecarbon INFO @ 01:40:28] Energy consumed for RAM : 0.001366 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:40:28] Energy consumed for all GPUs : 0.014803 kWh. Total GPU Power : 54.04502083565573 W\n",
            "[codecarbon INFO @ 01:40:28] Energy consumed for all CPUs : 0.012226 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:40:28] 0.028395 kWh of electricity used since the beginning.\n",
            "Epoch [17/80] - Training:  87%|████████▋ | 272/313 [00:47<00:08,  4.56it/s][codecarbon INFO @ 01:40:43] Energy consumed for RAM : 0.001386 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:40:43] Energy consumed for all GPUs : 0.015031 kWh. Total GPU Power : 54.621173825942606 W\n",
            "[codecarbon INFO @ 01:40:43] Energy consumed for all CPUs : 0.012403 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:40:43] 0.028820 kWh of electricity used since the beginning.\n",
            "Epoch [17/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.82it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:40:58] Energy consumed for RAM : 0.001405 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:40:58] Energy consumed for all GPUs : 0.015221 kWh. Total GPU Power : 45.69674385242736 W\n",
            "[codecarbon INFO @ 01:40:58] Energy consumed for all CPUs : 0.012581 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:40:58] 0.029207 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/80], Train Loss: 0.6069, Train Acc: 79.50%, Val Loss: 0.6272, Val Acc: 78.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [18/80] - Training:  25%|██▍       | 77/313 [00:13<00:52,  4.48it/s][codecarbon INFO @ 01:41:13] Energy consumed for RAM : 0.001425 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:41:13] Energy consumed for all GPUs : 0.015441 kWh. Total GPU Power : 52.586081827588686 W\n",
            "[codecarbon INFO @ 01:41:13] Energy consumed for all CPUs : 0.012758 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:41:13] 0.029625 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:41:13] 0.003799 g.CO2eq/s mean an estimation of 119.80015291312223 kg.CO2eq/year\n",
            "Epoch [18/80] - Training:  53%|█████▎    | 167/313 [00:28<00:33,  4.37it/s][codecarbon INFO @ 01:41:28] Energy consumed for RAM : 0.001445 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:41:28] Energy consumed for all GPUs : 0.015673 kWh. Total GPU Power : 55.68786090538561 W\n",
            "[codecarbon INFO @ 01:41:28] Energy consumed for all CPUs : 0.012935 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:41:28] 0.030053 kWh of electricity used since the beginning.\n",
            "Epoch [18/80] - Training:  83%|████████▎ | 259/313 [00:42<00:11,  4.66it/s][codecarbon INFO @ 01:41:43] Energy consumed for RAM : 0.001465 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:41:43] Energy consumed for all GPUs : 0.015902 kWh. Total GPU Power : 54.98775027995681 W\n",
            "[codecarbon INFO @ 01:41:43] Energy consumed for all CPUs : 0.013112 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:41:43] 0.030479 kWh of electricity used since the beginning.\n",
            "Epoch [18/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.13it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:41:58] Energy consumed for RAM : 0.001485 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:41:58] Energy consumed for all GPUs : 0.016096 kWh. Total GPU Power : 46.67219649935736 W\n",
            "[codecarbon INFO @ 01:41:58] Energy consumed for all CPUs : 0.013289 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:41:58] 0.030870 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/80], Train Loss: 0.6107, Train Acc: 79.22%, Val Loss: 0.6284, Val Acc: 78.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [19/80] - Training:  21%|██        | 66/313 [00:11<00:59,  4.15it/s][codecarbon INFO @ 01:42:13] Energy consumed for RAM : 0.001504 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:42:13] Energy consumed for all GPUs : 0.016304 kWh. Total GPU Power : 49.698091601063766 W\n",
            "[codecarbon INFO @ 01:42:13] Energy consumed for all CPUs : 0.013467 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:42:13] 0.031275 kWh of electricity used since the beginning.\n",
            "Epoch [19/80] - Training:  50%|████▉     | 156/313 [00:26<00:37,  4.19it/s][codecarbon INFO @ 01:42:28] Energy consumed for RAM : 0.001524 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:42:28] Energy consumed for all GPUs : 0.016534 kWh. Total GPU Power : 55.46033438024574 W\n",
            "[codecarbon INFO @ 01:42:28] Energy consumed for all CPUs : 0.013644 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:42:28] 0.031702 kWh of electricity used since the beginning.\n",
            "Epoch [19/80] - Training:  79%|███████▊  | 246/313 [00:41<00:15,  4.40it/s][codecarbon INFO @ 01:42:43] Energy consumed for RAM : 0.001544 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:42:43] Energy consumed for all GPUs : 0.016763 kWh. Total GPU Power : 54.99178563382497 W\n",
            "[codecarbon INFO @ 01:42:43] Energy consumed for all CPUs : 0.013821 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:42:43] 0.032128 kWh of electricity used since the beginning.\n",
            "Epoch [19/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.08it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:42:58] Energy consumed for RAM : 0.001564 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:42:58] Energy consumed for all GPUs : 0.016974 kWh. Total GPU Power : 50.61531554245037 W\n",
            "[codecarbon INFO @ 01:42:58] Energy consumed for all CPUs : 0.013998 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:42:58] 0.032536 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/80], Train Loss: 0.5870, Train Acc: 79.97%, Val Loss: 0.6146, Val Acc: 79.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [20/80] - Training:  15%|█▍        | 46/313 [00:09<01:05,  4.10it/s][codecarbon INFO @ 01:43:13] Energy consumed for RAM : 0.001584 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:43:13] Energy consumed for all GPUs : 0.017158 kWh. Total GPU Power : 44.05497134086916 W\n",
            "[codecarbon INFO @ 01:43:13] Energy consumed for all CPUs : 0.014175 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:43:14] 0.032917 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:43:14] 0.003802 g.CO2eq/s mean an estimation of 119.90022059918729 kg.CO2eq/year\n",
            "Epoch [20/80] - Training:  43%|████▎     | 134/313 [00:24<00:43,  4.12it/s][codecarbon INFO @ 01:43:28] Energy consumed for RAM : 0.001603 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:43:28] Energy consumed for all GPUs : 0.017380 kWh. Total GPU Power : 53.66646848040851 W\n",
            "[codecarbon INFO @ 01:43:28] Energy consumed for all CPUs : 0.014352 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:43:28] 0.033335 kWh of electricity used since the beginning.\n",
            "Epoch [20/80] - Training:  72%|███████▏  | 224/313 [00:39<00:22,  3.96it/s][codecarbon INFO @ 01:43:43] Energy consumed for RAM : 0.001623 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:43:43] Energy consumed for all GPUs : 0.017604 kWh. Total GPU Power : 53.722254046591225 W\n",
            "[codecarbon INFO @ 01:43:43] Energy consumed for all CPUs : 0.014529 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:43:43] 0.033756 kWh of electricity used since the beginning.\n",
            "Epoch [20/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.87it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:43:58] Energy consumed for RAM : 0.001643 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:43:59] Energy consumed for all GPUs : 0.017839 kWh. Total GPU Power : 56.3018294050264 W\n",
            "[codecarbon INFO @ 01:43:59] Energy consumed for all CPUs : 0.014706 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:43:59] 0.034188 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/80], Train Loss: 0.5899, Train Acc: 80.00%, Val Loss: 0.6204, Val Acc: 79.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [21/80] - Training:   9%|▉         | 28/313 [00:06<00:52,  5.48it/s][codecarbon INFO @ 01:44:14] Energy consumed for RAM : 0.001663 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:44:14] Energy consumed for all GPUs : 0.018005 kWh. Total GPU Power : 39.99064177126551 W\n",
            "[codecarbon INFO @ 01:44:14] Energy consumed for all CPUs : 0.014883 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:44:14] 0.034551 kWh of electricity used since the beginning.\n",
            "Epoch [21/80] - Training:  37%|███▋      | 117/313 [00:21<00:32,  6.03it/s][codecarbon INFO @ 01:44:29] Energy consumed for RAM : 0.001682 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:44:29] Energy consumed for all GPUs : 0.018233 kWh. Total GPU Power : 54.503932413372816 W\n",
            "[codecarbon INFO @ 01:44:29] Energy consumed for all CPUs : 0.015060 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:44:29] 0.034975 kWh of electricity used since the beginning.\n",
            "Epoch [21/80] - Training:  66%|██████▌   | 207/313 [00:36<00:16,  6.47it/s][codecarbon INFO @ 01:44:44] Energy consumed for RAM : 0.001702 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:44:44] Energy consumed for all GPUs : 0.018462 kWh. Total GPU Power : 55.14398845389061 W\n",
            "[codecarbon INFO @ 01:44:44] Energy consumed for all CPUs : 0.015238 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:44:44] 0.035402 kWh of electricity used since the beginning.\n",
            "Epoch [21/80] - Training:  95%|█████████▍| 296/313 [00:51<00:02,  6.32it/s][codecarbon INFO @ 01:44:59] Energy consumed for RAM : 0.001722 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:44:59] Energy consumed for all GPUs : 0.018691 kWh. Total GPU Power : 54.987561320386206 W\n",
            "[codecarbon INFO @ 01:44:59] Energy consumed for all CPUs : 0.015415 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:44:59] 0.035828 kWh of electricity used since the beginning.\n",
            "Epoch [21/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.81it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/80], Train Loss: 0.5689, Train Acc: 80.51%, Val Loss: 0.6387, Val Acc: 78.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [22/80] - Training:   4%|▎         | 11/313 [00:02<00:49,  6.10it/s][codecarbon INFO @ 01:45:14] Energy consumed for RAM : 0.001742 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:45:14] Energy consumed for all GPUs : 0.018867 kWh. Total GPU Power : 42.31105463027865 W\n",
            "[codecarbon INFO @ 01:45:14] Energy consumed for all CPUs : 0.015592 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:45:14] 0.036201 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:45:14] 0.003795 g.CO2eq/s mean an estimation of 119.68251862286053 kg.CO2eq/year\n",
            "Epoch [22/80] - Training:  32%|███▏      | 100/313 [00:17<00:33,  6.33it/s][codecarbon INFO @ 01:45:29] Energy consumed for RAM : 0.001762 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:45:29] Energy consumed for all GPUs : 0.019088 kWh. Total GPU Power : 53.186467335930274 W\n",
            "[codecarbon INFO @ 01:45:29] Energy consumed for all CPUs : 0.015769 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:45:29] 0.036619 kWh of electricity used since the beginning.\n",
            "Epoch [22/80] - Training:  60%|██████    | 188/313 [00:32<00:18,  6.91it/s][codecarbon INFO @ 01:45:44] Energy consumed for RAM : 0.001781 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:45:44] Energy consumed for all GPUs : 0.019311 kWh. Total GPU Power : 53.519657322109545 W\n",
            "[codecarbon INFO @ 01:45:44] Energy consumed for all CPUs : 0.015946 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:45:44] 0.037038 kWh of electricity used since the beginning.\n",
            "Epoch [22/80] - Training:  88%|████████▊ | 276/313 [00:47<00:05,  6.70it/s][codecarbon INFO @ 01:45:59] Energy consumed for RAM : 0.001801 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:45:59] Energy consumed for all GPUs : 0.019538 kWh. Total GPU Power : 54.47921693791103 W\n",
            "[codecarbon INFO @ 01:45:59] Energy consumed for all CPUs : 0.016123 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:45:59] 0.037462 kWh of electricity used since the beginning.\n",
            "Epoch [22/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:46:14] Energy consumed for RAM : 0.001821 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:46:14] Energy consumed for all GPUs : 0.019729 kWh. Total GPU Power : 45.78588457107963 W\n",
            "[codecarbon INFO @ 01:46:14] Energy consumed for all CPUs : 0.016300 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:46:14] 0.037850 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/80], Train Loss: 0.5615, Train Acc: 81.07%, Val Loss: 0.6730, Val Acc: 77.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [23/80] - Training:  25%|██▍       | 77/313 [00:14<00:32,  7.20it/s][codecarbon INFO @ 01:46:29] Energy consumed for RAM : 0.001841 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:46:29] Energy consumed for all GPUs : 0.019939 kWh. Total GPU Power : 50.46574793239083 W\n",
            "[codecarbon INFO @ 01:46:29] Energy consumed for all CPUs : 0.016477 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:46:29] 0.038257 kWh of electricity used since the beginning.\n",
            "Epoch [23/80] - Training:  54%|█████▎    | 168/313 [00:29<00:21,  6.89it/s][codecarbon INFO @ 01:46:44] Energy consumed for RAM : 0.001861 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:46:44] Energy consumed for all GPUs : 0.020172 kWh. Total GPU Power : 55.88222482252938 W\n",
            "[codecarbon INFO @ 01:46:44] Energy consumed for all CPUs : 0.016654 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:46:44] 0.038687 kWh of electricity used since the beginning.\n",
            "Epoch [23/80] - Training:  82%|████████▏ | 258/313 [00:44<00:08,  6.82it/s][codecarbon INFO @ 01:46:59] Energy consumed for RAM : 0.001880 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:46:59] Energy consumed for all GPUs : 0.020402 kWh. Total GPU Power : 55.23146278565832 W\n",
            "[codecarbon INFO @ 01:46:59] Energy consumed for all CPUs : 0.016832 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:46:59] 0.039114 kWh of electricity used since the beginning.\n",
            "Epoch [23/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.03it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:47:14] Energy consumed for RAM : 0.001900 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:47:14] Energy consumed for all GPUs : 0.020610 kWh. Total GPU Power : 50.05031177140845 W\n",
            "[codecarbon INFO @ 01:47:14] Energy consumed for all CPUs : 0.017009 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:47:14] 0.039519 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:47:14] 0.003834 g.CO2eq/s mean an estimation of 120.92437369337783 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/80], Train Loss: 0.5613, Train Acc: 80.82%, Val Loss: 0.6165, Val Acc: 78.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [24/80] - Training:  20%|██        | 64/313 [00:11<00:34,  7.23it/s][codecarbon INFO @ 01:47:29] Energy consumed for RAM : 0.001920 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:47:29] Energy consumed for all GPUs : 0.020806 kWh. Total GPU Power : 47.008241875825526 W\n",
            "[codecarbon INFO @ 01:47:29] Energy consumed for all CPUs : 0.017186 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:47:29] 0.039912 kWh of electricity used since the beginning.\n",
            "Epoch [24/80] - Training:  51%|█████     | 159/313 [00:26<00:19,  7.71it/s][codecarbon INFO @ 01:47:44] Energy consumed for RAM : 0.001940 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:47:44] Energy consumed for all GPUs : 0.021035 kWh. Total GPU Power : 54.99917101657436 W\n",
            "[codecarbon INFO @ 01:47:44] Energy consumed for all CPUs : 0.017363 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:47:44] 0.040338 kWh of electricity used since the beginning.\n",
            "Epoch [24/80] - Training:  81%|████████  | 254/313 [00:42<00:08,  6.81it/s][codecarbon INFO @ 01:47:59] Energy consumed for RAM : 0.001959 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:47:59] Energy consumed for all GPUs : 0.021269 kWh. Total GPU Power : 56.16798723399899 W\n",
            "[codecarbon INFO @ 01:47:59] Energy consumed for all CPUs : 0.017540 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:47:59] 0.040769 kWh of electricity used since the beginning.\n",
            "Epoch [24/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.14it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:48:14] Energy consumed for RAM : 0.001979 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:48:14] Energy consumed for all GPUs : 0.021481 kWh. Total GPU Power : 50.916306551069546 W\n",
            "[codecarbon INFO @ 01:48:14] Energy consumed for all CPUs : 0.017717 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:48:14] 0.041178 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/80], Train Loss: 0.5498, Train Acc: 81.21%, Val Loss: 0.6213, Val Acc: 78.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [25/80] - Training:  21%|██        | 65/313 [00:12<00:35,  7.05it/s][codecarbon INFO @ 01:48:29] Energy consumed for RAM : 0.001999 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:48:29] Energy consumed for all GPUs : 0.021678 kWh. Total GPU Power : 47.24099955347046 W\n",
            "[codecarbon INFO @ 01:48:29] Energy consumed for all CPUs : 0.017895 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:48:29] 0.041572 kWh of electricity used since the beginning.\n",
            "Epoch [25/80] - Training:  50%|████▉     | 156/313 [00:27<00:22,  7.01it/s][codecarbon INFO @ 01:48:44] Energy consumed for RAM : 0.002019 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:48:44] Energy consumed for all GPUs : 0.021907 kWh. Total GPU Power : 54.98509057279036 W\n",
            "[codecarbon INFO @ 01:48:44] Energy consumed for all CPUs : 0.018072 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:48:44] 0.041998 kWh of electricity used since the beginning.\n",
            "Epoch [25/80] - Training:  79%|███████▊  | 246/313 [00:42<00:09,  7.03it/s][codecarbon INFO @ 01:48:59] Energy consumed for RAM : 0.002039 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:48:59] Energy consumed for all GPUs : 0.022136 kWh. Total GPU Power : 54.824309002254004 W\n",
            "[codecarbon INFO @ 01:48:59] Energy consumed for all CPUs : 0.018249 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:48:59] 0.042423 kWh of electricity used since the beginning.\n",
            "Epoch [25/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.85it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:49:14] Energy consumed for RAM : 0.002058 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:49:14] Energy consumed for all GPUs : 0.022351 kWh. Total GPU Power : 51.56850869135489 W\n",
            "[codecarbon INFO @ 01:49:14] Energy consumed for all CPUs : 0.018426 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:49:14] 0.042835 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:49:14] 0.003830 g.CO2eq/s mean an estimation of 120.78077161113708 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/80], Train Loss: 0.5412, Train Acc: 81.64%, Val Loss: 0.5805, Val Acc: 80.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [26/80] - Training:  16%|█▌        | 50/313 [00:09<00:38,  6.80it/s][codecarbon INFO @ 01:49:29] Energy consumed for RAM : 0.002078 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:49:29] Energy consumed for all GPUs : 0.022536 kWh. Total GPU Power : 44.4340329734726 W\n",
            "[codecarbon INFO @ 01:49:29] Energy consumed for all CPUs : 0.018603 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:49:29] 0.043217 kWh of electricity used since the beginning.\n",
            "Epoch [26/80] - Training:  45%|████▍     | 140/313 [00:24<00:25,  6.77it/s][codecarbon INFO @ 01:49:44] Energy consumed for RAM : 0.002098 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:49:44] Energy consumed for all GPUs : 0.022761 kWh. Total GPU Power : 54.19305895352616 W\n",
            "[codecarbon INFO @ 01:49:44] Energy consumed for all CPUs : 0.018781 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:49:44] 0.043640 kWh of electricity used since the beginning.\n",
            "Epoch [26/80] - Training:  73%|███████▎  | 228/313 [00:39<00:12,  6.87it/s][codecarbon INFO @ 01:49:59] Energy consumed for RAM : 0.002118 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:49:59] Energy consumed for all GPUs : 0.022986 kWh. Total GPU Power : 54.0536583845219 W\n",
            "[codecarbon INFO @ 01:49:59] Energy consumed for all CPUs : 0.018957 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:49:59] 0.044061 kWh of electricity used since the beginning.\n",
            "Epoch [26/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.86it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:50:14] Energy consumed for RAM : 0.002137 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:50:14] Energy consumed for all GPUs : 0.023211 kWh. Total GPU Power : 54.03538520141186 W\n",
            "[codecarbon INFO @ 01:50:14] Energy consumed for all CPUs : 0.019134 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:50:14] 0.044483 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/80], Train Loss: 0.5386, Train Acc: 81.65%, Val Loss: 0.5911, Val Acc: 79.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [27/80] - Training:  10%|▉         | 30/313 [00:05<00:40,  7.04it/s][codecarbon INFO @ 01:50:29] Energy consumed for RAM : 0.002157 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:50:29] Energy consumed for all GPUs : 0.023387 kWh. Total GPU Power : 42.45605932779415 W\n",
            "[codecarbon INFO @ 01:50:29] Energy consumed for all CPUs : 0.019311 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:50:29] 0.044856 kWh of electricity used since the beginning.\n",
            "Epoch [27/80] - Training:  39%|███▊      | 121/313 [00:20<00:27,  6.90it/s][codecarbon INFO @ 01:50:44] Energy consumed for RAM : 0.002177 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:50:44] Energy consumed for all GPUs : 0.023617 kWh. Total GPU Power : 55.25614090210138 W\n",
            "[codecarbon INFO @ 01:50:44] Energy consumed for all CPUs : 0.019488 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:50:44] 0.045282 kWh of electricity used since the beginning.\n",
            "Epoch [27/80] - Training:  67%|██████▋   | 210/313 [00:35<00:15,  6.61it/s][codecarbon INFO @ 01:50:59] Energy consumed for RAM : 0.002197 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:50:59] Energy consumed for all GPUs : 0.023842 kWh. Total GPU Power : 54.02491271189723 W\n",
            "[codecarbon INFO @ 01:50:59] Energy consumed for all CPUs : 0.019666 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:50:59] 0.045704 kWh of electricity used since the beginning.\n",
            "Epoch [27/80] - Training:  96%|█████████▌| 301/313 [00:50<00:01,  7.19it/s][codecarbon INFO @ 01:51:14] Energy consumed for RAM : 0.002217 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:51:14] Energy consumed for all GPUs : 0.024071 kWh. Total GPU Power : 54.94024715376875 W\n",
            "[codecarbon INFO @ 01:51:14] Energy consumed for all CPUs : 0.019843 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:51:14] 0.046130 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:51:14] 0.003808 g.CO2eq/s mean an estimation of 120.07818010966567 kg.CO2eq/year\n",
            "Epoch [27/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.04it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/80], Train Loss: 0.5311, Train Acc: 81.75%, Val Loss: 0.6036, Val Acc: 79.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [28/80] - Training:   4%|▍         | 14/313 [00:02<00:48,  6.12it/s][codecarbon INFO @ 01:51:29] Energy consumed for RAM : 0.002236 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:51:29] Energy consumed for all GPUs : 0.024242 kWh. Total GPU Power : 41.05565335885879 W\n",
            "[codecarbon INFO @ 01:51:29] Energy consumed for all CPUs : 0.020020 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:51:29] 0.046498 kWh of electricity used since the beginning.\n",
            "Epoch [28/80] - Training:  33%|███▎      | 104/313 [00:17<00:31,  6.59it/s][codecarbon INFO @ 01:51:44] Energy consumed for RAM : 0.002256 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:51:44] Energy consumed for all GPUs : 0.024467 kWh. Total GPU Power : 54.04942074193018 W\n",
            "[codecarbon INFO @ 01:51:44] Energy consumed for all CPUs : 0.020197 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:51:44] 0.046920 kWh of electricity used since the beginning.\n",
            "Epoch [28/80] - Training:  62%|██████▏   | 193/313 [00:32<00:17,  6.68it/s][codecarbon INFO @ 01:51:59] Energy consumed for RAM : 0.002276 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:51:59] Energy consumed for all GPUs : 0.024694 kWh. Total GPU Power : 54.675436527838116 W\n",
            "[codecarbon INFO @ 01:51:59] Energy consumed for all CPUs : 0.020374 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:51:59] 0.047344 kWh of electricity used since the beginning.\n",
            "Epoch [28/80] - Training:  91%|█████████ | 284/313 [00:47<00:04,  6.86it/s][codecarbon INFO @ 01:52:14] Energy consumed for RAM : 0.002296 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:52:14] Energy consumed for all GPUs : 0.024925 kWh. Total GPU Power : 55.27577240748597 W\n",
            "[codecarbon INFO @ 01:52:14] Energy consumed for all CPUs : 0.020551 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:52:14] 0.047772 kWh of electricity used since the beginning.\n",
            "Epoch [28/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  6.01it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/80], Train Loss: 0.5264, Train Acc: 82.06%, Val Loss: 0.5980, Val Acc: 79.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [29/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s][codecarbon INFO @ 01:52:29] Energy consumed for RAM : 0.002315 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:52:29] Energy consumed for all GPUs : 0.025112 kWh. Total GPU Power : 44.915792467950716 W\n",
            "[codecarbon INFO @ 01:52:29] Energy consumed for all CPUs : 0.020728 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:52:29] 0.048155 kWh of electricity used since the beginning.\n",
            "Epoch [29/80] - Training:  28%|██▊       | 88/313 [00:15<00:32,  6.98it/s][codecarbon INFO @ 01:52:44] Energy consumed for RAM : 0.002335 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:52:44] Energy consumed for all GPUs : 0.025331 kWh. Total GPU Power : 52.84986074953821 W\n",
            "[codecarbon INFO @ 01:52:44] Energy consumed for all CPUs : 0.020905 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:52:44] 0.048572 kWh of electricity used since the beginning.\n",
            "Epoch [29/80] - Training:  57%|█████▋    | 178/313 [00:30<00:19,  7.03it/s][codecarbon INFO @ 01:52:59] Energy consumed for RAM : 0.002355 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:52:59] Energy consumed for all GPUs : 0.025557 kWh. Total GPU Power : 54.066449890578106 W\n",
            "[codecarbon INFO @ 01:52:59] Energy consumed for all CPUs : 0.021082 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:52:59] 0.048994 kWh of electricity used since the beginning.\n",
            "Epoch [29/80] - Training:  86%|████████▌ | 268/313 [00:45<00:06,  6.90it/s][codecarbon INFO @ 01:53:14] Energy consumed for RAM : 0.002375 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:53:14] Energy consumed for all GPUs : 0.025789 kWh. Total GPU Power : 55.672629418477115 W\n",
            "[codecarbon INFO @ 01:53:14] Energy consumed for all CPUs : 0.021259 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:53:14] 0.049423 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:53:14] 0.003805 g.CO2eq/s mean an estimation of 119.99107667742348 kg.CO2eq/year\n",
            "Epoch [29/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.85it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:53:29] Energy consumed for RAM : 0.002395 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:53:29] Energy consumed for all GPUs : 0.025977 kWh. Total GPU Power : 45.11245356543205 W\n",
            "[codecarbon INFO @ 01:53:29] Energy consumed for all CPUs : 0.021437 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:53:29] 0.049808 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/80], Train Loss: 0.5217, Train Acc: 82.14%, Val Loss: 0.5978, Val Acc: 79.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [30/80] - Training:  25%|██▍       | 78/313 [00:13<00:32,  7.28it/s][codecarbon INFO @ 01:53:44] Energy consumed for RAM : 0.002414 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:53:44] Energy consumed for all GPUs : 0.026183 kWh. Total GPU Power : 49.54801129888492 W\n",
            "[codecarbon INFO @ 01:53:44] Energy consumed for all CPUs : 0.021614 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:53:44] 0.050211 kWh of electricity used since the beginning.\n",
            "Epoch [30/80] - Training:  55%|█████▍    | 172/313 [00:28<00:19,  7.10it/s][codecarbon INFO @ 01:53:59] Energy consumed for RAM : 0.002434 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:53:59] Energy consumed for all GPUs : 0.026417 kWh. Total GPU Power : 56.13210321501394 W\n",
            "[codecarbon INFO @ 01:53:59] Energy consumed for all CPUs : 0.021791 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:53:59] 0.050642 kWh of electricity used since the beginning.\n",
            "Epoch [30/80] - Training:  85%|████████▌ | 267/313 [00:43<00:06,  6.90it/s][codecarbon INFO @ 01:54:14] Energy consumed for RAM : 0.002454 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:54:14] Energy consumed for all GPUs : 0.026653 kWh. Total GPU Power : 56.6953773935779 W\n",
            "[codecarbon INFO @ 01:54:14] Energy consumed for all CPUs : 0.021968 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:54:14] 0.051075 kWh of electricity used since the beginning.\n",
            "Epoch [30/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.11it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:54:29] Energy consumed for RAM : 0.002474 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:54:29] Energy consumed for all GPUs : 0.026845 kWh. Total GPU Power : 46.086904963328735 W\n",
            "[codecarbon INFO @ 01:54:29] Energy consumed for all CPUs : 0.022145 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:54:29] 0.051464 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/80], Train Loss: 0.5118, Train Acc: 82.44%, Val Loss: 0.5784, Val Acc: 80.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [31/80] - Training:  25%|██▍       | 78/313 [00:12<00:45,  5.15it/s][codecarbon INFO @ 01:54:44] Energy consumed for RAM : 0.002494 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:54:44] Energy consumed for all GPUs : 0.027065 kWh. Total GPU Power : 52.636048412303836 W\n",
            "[codecarbon INFO @ 01:54:44] Energy consumed for all CPUs : 0.022323 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:54:44] 0.051881 kWh of electricity used since the beginning.\n",
            "Epoch [31/80] - Training:  54%|█████▎    | 168/313 [00:27<00:31,  4.65it/s][codecarbon INFO @ 01:54:59] Energy consumed for RAM : 0.002513 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:54:59] Energy consumed for all GPUs : 0.027294 kWh. Total GPU Power : 55.19428334991237 W\n",
            "[codecarbon INFO @ 01:54:59] Energy consumed for all CPUs : 0.022500 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:54:59] 0.052307 kWh of electricity used since the beginning.\n",
            "Epoch [31/80] - Training:  83%|████████▎ | 259/313 [00:42<00:10,  5.01it/s][codecarbon INFO @ 01:55:14] Energy consumed for RAM : 0.002533 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:55:14] Energy consumed for all GPUs : 0.027529 kWh. Total GPU Power : 56.44434378407533 W\n",
            "[codecarbon INFO @ 01:55:14] Energy consumed for all CPUs : 0.022677 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:55:14] 0.052739 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:55:14] 0.003830 g.CO2eq/s mean an estimation of 120.7985502982255 kg.CO2eq/year\n",
            "Epoch [31/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.11it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:55:29] Energy consumed for RAM : 0.002553 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:55:29] Energy consumed for all GPUs : 0.027732 kWh. Total GPU Power : 48.67214122532928 W\n",
            "[codecarbon INFO @ 01:55:29] Energy consumed for all CPUs : 0.022854 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:55:29] 0.053138 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/80], Train Loss: 0.5100, Train Acc: 82.47%, Val Loss: 0.5978, Val Acc: 79.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [32/80] - Training:  20%|██        | 63/313 [00:10<00:52,  4.79it/s][codecarbon INFO @ 01:55:44] Energy consumed for RAM : 0.002573 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:55:44] Energy consumed for all GPUs : 0.027937 kWh. Total GPU Power : 49.10939530736357 W\n",
            "[codecarbon INFO @ 01:55:44] Energy consumed for all CPUs : 0.023031 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:55:44] 0.053541 kWh of electricity used since the beginning.\n",
            "Epoch [32/80] - Training:  50%|█████     | 157/313 [00:25<00:34,  4.56it/s][codecarbon INFO @ 01:55:59] Energy consumed for RAM : 0.002593 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:55:59] Energy consumed for all GPUs : 0.028169 kWh. Total GPU Power : 55.560862104532276 W\n",
            "[codecarbon INFO @ 01:55:59] Energy consumed for all CPUs : 0.023209 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:55:59] 0.053970 kWh of electricity used since the beginning.\n",
            "Epoch [32/80] - Training:  80%|███████▉  | 249/313 [00:40<00:14,  4.36it/s][codecarbon INFO @ 01:56:14] Energy consumed for RAM : 0.002612 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:56:14] Energy consumed for all GPUs : 0.028397 kWh. Total GPU Power : 54.64703828561193 W\n",
            "[codecarbon INFO @ 01:56:14] Energy consumed for all CPUs : 0.023386 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:56:14] 0.054395 kWh of electricity used since the beginning.\n",
            "Epoch [32/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.18it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:56:29] Energy consumed for RAM : 0.002632 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:56:29] Energy consumed for all GPUs : 0.028605 kWh. Total GPU Power : 49.92449020381015 W\n",
            "[codecarbon INFO @ 01:56:29] Energy consumed for all CPUs : 0.023564 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:56:29] 0.054801 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/80], Train Loss: 0.5072, Train Acc: 82.69%, Val Loss: 0.5627, Val Acc: 80.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [33/80] - Training:  16%|█▌        | 49/313 [00:09<00:59,  4.47it/s][codecarbon INFO @ 01:56:44] Energy consumed for RAM : 0.002652 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:56:44] Energy consumed for all GPUs : 0.028795 kWh. Total GPU Power : 45.691049623483245 W\n",
            "[codecarbon INFO @ 01:56:44] Energy consumed for all CPUs : 0.023741 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:56:44] 0.055188 kWh of electricity used since the beginning.\n",
            "Epoch [33/80] - Training:  45%|████▍     | 140/313 [00:24<00:36,  4.74it/s][codecarbon INFO @ 01:56:59] Energy consumed for RAM : 0.002672 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:56:59] Energy consumed for all GPUs : 0.029022 kWh. Total GPU Power : 54.30000719479874 W\n",
            "[codecarbon INFO @ 01:56:59] Energy consumed for all CPUs : 0.023918 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:56:59] 0.055612 kWh of electricity used since the beginning.\n",
            "Epoch [33/80] - Training:  73%|███████▎  | 229/313 [00:39<00:19,  4.27it/s][codecarbon INFO @ 01:57:14] Energy consumed for RAM : 0.002692 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:57:14] Energy consumed for all GPUs : 0.029254 kWh. Total GPU Power : 55.668078743656565 W\n",
            "[codecarbon INFO @ 01:57:14] Energy consumed for all CPUs : 0.024095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:57:14] 0.056040 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 01:57:14] 0.003811 g.CO2eq/s mean an estimation of 120.18361490462031 kg.CO2eq/year\n",
            "Epoch [33/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.03it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 01:57:29] Energy consumed for RAM : 0.002711 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:57:29] Energy consumed for all GPUs : 0.029481 kWh. Total GPU Power : 54.42752247169504 W\n",
            "[codecarbon INFO @ 01:57:29] Energy consumed for all CPUs : 0.024273 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:57:29] 0.056465 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/80], Train Loss: 0.5036, Train Acc: 82.77%, Val Loss: 0.5786, Val Acc: 80.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [34/80] - Training:  10%|█         | 32/313 [00:07<01:06,  4.20it/s][codecarbon INFO @ 01:57:44] Energy consumed for RAM : 0.002731 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:57:44] Energy consumed for all GPUs : 0.029653 kWh. Total GPU Power : 41.47288346242917 W\n",
            "[codecarbon INFO @ 01:57:44] Energy consumed for all CPUs : 0.024450 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:57:44] 0.056834 kWh of electricity used since the beginning.\n",
            "Epoch [34/80] - Training:  39%|███▊      | 121/313 [00:22<00:51,  3.74it/s][codecarbon INFO @ 01:57:59] Energy consumed for RAM : 0.002751 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:57:59] Energy consumed for all GPUs : 0.029877 kWh. Total GPU Power : 53.82194355816153 W\n",
            "[codecarbon INFO @ 01:57:59] Energy consumed for all CPUs : 0.024627 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:57:59] 0.057255 kWh of electricity used since the beginning.\n",
            "Epoch [34/80] - Training:  68%|██████▊   | 212/313 [00:37<00:21,  4.75it/s][codecarbon INFO @ 01:58:14] Energy consumed for RAM : 0.002771 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:58:14] Energy consumed for all GPUs : 0.030104 kWh. Total GPU Power : 54.41554834104979 W\n",
            "[codecarbon INFO @ 01:58:14] Energy consumed for all CPUs : 0.024804 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:58:14] 0.057679 kWh of electricity used since the beginning.\n",
            "Epoch [34/80] - Training:  96%|█████████▌| 301/313 [00:52<00:02,  4.16it/s][codecarbon INFO @ 01:58:29] Energy consumed for RAM : 0.002791 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:58:29] Energy consumed for all GPUs : 0.030334 kWh. Total GPU Power : 55.2768994483306 W\n",
            "[codecarbon INFO @ 01:58:29] Energy consumed for all CPUs : 0.024981 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:58:29] 0.058106 kWh of electricity used since the beginning.\n",
            "Epoch [34/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.81it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/80], Train Loss: 0.4956, Train Acc: 83.20%, Val Loss: 0.5934, Val Acc: 79.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [35/80] - Training:   5%|▌         | 16/313 [00:04<01:16,  3.89it/s][codecarbon INFO @ 01:58:44] Energy consumed for RAM : 0.002810 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:58:44] Energy consumed for all GPUs : 0.030504 kWh. Total GPU Power : 40.82216123825453 W\n",
            "[codecarbon INFO @ 01:58:44] Energy consumed for all CPUs : 0.025158 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:58:44] 0.058473 kWh of electricity used since the beginning.\n",
            "Epoch [35/80] - Training:  34%|███▍      | 106/313 [00:19<00:48,  4.23it/s][codecarbon INFO @ 01:58:59] Energy consumed for RAM : 0.002830 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:58:59] Energy consumed for all GPUs : 0.030727 kWh. Total GPU Power : 53.42424665592001 W\n",
            "[codecarbon INFO @ 01:58:59] Energy consumed for all CPUs : 0.025335 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:58:59] 0.058893 kWh of electricity used since the beginning.\n",
            "Epoch [35/80] - Training:  63%|██████▎   | 196/313 [00:34<00:26,  4.47it/s][codecarbon INFO @ 01:59:14] Energy consumed for RAM : 0.002850 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:59:14] Energy consumed for all GPUs : 0.030955 kWh. Total GPU Power : 54.62348678678896 W\n",
            "[codecarbon INFO @ 01:59:14] Energy consumed for all CPUs : 0.025513 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:59:14] 0.059317 kWh of electricity used since the beginning.\n",
            "Epoch [35/80] - Training:  63%|██████▎   | 197/313 [00:34<00:27,  4.26it/s][codecarbon INFO @ 01:59:14] 0.003785 g.CO2eq/s mean an estimation of 119.3594586099352 kg.CO2eq/year\n",
            "Epoch [35/80] - Training:  91%|█████████▏| 286/313 [00:49<00:07,  3.77it/s][codecarbon INFO @ 01:59:29] Energy consumed for RAM : 0.002870 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:59:29] Energy consumed for all GPUs : 0.031177 kWh. Total GPU Power : 53.42796705279439 W\n",
            "[codecarbon INFO @ 01:59:29] Energy consumed for all CPUs : 0.025690 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:59:29] 0.059737 kWh of electricity used since the beginning.\n",
            "Epoch [35/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.82it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/80], Train Loss: 0.4895, Train Acc: 83.15%, Val Loss: 0.5921, Val Acc: 79.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [36/80] - Training:   1%|          | 2/313 [00:01<03:11,  1.62it/s][codecarbon INFO @ 01:59:44] Energy consumed for RAM : 0.002890 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:59:44] Energy consumed for all GPUs : 0.031350 kWh. Total GPU Power : 41.40360500863557 W\n",
            "[codecarbon INFO @ 01:59:44] Energy consumed for all CPUs : 0.025867 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:59:44] 0.060106 kWh of electricity used since the beginning.\n",
            "Epoch [36/80] - Training:  28%|██▊       | 88/313 [00:16<00:57,  3.89it/s][codecarbon INFO @ 01:59:59] Energy consumed for RAM : 0.002909 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 01:59:59] Energy consumed for all GPUs : 0.031562 kWh. Total GPU Power : 51.0294411767305 W\n",
            "[codecarbon INFO @ 01:59:59] Energy consumed for all CPUs : 0.026044 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 01:59:59] 0.060516 kWh of electricity used since the beginning.\n",
            "Epoch [36/80] - Training:  57%|█████▋    | 177/313 [00:31<00:32,  4.24it/s][codecarbon INFO @ 02:00:14] Energy consumed for RAM : 0.002929 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:00:14] Energy consumed for all GPUs : 0.031789 kWh. Total GPU Power : 54.238494623806446 W\n",
            "[codecarbon INFO @ 02:00:14] Energy consumed for all CPUs : 0.026221 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:00:14] 0.060939 kWh of electricity used since the beginning.\n",
            "Epoch [36/80] - Training:  85%|████████▌ | 267/313 [00:46<00:10,  4.25it/s][codecarbon INFO @ 02:00:29] Energy consumed for RAM : 0.002949 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:00:29] Energy consumed for all GPUs : 0.032016 kWh. Total GPU Power : 54.528471080423344 W\n",
            "[codecarbon INFO @ 02:00:30] Energy consumed for all CPUs : 0.026399 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:00:30] 0.061364 kWh of electricity used since the beginning.\n",
            "Epoch [36/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.87it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:00:44] Energy consumed for RAM : 0.002969 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:00:44] Energy consumed for all GPUs : 0.032206 kWh. Total GPU Power : 45.702453115830295 W\n",
            "[codecarbon INFO @ 02:00:44] Energy consumed for all CPUs : 0.026576 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:00:44] 0.061751 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/80], Train Loss: 0.4899, Train Acc: 83.14%, Val Loss: 0.5845, Val Acc: 80.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [37/80] - Training:  21%|██▏       | 67/313 [00:12<01:02,  3.95it/s][codecarbon INFO @ 02:00:59] Energy consumed for RAM : 0.002989 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:00:59] Energy consumed for all GPUs : 0.032412 kWh. Total GPU Power : 49.483809885671654 W\n",
            "[codecarbon INFO @ 02:00:59] Energy consumed for all CPUs : 0.026753 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:00:59] 0.062154 kWh of electricity used since the beginning.\n",
            "Epoch [37/80] - Training:  51%|█████     | 159/313 [00:27<00:34,  4.48it/s][codecarbon INFO @ 02:01:15] Energy consumed for RAM : 0.003008 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:01:15] Energy consumed for all GPUs : 0.032637 kWh. Total GPU Power : 53.84267488461583 W\n",
            "[codecarbon INFO @ 02:01:15] Energy consumed for all CPUs : 0.026930 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:01:15] 0.062575 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:01:15] 0.003763 g.CO2eq/s mean an estimation of 118.67736144107374 kg.CO2eq/year\n",
            "Epoch [37/80] - Training:  80%|███████▉  | 249/313 [00:42<00:13,  4.75it/s][codecarbon INFO @ 02:01:30] Energy consumed for RAM : 0.003028 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:01:30] Energy consumed for all GPUs : 0.032866 kWh. Total GPU Power : 54.87352205444673 W\n",
            "[codecarbon INFO @ 02:01:30] Energy consumed for all CPUs : 0.027108 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:01:30] 0.063002 kWh of electricity used since the beginning.\n",
            "Epoch [37/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  6.00it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:01:45] Energy consumed for RAM : 0.003048 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:01:45] Energy consumed for all GPUs : 0.033073 kWh. Total GPU Power : 49.504680745107265 W\n",
            "[codecarbon INFO @ 02:01:45] Energy consumed for all CPUs : 0.027285 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:01:45] 0.063406 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/80], Train Loss: 0.4832, Train Acc: 83.41%, Val Loss: 0.5810, Val Acc: 79.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [38/80] - Training:  16%|█▋        | 51/313 [00:09<00:57,  4.55it/s][codecarbon INFO @ 02:02:00] Energy consumed for RAM : 0.003068 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:02:00] Energy consumed for all GPUs : 0.033260 kWh. Total GPU Power : 45.20518768427377 W\n",
            "[codecarbon INFO @ 02:02:00] Energy consumed for all CPUs : 0.027462 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:02:00] 0.063790 kWh of electricity used since the beginning.\n",
            "Epoch [38/80] - Training:  45%|████▍     | 140/313 [00:24<00:39,  4.33it/s][codecarbon INFO @ 02:02:15] Energy consumed for RAM : 0.003088 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [38/80] - Training:  45%|████▌     | 141/313 [00:24<00:38,  4.51it/s][codecarbon INFO @ 02:02:15] Energy consumed for all GPUs : 0.033488 kWh. Total GPU Power : 54.56389762962024 W\n",
            "[codecarbon INFO @ 02:02:15] Energy consumed for all CPUs : 0.027639 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:02:15] 0.064214 kWh of electricity used since the beginning.\n",
            "Epoch [38/80] - Training:  74%|███████▍  | 231/313 [00:39<00:18,  4.49it/s][codecarbon INFO @ 02:02:30] Energy consumed for RAM : 0.003107 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:02:30] Energy consumed for all GPUs : 0.033714 kWh. Total GPU Power : 54.41526072008019 W\n",
            "[codecarbon INFO @ 02:02:30] Energy consumed for all CPUs : 0.027816 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:02:30] 0.064638 kWh of electricity used since the beginning.\n",
            "Epoch [38/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  6.01it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:02:45] Energy consumed for RAM : 0.003127 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:02:45] Energy consumed for all GPUs : 0.033938 kWh. Total GPU Power : 53.68786511944707 W\n",
            "[codecarbon INFO @ 02:02:45] Energy consumed for all CPUs : 0.027994 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:02:45] 0.065059 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/80], Train Loss: 0.4786, Train Acc: 83.63%, Val Loss: 0.5768, Val Acc: 79.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [39/80] - Training:  11%|█         | 33/313 [00:07<01:05,  4.25it/s][codecarbon INFO @ 02:03:00] Energy consumed for RAM : 0.003147 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:03:00] Energy consumed for all GPUs : 0.034106 kWh. Total GPU Power : 40.266891160120885 W\n",
            "[codecarbon INFO @ 02:03:00] Energy consumed for all CPUs : 0.028170 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:03:00] 0.065423 kWh of electricity used since the beginning.\n",
            "Epoch [39/80] - Training:  39%|███▉      | 123/313 [00:22<00:43,  4.37it/s][codecarbon INFO @ 02:03:15] Energy consumed for RAM : 0.003167 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:03:15] Energy consumed for all GPUs : 0.034330 kWh. Total GPU Power : 53.86515588667913 W\n",
            "[codecarbon INFO @ 02:03:15] Energy consumed for all CPUs : 0.028348 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:03:15] 0.065844 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:03:15] 0.003776 g.CO2eq/s mean an estimation of 119.07612627878918 kg.CO2eq/year\n",
            "Epoch [39/80] - Training:  68%|██████▊   | 212/313 [00:37<00:23,  4.36it/s][codecarbon INFO @ 02:03:30] Energy consumed for RAM : 0.003186 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:03:30] Energy consumed for all GPUs : 0.034555 kWh. Total GPU Power : 53.932706589021414 W\n",
            "[codecarbon INFO @ 02:03:30] Energy consumed for all CPUs : 0.028525 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:03:30] 0.066266 kWh of electricity used since the beginning.\n",
            "Epoch [39/80] - Training:  96%|█████████▋| 302/313 [00:52<00:02,  4.13it/s][codecarbon INFO @ 02:03:45] Energy consumed for RAM : 0.003206 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:03:45] Energy consumed for all GPUs : 0.034782 kWh. Total GPU Power : 54.59018910701401 W\n",
            "[codecarbon INFO @ 02:03:45] Energy consumed for all CPUs : 0.028702 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:03:45] 0.066690 kWh of electricity used since the beginning.\n",
            "Epoch [39/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.83it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/80], Train Loss: 0.3987, Train Acc: 86.33%, Val Loss: 0.4851, Val Acc: 83.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [40/80] - Training:   5%|▍         | 15/313 [00:04<01:12,  4.09it/s][codecarbon INFO @ 02:04:00] Energy consumed for RAM : 0.003226 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:04:00] Energy consumed for all GPUs : 0.034944 kWh. Total GPU Power : 38.877907473162615 W\n",
            "[codecarbon INFO @ 02:04:00] Energy consumed for all CPUs : 0.028879 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:04:00] 0.067050 kWh of electricity used since the beginning.\n",
            "Epoch [40/80] - Training:  33%|███▎      | 104/313 [00:19<00:46,  4.51it/s][codecarbon INFO @ 02:04:15] Energy consumed for RAM : 0.003246 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:04:15] Energy consumed for all GPUs : 0.035166 kWh. Total GPU Power : 53.114648340691616 W\n",
            "[codecarbon INFO @ 02:04:15] Energy consumed for all CPUs : 0.029057 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:04:15] 0.067468 kWh of electricity used since the beginning.\n",
            "Epoch [40/80] - Training:  62%|██████▏   | 194/313 [00:34<00:27,  4.33it/s][codecarbon INFO @ 02:04:30] Energy consumed for RAM : 0.003266 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:04:30] Energy consumed for all GPUs : 0.035392 kWh. Total GPU Power : 54.10871477425637 W\n",
            "[codecarbon INFO @ 02:04:30] Energy consumed for all CPUs : 0.029234 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:04:30] 0.067891 kWh of electricity used since the beginning.\n",
            "Epoch [40/80] - Training:  91%|█████████ | 284/313 [00:49<00:06,  4.20it/s][codecarbon INFO @ 02:04:45] Energy consumed for RAM : 0.003285 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:04:45] Energy consumed for all GPUs : 0.035620 kWh. Total GPU Power : 54.93180719364105 W\n",
            "[codecarbon INFO @ 02:04:45] Energy consumed for all CPUs : 0.029412 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:04:45] 0.068317 kWh of electricity used since the beginning.\n",
            "Epoch [40/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.85it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/80], Train Loss: 0.3578, Train Acc: 87.58%, Val Loss: 0.4638, Val Acc: 83.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [41/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s][codecarbon INFO @ 02:05:00] Energy consumed for RAM : 0.003305 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:05:00] Energy consumed for all GPUs : 0.035803 kWh. Total GPU Power : 44.0304114155931 W\n",
            "[codecarbon INFO @ 02:05:00] Energy consumed for all CPUs : 0.029588 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:05:00] 0.068697 kWh of electricity used since the beginning.\n",
            "Epoch [41/80] - Training:  28%|██▊       | 89/313 [00:15<00:37,  5.90it/s][codecarbon INFO @ 02:05:15] Energy consumed for RAM : 0.003325 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:05:15] Energy consumed for all GPUs : 0.036028 kWh. Total GPU Power : 53.88609893181072 W\n",
            "[codecarbon INFO @ 02:05:15] Energy consumed for all CPUs : 0.029766 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:05:15] 0.069119 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:05:15] 0.003780 g.CO2eq/s mean an estimation of 119.21120592809716 kg.CO2eq/year\n",
            "Epoch [41/80] - Training:  58%|█████▊    | 181/313 [00:30<00:22,  5.95it/s][codecarbon INFO @ 02:05:30] Energy consumed for RAM : 0.003345 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:05:30] Energy consumed for all GPUs : 0.036258 kWh. Total GPU Power : 55.28637167664253 W\n",
            "[codecarbon INFO @ 02:05:30] Energy consumed for all CPUs : 0.029943 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:05:30] 0.069546 kWh of electricity used since the beginning.\n",
            "Epoch [41/80] - Training:  88%|████████▊ | 274/313 [00:45<00:05,  7.03it/s][codecarbon INFO @ 02:05:45] Energy consumed for RAM : 0.003365 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:05:45] Energy consumed for all GPUs : 0.036487 kWh. Total GPU Power : 54.880624566257026 W\n",
            "[codecarbon INFO @ 02:05:45] Energy consumed for all CPUs : 0.030120 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:05:45] 0.069971 kWh of electricity used since the beginning.\n",
            "Epoch [41/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.15it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:06:00] Energy consumed for RAM : 0.003384 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:06:00] Energy consumed for all GPUs : 0.036679 kWh. Total GPU Power : 46.08419862493834 W\n",
            "[codecarbon INFO @ 02:06:00] Energy consumed for all CPUs : 0.030297 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:06:00] 0.070360 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/80], Train Loss: 0.3468, Train Acc: 87.93%, Val Loss: 0.4591, Val Acc: 84.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [42/80] - Training:  27%|██▋       | 83/313 [00:14<00:33,  6.80it/s][codecarbon INFO @ 02:06:15] Energy consumed for RAM : 0.003404 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:06:15] Energy consumed for all GPUs : 0.036893 kWh. Total GPU Power : 51.425279110800076 W\n",
            "[codecarbon INFO @ 02:06:15] Energy consumed for all CPUs : 0.030474 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:06:15] 0.070771 kWh of electricity used since the beginning.\n",
            "Epoch [42/80] - Training:  57%|█████▋    | 178/313 [00:29<00:19,  6.82it/s][codecarbon INFO @ 02:06:30] Energy consumed for RAM : 0.003424 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [42/80] - Training:  57%|█████▋    | 179/313 [00:29<00:18,  7.27it/s][codecarbon INFO @ 02:06:30] Energy consumed for all GPUs : 0.037126 kWh. Total GPU Power : 55.916172899225586 W\n",
            "[codecarbon INFO @ 02:06:30] Energy consumed for all CPUs : 0.030651 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:06:30] 0.071201 kWh of electricity used since the beginning.\n",
            "Epoch [42/80] - Training:  87%|████████▋ | 271/313 [00:44<00:06,  6.98it/s][codecarbon INFO @ 02:06:45] Energy consumed for RAM : 0.003444 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:06:45] Energy consumed for all GPUs : 0.037360 kWh. Total GPU Power : 56.23291408534215 W\n",
            "[codecarbon INFO @ 02:06:45] Energy consumed for all CPUs : 0.030829 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:06:45] 0.071633 kWh of electricity used since the beginning.\n",
            "Epoch [42/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.25it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:07:00] Energy consumed for RAM : 0.003464 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:07:00] Energy consumed for all GPUs : 0.037554 kWh. Total GPU Power : 46.43562788496581 W\n",
            "[codecarbon INFO @ 02:07:00] Energy consumed for all CPUs : 0.031006 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:07:00] 0.072023 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/80], Train Loss: 0.3316, Train Acc: 88.56%, Val Loss: 0.4546, Val Acc: 84.58%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [43/80] - Training:  23%|██▎       | 73/313 [00:13<00:35,  6.82it/s][codecarbon INFO @ 02:07:15] Energy consumed for RAM : 0.003483 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:07:15] Energy consumed for all GPUs : 0.037757 kWh. Total GPU Power : 48.89830810179377 W\n",
            "[codecarbon INFO @ 02:07:15] Energy consumed for all CPUs : 0.031183 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:07:15] 0.072424 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:07:15] 0.003818 g.CO2eq/s mean an estimation of 120.40093886991615 kg.CO2eq/year\n",
            "Epoch [43/80] - Training:  52%|█████▏    | 162/313 [00:28<00:22,  6.80it/s][codecarbon INFO @ 02:07:30] Energy consumed for RAM : 0.003503 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:07:30] Energy consumed for all GPUs : 0.037984 kWh. Total GPU Power : 54.461924276633226 W\n",
            "[codecarbon INFO @ 02:07:30] Energy consumed for all CPUs : 0.031360 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:07:30] 0.072847 kWh of electricity used since the beginning.\n",
            "Epoch [43/80] - Training:  79%|███████▊  | 246/313 [00:43<00:10,  6.67it/s][codecarbon INFO @ 02:07:45] Energy consumed for RAM : 0.003523 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:07:45] Energy consumed for all GPUs : 0.038204 kWh. Total GPU Power : 52.687948905878436 W\n",
            "[codecarbon INFO @ 02:07:45] Energy consumed for all CPUs : 0.031537 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:07:45] 0.073264 kWh of electricity used since the beginning.\n",
            "Epoch [43/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.82it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:08:00] Energy consumed for RAM : 0.003543 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:08:00] Energy consumed for all GPUs : 0.038422 kWh. Total GPU Power : 52.514662459091845 W\n",
            "[codecarbon INFO @ 02:08:00] Energy consumed for all CPUs : 0.031714 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:08:00] 0.073680 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/80], Train Loss: 0.3220, Train Acc: 88.86%, Val Loss: 0.4640, Val Acc: 84.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [44/80] - Training:  17%|█▋        | 52/313 [00:10<00:37,  6.96it/s][codecarbon INFO @ 02:08:15] Energy consumed for RAM : 0.003563 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:08:15] Energy consumed for all GPUs : 0.038600 kWh. Total GPU Power : 42.70265594278918 W\n",
            "[codecarbon INFO @ 02:08:15] Energy consumed for all CPUs : 0.031891 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:08:15] 0.074054 kWh of electricity used since the beginning.\n",
            "Epoch [44/80] - Training:  46%|████▌     | 143/313 [00:25<00:25,  6.69it/s][codecarbon INFO @ 02:08:30] Energy consumed for RAM : 0.003582 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:08:30] Energy consumed for all GPUs : 0.038829 kWh. Total GPU Power : 54.91105569398891 W\n",
            "[codecarbon INFO @ 02:08:30] Energy consumed for all CPUs : 0.032069 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:08:30] 0.074480 kWh of electricity used since the beginning.\n",
            "Epoch [44/80] - Training:  76%|███████▌  | 237/313 [00:40<00:11,  6.78it/s][codecarbon INFO @ 02:08:45] Energy consumed for RAM : 0.003602 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:08:45] Energy consumed for all GPUs : 0.039065 kWh. Total GPU Power : 56.451530579209695 W\n",
            "[codecarbon INFO @ 02:08:45] Energy consumed for all CPUs : 0.032246 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:08:45] 0.074913 kWh of electricity used since the beginning.\n",
            "Epoch [44/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.97it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:09:00] Energy consumed for RAM : 0.003622 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:09:00] Energy consumed for all GPUs : 0.039284 kWh. Total GPU Power : 52.614856567478576 W\n",
            "[codecarbon INFO @ 02:09:00] Energy consumed for all CPUs : 0.032423 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:09:00] 0.075329 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/80], Train Loss: 0.3142, Train Acc: 89.23%, Val Loss: 0.4495, Val Acc: 84.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [45/80] - Training:  14%|█▍        | 45/313 [00:08<00:36,  7.36it/s][codecarbon INFO @ 02:09:15] Energy consumed for RAM : 0.003642 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:09:15] Energy consumed for all GPUs : 0.039462 kWh. Total GPU Power : 42.58823231524222 W\n",
            "[codecarbon INFO @ 02:09:15] Energy consumed for all CPUs : 0.032600 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:09:15] 0.075704 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:09:15] 0.003788 g.CO2eq/s mean an estimation of 119.46958145531015 kg.CO2eq/year\n",
            "Epoch [45/80] - Training:  44%|████▍     | 139/313 [00:23<00:25,  6.75it/s][codecarbon INFO @ 02:09:30] Energy consumed for RAM : 0.003662 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:09:30] Energy consumed for all GPUs : 0.039691 kWh. Total GPU Power : 54.932021883194366 W\n",
            "[codecarbon INFO @ 02:09:30] Energy consumed for all CPUs : 0.032778 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:09:30] 0.076130 kWh of electricity used since the beginning.\n",
            "Epoch [45/80] - Training:  74%|███████▍  | 231/313 [00:39<00:12,  6.67it/s][codecarbon INFO @ 02:09:45] Energy consumed for RAM : 0.003681 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:09:45] Energy consumed for all GPUs : 0.039920 kWh. Total GPU Power : 55.2209854839963 W\n",
            "[codecarbon INFO @ 02:09:45] Energy consumed for all CPUs : 0.032955 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:09:45] 0.076556 kWh of electricity used since the beginning.\n",
            "Epoch [45/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:10:00] Energy consumed for RAM : 0.003701 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:10:00] Energy consumed for all GPUs : 0.040141 kWh. Total GPU Power : 52.873001735006504 W\n",
            "[codecarbon INFO @ 02:10:00] Energy consumed for all CPUs : 0.033132 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:10:00] 0.076974 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [45/80], Train Loss: 0.3117, Train Acc: 89.21%, Val Loss: 0.4464, Val Acc: 84.95%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [46/80] - Training:  11%|█         | 33/313 [00:05<00:42,  6.66it/s][codecarbon INFO @ 02:10:15] Energy consumed for RAM : 0.003721 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:10:15] Energy consumed for all GPUs : 0.040318 kWh. Total GPU Power : 42.59238440359939 W\n",
            "[codecarbon INFO @ 02:10:15] Energy consumed for all CPUs : 0.033309 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:10:15] 0.077349 kWh of electricity used since the beginning.\n",
            "Epoch [46/80] - Training:  39%|███▉      | 122/313 [00:20<00:28,  6.81it/s][codecarbon INFO @ 02:10:30] Energy consumed for RAM : 0.003741 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:10:30] Energy consumed for all GPUs : 0.040545 kWh. Total GPU Power : 54.408019006148166 W\n",
            "[codecarbon INFO @ 02:10:30] Energy consumed for all CPUs : 0.033486 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:10:30] 0.077772 kWh of electricity used since the beginning.\n",
            "Epoch [46/80] - Training:  67%|██████▋   | 210/313 [00:35<00:15,  6.79it/s][codecarbon INFO @ 02:10:45] Energy consumed for RAM : 0.003760 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:10:45] Energy consumed for all GPUs : 0.040772 kWh. Total GPU Power : 54.6594480073889 W\n",
            "[codecarbon INFO @ 02:10:45] Energy consumed for all CPUs : 0.033663 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:10:45] 0.078196 kWh of electricity used since the beginning.\n",
            "Epoch [46/80] - Training:  95%|█████████▌| 298/313 [00:50<00:02,  6.19it/s][codecarbon INFO @ 02:11:00] Energy consumed for RAM : 0.003780 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:11:00] Energy consumed for all GPUs : 0.040998 kWh. Total GPU Power : 54.21372125084915 W\n",
            "[codecarbon INFO @ 02:11:00] Energy consumed for all CPUs : 0.033841 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:11:00] 0.078619 kWh of electricity used since the beginning.\n",
            "Epoch [46/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/80], Train Loss: 0.3084, Train Acc: 89.28%, Val Loss: 0.4575, Val Acc: 84.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [47/80] - Training:   3%|▎         | 9/313 [00:02<00:51,  5.90it/s][codecarbon INFO @ 02:11:15] Energy consumed for RAM : 0.003800 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:11:15] Energy consumed for all GPUs : 0.041171 kWh. Total GPU Power : 41.44448251372802 W\n",
            "[codecarbon INFO @ 02:11:15] Energy consumed for all CPUs : 0.034018 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:11:15] 0.078988 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:11:15] 0.003794 g.CO2eq/s mean an estimation of 119.63460848472812 kg.CO2eq/year\n",
            "Epoch [47/80] - Training:  31%|███       | 97/313 [00:17<00:32,  6.60it/s][codecarbon INFO @ 02:11:30] Energy consumed for RAM : 0.003820 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:11:30] Energy consumed for all GPUs : 0.041390 kWh. Total GPU Power : 52.798926886972986 W\n",
            "[codecarbon INFO @ 02:11:30] Energy consumed for all CPUs : 0.034195 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:11:30] 0.079405 kWh of electricity used since the beginning.\n",
            "Epoch [47/80] - Training:  59%|█████▉    | 184/313 [00:32<00:18,  6.90it/s][codecarbon INFO @ 02:11:45] Energy consumed for RAM : 0.003840 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:11:45] Energy consumed for all GPUs : 0.041614 kWh. Total GPU Power : 53.65094322747542 W\n",
            "Epoch [47/80] - Training:  59%|█████▉    | 185/313 [00:32<00:20,  6.37it/s][codecarbon INFO @ 02:11:45] Energy consumed for all CPUs : 0.034372 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:11:45] 0.079826 kWh of electricity used since the beginning.\n",
            "Epoch [47/80] - Training:  87%|████████▋ | 273/313 [00:47<00:06,  6.61it/s][codecarbon INFO @ 02:12:00] Energy consumed for RAM : 0.003859 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:12:00] Energy consumed for all GPUs : 0.041841 kWh. Total GPU Power : 54.55586825313756 W\n",
            "[codecarbon INFO @ 02:12:00] Energy consumed for all CPUs : 0.034549 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:12:00] 0.080249 kWh of electricity used since the beginning.\n",
            "Epoch [47/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.90it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:12:15] Energy consumed for RAM : 0.003879 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:12:15] Energy consumed for all GPUs : 0.042033 kWh. Total GPU Power : 46.17326820123305 W\n",
            "[codecarbon INFO @ 02:12:15] Energy consumed for all CPUs : 0.034726 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:12:15] 0.080639 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/80], Train Loss: 0.2931, Train Acc: 90.06%, Val Loss: 0.4531, Val Acc: 84.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [48/80] - Training:  24%|██▍       | 76/313 [00:13<00:36,  6.44it/s][codecarbon INFO @ 02:12:30] Energy consumed for RAM : 0.003899 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:12:30] Energy consumed for all GPUs : 0.042237 kWh. Total GPU Power : 48.95421105179894 W\n",
            "[codecarbon INFO @ 02:12:30] Energy consumed for all CPUs : 0.034903 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:12:30] 0.081039 kWh of electricity used since the beginning.\n",
            "Epoch [48/80] - Training:  52%|█████▏    | 163/313 [00:29<00:23,  6.31it/s][codecarbon INFO @ 02:12:45] Energy consumed for RAM : 0.003919 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:12:45] Energy consumed for all GPUs : 0.042456 kWh. Total GPU Power : 52.6691424553031 W\n",
            "[codecarbon INFO @ 02:12:45] Energy consumed for all CPUs : 0.035080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:12:45] 0.081455 kWh of electricity used since the beginning.\n",
            "Epoch [48/80] - Training:  80%|███████▉  | 250/313 [00:43<00:09,  6.93it/s][codecarbon INFO @ 02:13:00] Energy consumed for RAM : 0.003939 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:13:00] Energy consumed for all GPUs : 0.042680 kWh. Total GPU Power : 53.762120819545906 W\n",
            "[codecarbon INFO @ 02:13:00] Energy consumed for all CPUs : 0.035257 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:13:00] 0.081876 kWh of electricity used since the beginning.\n",
            "Epoch [48/80] - Training: 100%|██████████| 313/313 [00:54<00:00,  5.70it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:13:15] Energy consumed for RAM : 0.003958 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:13:15] Energy consumed for all GPUs : 0.042887 kWh. Total GPU Power : 49.48823587689157 W\n",
            "[codecarbon INFO @ 02:13:15] Energy consumed for all CPUs : 0.035435 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:13:15] 0.082280 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:13:15] 0.003802 g.CO2eq/s mean an estimation of 119.90690018806606 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/80], Train Loss: 0.2977, Train Acc: 89.63%, Val Loss: 0.4480, Val Acc: 84.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [49/80] - Training:  15%|█▌        | 47/313 [00:09<00:41,  6.40it/s][codecarbon INFO @ 02:13:30] Energy consumed for RAM : 0.003978 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [49/80] - Training:  15%|█▌        | 48/313 [00:09<00:42,  6.21it/s][codecarbon INFO @ 02:13:30] Energy consumed for all GPUs : 0.043066 kWh. Total GPU Power : 43.127197369080946 W\n",
            "[codecarbon INFO @ 02:13:30] Energy consumed for all CPUs : 0.035612 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:13:30] 0.082656 kWh of electricity used since the beginning.\n",
            "Epoch [49/80] - Training:  43%|████▎     | 134/313 [00:24<00:26,  6.74it/s][codecarbon INFO @ 02:13:45] Energy consumed for RAM : 0.003998 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:13:45] Energy consumed for all GPUs : 0.043286 kWh. Total GPU Power : 52.89710809109936 W\n",
            "[codecarbon INFO @ 02:13:45] Energy consumed for all CPUs : 0.035789 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:13:45] 0.083074 kWh of electricity used since the beginning.\n",
            "Epoch [49/80] - Training:  71%|███████   | 222/313 [00:39<00:13,  6.56it/s][codecarbon INFO @ 02:14:00] Energy consumed for RAM : 0.004018 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:14:00] Energy consumed for all GPUs : 0.043512 kWh. Total GPU Power : 54.27663049228827 W\n",
            "[codecarbon INFO @ 02:14:00] Energy consumed for all CPUs : 0.035966 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:14:00] 0.083496 kWh of electricity used since the beginning.\n",
            "Epoch [49/80] - Training: 100%|██████████| 313/313 [00:54<00:00,  5.71it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:14:15] Energy consumed for RAM : 0.004038 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:14:15] Energy consumed for all GPUs : 0.043739 kWh. Total GPU Power : 54.49607206588808 W\n",
            "[codecarbon INFO @ 02:14:15] Energy consumed for all CPUs : 0.036144 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:14:15] 0.083921 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:14:15] Energy consumed for all GPUs : 0.043739 kWh. Total GPU Power : 54.49607206588808 W\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/80], Train Loss: 0.2884, Train Acc: 90.06%, Val Loss: 0.4375, Val Acc: 85.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [50/80] - Training:   6%|▋         | 20/313 [00:03<00:43,  6.76it/s][codecarbon INFO @ 02:14:30] Energy consumed for RAM : 0.004057 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:14:30] Energy consumed for all GPUs : 0.043908 kWh. Total GPU Power : 40.40768099598549 W\n",
            "[codecarbon INFO @ 02:14:30] Energy consumed for all CPUs : 0.036320 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:14:30] 0.084285 kWh of electricity used since the beginning.\n",
            "Epoch [50/80] - Training:  34%|███▍      | 107/313 [00:18<00:31,  6.62it/s][codecarbon INFO @ 02:14:45] Energy consumed for RAM : 0.004077 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:14:45] Energy consumed for all GPUs : 0.044127 kWh. Total GPU Power : 52.67071236694638 W\n",
            "[codecarbon INFO @ 02:14:45] Energy consumed for all CPUs : 0.036497 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:14:45] 0.084701 kWh of electricity used since the beginning.\n",
            "Epoch [50/80] - Training:  62%|██████▏   | 195/313 [00:33<00:16,  7.00it/s][codecarbon INFO @ 02:15:00] Energy consumed for RAM : 0.004097 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:15:00] Energy consumed for all GPUs : 0.044356 kWh. Total GPU Power : 55.15742971773816 W\n",
            "[codecarbon INFO @ 02:15:00] Energy consumed for all CPUs : 0.036674 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:15:00] 0.085128 kWh of electricity used since the beginning.\n",
            "Epoch [50/80] - Training:  90%|█████████ | 283/313 [00:48<00:04,  7.18it/s][codecarbon INFO @ 02:15:15] Energy consumed for RAM : 0.004117 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:15:15] Energy consumed for all GPUs : 0.044581 kWh. Total GPU Power : 53.845922339567075 W\n",
            "[codecarbon INFO @ 02:15:15] Energy consumed for all CPUs : 0.036851 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:15:15] 0.085549 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:15:15] 0.003778 g.CO2eq/s mean an estimation of 119.14379883658887 kg.CO2eq/year\n",
            "Epoch [50/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.90it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/80], Train Loss: 0.2857, Train Acc: 90.11%, Val Loss: 0.4416, Val Acc: 84.88%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [51/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s][codecarbon INFO @ 02:15:30] Energy consumed for RAM : 0.004136 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:15:30] Energy consumed for all GPUs : 0.044762 kWh. Total GPU Power : 43.4227331868636 W\n",
            "[codecarbon INFO @ 02:15:30] Energy consumed for all CPUs : 0.037029 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:15:30] 0.085927 kWh of electricity used since the beginning.\n",
            "Epoch [51/80] - Training:  25%|██▌       | 79/313 [00:14<00:36,  6.50it/s][codecarbon INFO @ 02:15:45] Energy consumed for RAM : 0.004156 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:15:45] Energy consumed for all GPUs : 0.044969 kWh. Total GPU Power : 49.822400519899006 W\n",
            "[codecarbon INFO @ 02:15:45] Energy consumed for all CPUs : 0.037206 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:15:45] 0.086331 kWh of electricity used since the beginning.\n",
            "Epoch [51/80] - Training:  54%|█████▎    | 168/313 [00:29<00:20,  6.91it/s][codecarbon INFO @ 02:16:00] Energy consumed for RAM : 0.004176 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:16:00] Energy consumed for all GPUs : 0.045194 kWh. Total GPU Power : 53.946472839989184 W\n",
            "[codecarbon INFO @ 02:16:00] Energy consumed for all CPUs : 0.037383 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:16:00] 0.086753 kWh of electricity used since the beginning.\n",
            "Epoch [51/80] - Training:  81%|████████▏ | 255/313 [00:44<00:08,  6.77it/s][codecarbon INFO @ 02:16:15] Energy consumed for RAM : 0.004196 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:16:15] Energy consumed for all GPUs : 0.045419 kWh. Total GPU Power : 53.981265368283076 W\n",
            "[codecarbon INFO @ 02:16:15] Energy consumed for all CPUs : 0.037560 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:16:15] 0.087174 kWh of electricity used since the beginning.\n",
            "Epoch [51/80] - Training: 100%|██████████| 313/313 [00:54<00:00,  5.77it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:16:30] Energy consumed for RAM : 0.004216 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:16:30] Energy consumed for all GPUs : 0.045630 kWh. Total GPU Power : 50.733256109551114 W\n",
            "[codecarbon INFO @ 02:16:30] Energy consumed for all CPUs : 0.037737 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:16:30] 0.087583 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [51/80], Train Loss: 0.2808, Train Acc: 90.19%, Val Loss: 0.4501, Val Acc: 84.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [52/80] - Training:  19%|█▉        | 59/313 [00:11<00:37,  6.70it/s][codecarbon INFO @ 02:16:45] Energy consumed for RAM : 0.004235 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:16:45] Energy consumed for all GPUs : 0.045818 kWh. Total GPU Power : 45.028314512820806 W\n",
            "[codecarbon INFO @ 02:16:45] Energy consumed for all CPUs : 0.037915 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:16:45] 0.087968 kWh of electricity used since the beginning.\n",
            "Epoch [52/80] - Training:  47%|████▋     | 147/313 [00:26<00:23,  6.96it/s][codecarbon INFO @ 02:17:00] Energy consumed for RAM : 0.004255 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:17:01] Energy consumed for all GPUs : 0.046039 kWh. Total GPU Power : 53.156592256733916 W\n",
            "[codecarbon INFO @ 02:17:01] Energy consumed for all CPUs : 0.038092 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:17:01] 0.088386 kWh of electricity used since the beginning.\n",
            "Epoch [52/80] - Training:  75%|███████▌  | 235/313 [00:41<00:11,  6.72it/s][codecarbon INFO @ 02:17:15] Energy consumed for RAM : 0.004275 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:17:15] Energy consumed for all GPUs : 0.046263 kWh. Total GPU Power : 53.82501334933208 W\n",
            "[codecarbon INFO @ 02:17:15] Energy consumed for all CPUs : 0.038269 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:17:15] 0.088806 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:17:15] 0.003762 g.CO2eq/s mean an estimation of 118.65392614185808 kg.CO2eq/year\n",
            "Epoch [52/80] - Training: 100%|██████████| 313/313 [00:54<00:00,  5.73it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:17:31] Energy consumed for RAM : 0.004295 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:17:31] Energy consumed for all GPUs : 0.046484 kWh. Total GPU Power : 52.988975524828334 W\n",
            "[codecarbon INFO @ 02:17:31] Energy consumed for all CPUs : 0.038446 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:17:31] 0.089225 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [52/80], Train Loss: 0.2758, Train Acc: 90.42%, Val Loss: 0.4421, Val Acc: 85.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [53/80] - Training:  12%|█▏        | 37/313 [00:06<00:41,  6.62it/s][codecarbon INFO @ 02:17:46] Energy consumed for RAM : 0.004315 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:17:46] Energy consumed for all GPUs : 0.046664 kWh. Total GPU Power : 43.31036373407771 W\n",
            "[codecarbon INFO @ 02:17:46] Energy consumed for all CPUs : 0.038623 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:17:46] 0.089602 kWh of electricity used since the beginning.\n",
            "Epoch [53/80] - Training:  40%|███▉      | 125/313 [00:21<00:28,  6.64it/s][codecarbon INFO @ 02:18:01] Energy consumed for RAM : 0.004334 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:18:01] Energy consumed for all GPUs : 0.046888 kWh. Total GPU Power : 53.79470422969817 W\n",
            "[codecarbon INFO @ 02:18:01] Energy consumed for all CPUs : 0.038801 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:18:01] 0.090023 kWh of electricity used since the beginning.\n",
            "Epoch [53/80] - Training:  68%|██████▊   | 213/313 [00:36<00:14,  6.92it/s][codecarbon INFO @ 02:18:16] Energy consumed for RAM : 0.004354 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:18:16] Energy consumed for all GPUs : 0.047118 kWh. Total GPU Power : 55.068880224124555 W\n",
            "[codecarbon INFO @ 02:18:16] Energy consumed for all CPUs : 0.038978 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:18:16] 0.090450 kWh of electricity used since the beginning.\n",
            "Epoch [53/80] - Training:  97%|█████████▋| 303/313 [00:51<00:01,  6.51it/s][codecarbon INFO @ 02:18:31] Energy consumed for RAM : 0.004374 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:18:31] Energy consumed for all GPUs : 0.047345 kWh. Total GPU Power : 54.63831201539241 W\n",
            "[codecarbon INFO @ 02:18:31] Energy consumed for all CPUs : 0.039155 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:18:31] 0.090873 kWh of electricity used since the beginning.\n",
            "Epoch [53/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.93it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [53/80], Train Loss: 0.2756, Train Acc: 90.47%, Val Loss: 0.4491, Val Acc: 85.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [54/80] - Training:   5%|▍         | 15/313 [00:03<00:46,  6.48it/s][codecarbon INFO @ 02:18:46] Energy consumed for RAM : 0.004394 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:18:46] Energy consumed for all GPUs : 0.047520 kWh. Total GPU Power : 42.044253611703084 W\n",
            "[codecarbon INFO @ 02:18:46] Energy consumed for all CPUs : 0.039332 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:18:46] 0.091246 kWh of electricity used since the beginning.\n",
            "Epoch [54/80] - Training:  33%|███▎      | 103/313 [00:18<00:29,  7.04it/s][codecarbon INFO @ 02:19:01] Energy consumed for RAM : 0.004413 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:19:01] Energy consumed for all GPUs : 0.047744 kWh. Total GPU Power : 53.862647391350706 W\n",
            "[codecarbon INFO @ 02:19:01] Energy consumed for all CPUs : 0.039509 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:19:01] 0.091667 kWh of electricity used since the beginning.\n",
            "Epoch [54/80] - Training:  61%|██████▏   | 192/313 [00:33<00:18,  6.59it/s][codecarbon INFO @ 02:19:16] Energy consumed for RAM : 0.004433 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [54/80] - Training:  62%|██████▏   | 193/313 [00:33<00:17,  6.97it/s][codecarbon INFO @ 02:19:16] Energy consumed for all GPUs : 0.047968 kWh. Total GPU Power : 53.67586934969783 W\n",
            "[codecarbon INFO @ 02:19:16] Energy consumed for all CPUs : 0.039686 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:19:16] 0.092088 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:19:16] 0.003788 g.CO2eq/s mean an estimation of 119.47272325096472 kg.CO2eq/year\n",
            "Epoch [54/80] - Training:  90%|█████████ | 282/313 [00:48<00:04,  7.01it/s][codecarbon INFO @ 02:19:31] Energy consumed for RAM : 0.004453 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:19:31] Energy consumed for all GPUs : 0.048196 kWh. Total GPU Power : 54.687378972815 W\n",
            "[codecarbon INFO @ 02:19:31] Energy consumed for all CPUs : 0.039864 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:19:31] 0.092512 kWh of electricity used since the beginning.\n",
            "Epoch [54/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.90it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [54/80], Train Loss: 0.2669, Train Acc: 90.88%, Val Loss: 0.4444, Val Acc: 85.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [55/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s][codecarbon INFO @ 02:19:46] Energy consumed for RAM : 0.004473 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:19:46] Energy consumed for all GPUs : 0.048378 kWh. Total GPU Power : 43.96423668101899 W\n",
            "[codecarbon INFO @ 02:19:46] Energy consumed for all CPUs : 0.040041 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:19:46] 0.092892 kWh of electricity used since the beginning.\n",
            "Epoch [55/80] - Training:  27%|██▋       | 83/313 [00:15<00:35,  6.39it/s][codecarbon INFO @ 02:20:01] Energy consumed for RAM : 0.004493 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:20:01] Energy consumed for all GPUs : 0.048596 kWh. Total GPU Power : 52.081376138229544 W\n",
            "[codecarbon INFO @ 02:20:01] Energy consumed for all CPUs : 0.040218 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:20:01] 0.093306 kWh of electricity used since the beginning.\n",
            "Epoch [55/80] - Training:  54%|█████▍    | 169/313 [00:30<00:22,  6.40it/s][codecarbon INFO @ 02:20:16] Energy consumed for RAM : 0.004512 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:20:16] Energy consumed for all GPUs : 0.048812 kWh. Total GPU Power : 51.958710466013706 W\n",
            "[codecarbon INFO @ 02:20:16] Energy consumed for all CPUs : 0.040395 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:20:16] 0.093719 kWh of electricity used since the beginning.\n",
            "Epoch [55/80] - Training:  82%|████████▏ | 257/313 [00:45<00:08,  6.31it/s][codecarbon INFO @ 02:20:31] Energy consumed for RAM : 0.004532 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:20:31] Energy consumed for all GPUs : 0.049032 kWh. Total GPU Power : 52.87414221807392 W\n",
            "[codecarbon INFO @ 02:20:31] Energy consumed for all CPUs : 0.040572 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:20:31] 0.094137 kWh of electricity used since the beginning.\n",
            "Epoch [55/80] - Training: 100%|██████████| 313/313 [00:55<00:00,  5.66it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:20:46] Energy consumed for RAM : 0.004552 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:20:46] Energy consumed for all GPUs : 0.049229 kWh. Total GPU Power : 47.19201351348354 W\n",
            "[codecarbon INFO @ 02:20:46] Energy consumed for all CPUs : 0.040749 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:20:46] 0.094530 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [55/80], Train Loss: 0.2644, Train Acc: 90.68%, Val Loss: 0.4476, Val Acc: 85.55%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [56/80] - Training:  18%|█▊        | 56/313 [00:09<00:38,  6.75it/s][codecarbon INFO @ 02:21:01] Energy consumed for RAM : 0.004572 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:21:01] Energy consumed for all GPUs : 0.049420 kWh. Total GPU Power : 45.877386125501424 W\n",
            "[codecarbon INFO @ 02:21:01] Energy consumed for all CPUs : 0.040926 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:21:01] 0.094918 kWh of electricity used since the beginning.\n",
            "Epoch [56/80] - Training:  46%|████▌     | 143/313 [00:24<00:30,  5.67it/s][codecarbon INFO @ 02:21:16] Energy consumed for RAM : 0.004592 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:21:16] Energy consumed for all GPUs : 0.049644 kWh. Total GPU Power : 53.824548279280734 W\n",
            "[codecarbon INFO @ 02:21:16] Energy consumed for all CPUs : 0.041104 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:21:16] 0.095339 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:21:16] 0.003757 g.CO2eq/s mean an estimation of 118.4850763463253 kg.CO2eq/year\n",
            "Epoch [56/80] - Training:  74%|███████▍  | 232/313 [00:39<00:11,  6.84it/s][codecarbon INFO @ 02:21:31] Energy consumed for RAM : 0.004611 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:21:31] Energy consumed for all GPUs : 0.049871 kWh. Total GPU Power : 54.5020610035216 W\n",
            "[codecarbon INFO @ 02:21:31] Energy consumed for all CPUs : 0.041281 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:21:31] 0.095764 kWh of electricity used since the beginning.\n",
            "Epoch [56/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.91it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:21:46] Energy consumed for RAM : 0.004631 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:21:46] Energy consumed for all GPUs : 0.050094 kWh. Total GPU Power : 53.54108665457881 W\n",
            "[codecarbon INFO @ 02:21:46] Energy consumed for all CPUs : 0.041458 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:21:46] 0.096183 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [56/80], Train Loss: 0.2584, Train Acc: 91.11%, Val Loss: 0.4367, Val Acc: 85.70%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [57/80] - Training:   9%|▉         | 28/313 [00:05<00:44,  6.39it/s][codecarbon INFO @ 02:22:01] Energy consumed for RAM : 0.004651 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:22:01] Energy consumed for all GPUs : 0.050269 kWh. Total GPU Power : 41.82456799345665 W\n",
            "[codecarbon INFO @ 02:22:01] Energy consumed for all CPUs : 0.041635 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:22:01] 0.096555 kWh of electricity used since the beginning.\n",
            "Epoch [57/80] - Training:  37%|███▋      | 117/313 [00:20<00:29,  6.60it/s][codecarbon INFO @ 02:22:16] Energy consumed for RAM : 0.004671 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:22:16] Energy consumed for all GPUs : 0.050492 kWh. Total GPU Power : 53.428840744634215 W\n",
            "[codecarbon INFO @ 02:22:16] Energy consumed for all CPUs : 0.041812 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:22:16] 0.096975 kWh of electricity used since the beginning.\n",
            "Epoch [57/80] - Training:  65%|██████▌   | 204/313 [00:35<00:17,  6.26it/s][codecarbon INFO @ 02:22:31] Energy consumed for RAM : 0.004691 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:22:31] Energy consumed for all GPUs : 0.050714 kWh. Total GPU Power : 53.34731384553373 W\n",
            "[codecarbon INFO @ 02:22:31] Energy consumed for all CPUs : 0.041990 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:22:31] 0.097394 kWh of electricity used since the beginning.\n",
            "Epoch [57/80] - Training:  94%|█████████▎| 293/313 [00:50<00:03,  6.63it/s][codecarbon INFO @ 02:22:46] Energy consumed for RAM : 0.004710 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:22:46] Energy consumed for all GPUs : 0.050939 kWh. Total GPU Power : 53.857119428240544 W\n",
            "[codecarbon INFO @ 02:22:46] Energy consumed for all CPUs : 0.042167 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:22:46] 0.097816 kWh of electricity used since the beginning.\n",
            "Epoch [57/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.80it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [57/80], Train Loss: 0.2502, Train Acc: 91.40%, Val Loss: 0.4452, Val Acc: 85.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [58/80] - Training:   2%|▏         | 6/313 [00:01<01:21,  3.76it/s][codecarbon INFO @ 02:23:01] Energy consumed for RAM : 0.004730 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:23:01] Energy consumed for all GPUs : 0.051117 kWh. Total GPU Power : 42.68031808765115 W\n",
            "[codecarbon INFO @ 02:23:01] Energy consumed for all CPUs : 0.042344 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:23:01] 0.098191 kWh of electricity used since the beginning.\n",
            "Epoch [58/80] - Training:  30%|███       | 94/313 [00:17<00:43,  5.09it/s][codecarbon INFO @ 02:23:16] Energy consumed for RAM : 0.004750 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:23:16] Energy consumed for all GPUs : 0.051337 kWh. Total GPU Power : 52.98871532213774 W\n",
            "[codecarbon INFO @ 02:23:16] Energy consumed for all CPUs : 0.042522 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:23:16] 0.098609 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:23:16] 0.003775 g.CO2eq/s mean an estimation of 119.0409867818074 kg.CO2eq/year\n",
            "Epoch [58/80] - Training:  58%|█████▊    | 182/313 [00:31<00:21,  6.03it/s][codecarbon INFO @ 02:23:31] Energy consumed for RAM : 0.004770 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:23:31] Energy consumed for all GPUs : 0.051562 kWh. Total GPU Power : 53.936612368703116 W\n",
            "[codecarbon INFO @ 02:23:31] Energy consumed for all CPUs : 0.042699 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:23:31] 0.099030 kWh of electricity used since the beginning.\n",
            "Epoch [58/80] - Training:  86%|████████▋ | 270/313 [00:47<00:07,  5.64it/s][codecarbon INFO @ 02:23:46] Energy consumed for RAM : 0.004790 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:23:46] Energy consumed for all GPUs : 0.051787 kWh. Total GPU Power : 53.89478948713054 W\n",
            "[codecarbon INFO @ 02:23:46] Energy consumed for all CPUs : 0.042876 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:23:46] 0.099452 kWh of electricity used since the beginning.\n",
            "Epoch [58/80] - Training: 100%|██████████| 313/313 [00:54<00:00,  5.74it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:24:01] Energy consumed for RAM : 0.004809 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:24:01] Energy consumed for all GPUs : 0.051969 kWh. Total GPU Power : 43.831605792738856 W\n",
            "[codecarbon INFO @ 02:24:01] Energy consumed for all CPUs : 0.043053 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:24:01] 0.099832 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [58/80], Train Loss: 0.2458, Train Acc: 91.45%, Val Loss: 0.4377, Val Acc: 85.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [59/80] - Training:  24%|██▍       | 76/313 [00:12<00:38,  6.13it/s][codecarbon INFO @ 02:24:16] Energy consumed for RAM : 0.004829 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:24:16] Energy consumed for all GPUs : 0.052183 kWh. Total GPU Power : 51.191081479301715 W\n",
            "[codecarbon INFO @ 02:24:16] Energy consumed for all CPUs : 0.043230 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:24:16] 0.100242 kWh of electricity used since the beginning.\n",
            "Epoch [59/80] - Training:  54%|█████▍    | 169/313 [00:27<00:21,  6.82it/s][codecarbon INFO @ 02:24:31] Energy consumed for RAM : 0.004849 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:24:31] Energy consumed for all GPUs : 0.052410 kWh. Total GPU Power : 54.69228692227207 W\n",
            "[codecarbon INFO @ 02:24:31] Energy consumed for all CPUs : 0.043407 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:24:31] 0.100666 kWh of electricity used since the beginning.\n",
            "Epoch [59/80] - Training:  84%|████████▎ | 262/313 [00:42<00:09,  5.38it/s][codecarbon INFO @ 02:24:46] Energy consumed for RAM : 0.004869 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:24:46] Energy consumed for all GPUs : 0.052640 kWh. Total GPU Power : 55.26811334240612 W\n",
            "[codecarbon INFO @ 02:24:46] Energy consumed for all CPUs : 0.043585 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:24:46] 0.101094 kWh of electricity used since the beginning.\n",
            "Epoch [59/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.03it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:25:01] Energy consumed for RAM : 0.004888 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:25:01] Energy consumed for all GPUs : 0.052830 kWh. Total GPU Power : 45.637727306491 W\n",
            "[codecarbon INFO @ 02:25:01] Energy consumed for all CPUs : 0.043762 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:25:01] 0.101480 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [59/80], Train Loss: 0.2472, Train Acc: 91.46%, Val Loss: 0.4358, Val Acc: 85.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [60/80] - Training:  20%|█▉        | 62/313 [00:10<00:42,  5.97it/s][codecarbon INFO @ 02:25:16] Energy consumed for RAM : 0.004908 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:25:16] Energy consumed for all GPUs : 0.053026 kWh. Total GPU Power : 46.86831338510561 W\n",
            "[codecarbon INFO @ 02:25:16] Energy consumed for all CPUs : 0.043939 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:25:16] 0.101873 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:25:16] 0.003771 g.CO2eq/s mean an estimation of 118.91395749820329 kg.CO2eq/year\n",
            "Epoch [60/80] - Training:  48%|████▊     | 150/313 [00:25<00:23,  6.97it/s][codecarbon INFO @ 02:25:31] Energy consumed for RAM : 0.004928 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:25:31] Energy consumed for all GPUs : 0.053247 kWh. Total GPU Power : 53.16296672481939 W\n",
            "[codecarbon INFO @ 02:25:31] Energy consumed for all CPUs : 0.044116 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:25:31] 0.102291 kWh of electricity used since the beginning.\n",
            "Epoch [60/80] - Training:  76%|███████▌  | 237/313 [00:40<00:11,  6.72it/s][codecarbon INFO @ 02:25:46] Energy consumed for RAM : 0.004948 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:25:46] Energy consumed for all GPUs : 0.053472 kWh. Total GPU Power : 53.999833480029324 W\n",
            "[codecarbon INFO @ 02:25:46] Energy consumed for all CPUs : 0.044293 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:25:46] 0.102713 kWh of electricity used since the beginning.\n",
            "Epoch [60/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.89it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:26:01] Energy consumed for RAM : 0.004968 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:26:01] Energy consumed for all GPUs : 0.053689 kWh. Total GPU Power : 52.11877338137506 W\n",
            "[codecarbon INFO @ 02:26:01] Energy consumed for all CPUs : 0.044471 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:26:01] 0.103128 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [60/80], Train Loss: 0.2472, Train Acc: 91.48%, Val Loss: 0.4351, Val Acc: 85.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [61/80] - Training:  12%|█▏        | 36/313 [00:06<00:39,  7.03it/s][codecarbon INFO @ 02:26:16] Energy consumed for RAM : 0.004988 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:26:16] Energy consumed for all GPUs : 0.053867 kWh. Total GPU Power : 42.70091946288196 W\n",
            "[codecarbon INFO @ 02:26:16] Energy consumed for all CPUs : 0.044648 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:26:16] 0.103503 kWh of electricity used since the beginning.\n",
            "Epoch [61/80] - Training:  41%|████      | 127/313 [00:21<00:27,  6.79it/s][codecarbon INFO @ 02:26:31] Energy consumed for RAM : 0.005007 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:26:31] Energy consumed for all GPUs : 0.054093 kWh. Total GPU Power : 54.254354842657165 W\n",
            "[codecarbon INFO @ 02:26:31] Energy consumed for all CPUs : 0.044825 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:26:31] 0.103925 kWh of electricity used since the beginning.\n",
            "Epoch [61/80] - Training:  70%|███████   | 220/313 [00:36<00:13,  7.08it/s][codecarbon INFO @ 02:26:46] Energy consumed for RAM : 0.005027 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:26:46] Energy consumed for all GPUs : 0.054324 kWh. Total GPU Power : 55.41212483226585 W\n",
            "[codecarbon INFO @ 02:26:46] Energy consumed for all CPUs : 0.045002 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:26:46] 0.104353 kWh of electricity used since the beginning.\n",
            "Epoch [61/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.16it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:27:01] Energy consumed for RAM : 0.005047 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:27:01] Energy consumed for all GPUs : 0.054552 kWh. Total GPU Power : 54.83785389370662 W\n",
            "[codecarbon INFO @ 02:27:01] Energy consumed for all CPUs : 0.045179 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:27:01] 0.104778 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [61/80], Train Loss: 0.2476, Train Acc: 91.33%, Val Loss: 0.4459, Val Acc: 85.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [62/80] - Training:   9%|▉         | 28/313 [00:04<00:40,  7.02it/s][codecarbon INFO @ 02:27:16] Energy consumed for RAM : 0.005067 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:27:16] Energy consumed for all GPUs : 0.054726 kWh. Total GPU Power : 41.68588997807627 W\n",
            "[codecarbon INFO @ 02:27:16] Energy consumed for all CPUs : 0.045357 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:27:16] 0.105149 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:27:16] 0.003784 g.CO2eq/s mean an estimation of 119.33315158231088 kg.CO2eq/year\n",
            "Epoch [62/80] - Training:  38%|███▊      | 120/313 [00:19<00:29,  6.62it/s][codecarbon INFO @ 02:27:31] Energy consumed for RAM : 0.005086 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:27:31] Energy consumed for all GPUs : 0.054950 kWh. Total GPU Power : 53.69649932178229 W\n",
            "[codecarbon INFO @ 02:27:31] Energy consumed for all CPUs : 0.045534 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:27:31] 0.105570 kWh of electricity used since the beginning.\n",
            "Epoch [62/80] - Training:  68%|██████▊   | 212/313 [00:34<00:13,  7.39it/s][codecarbon INFO @ 02:27:46] Energy consumed for RAM : 0.005106 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:27:46] Energy consumed for all GPUs : 0.055180 kWh. Total GPU Power : 55.174625324648126 W\n",
            "[codecarbon INFO @ 02:27:46] Energy consumed for all CPUs : 0.045711 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:27:46] 0.105997 kWh of electricity used since the beginning.\n",
            "Epoch [62/80] - Training:  97%|█████████▋| 304/313 [00:50<00:01,  6.82it/s][codecarbon INFO @ 02:28:01] Energy consumed for RAM : 0.005126 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:28:01] Energy consumed for all GPUs : 0.055405 kWh. Total GPU Power : 54.2645169443823 W\n",
            "[codecarbon INFO @ 02:28:01] Energy consumed for all CPUs : 0.045888 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:28:01] 0.106419 kWh of electricity used since the beginning.\n",
            "Epoch [62/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.13it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [62/80], Train Loss: 0.2441, Train Acc: 91.50%, Val Loss: 0.4423, Val Acc: 85.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [63/80] - Training:   7%|▋         | 21/313 [00:04<00:55,  5.22it/s][codecarbon INFO @ 02:28:16] Energy consumed for RAM : 0.005146 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:28:16] Energy consumed for all GPUs : 0.055590 kWh. Total GPU Power : 44.18078079342581 W\n",
            "[codecarbon INFO @ 02:28:16] Energy consumed for all CPUs : 0.046065 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:28:16] 0.106801 kWh of electricity used since the beginning.\n",
            "Epoch [63/80] - Training:  36%|███▌      | 113/313 [00:18<00:36,  5.46it/s][codecarbon INFO @ 02:28:31] Energy consumed for RAM : 0.005166 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [63/80] - Training:  36%|███▋      | 114/313 [00:19<00:37,  5.24it/s][codecarbon INFO @ 02:28:31] Energy consumed for all GPUs : 0.055819 kWh. Total GPU Power : 55.20128974710794 W\n",
            "[codecarbon INFO @ 02:28:31] Energy consumed for all CPUs : 0.046242 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:28:31] 0.107227 kWh of electricity used since the beginning.\n",
            "Epoch [63/80] - Training:  66%|██████▌   | 207/313 [00:34<00:20,  5.21it/s][codecarbon INFO @ 02:28:46] Energy consumed for RAM : 0.005185 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:28:46] Energy consumed for all GPUs : 0.056048 kWh. Total GPU Power : 54.84274741140107 W\n",
            "[codecarbon INFO @ 02:28:46] Energy consumed for all CPUs : 0.046419 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:28:46] 0.107653 kWh of electricity used since the beginning.\n",
            "Epoch [63/80] - Training:  96%|█████████▌| 299/313 [00:49<00:02,  4.89it/s][codecarbon INFO @ 02:29:01] Energy consumed for RAM : 0.005205 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:29:01] Energy consumed for all GPUs : 0.056274 kWh. Total GPU Power : 54.33153113552916 W\n",
            "[codecarbon INFO @ 02:29:01] Energy consumed for all CPUs : 0.046597 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:29:01] 0.108076 kWh of electricity used since the beginning.\n",
            "Epoch [63/80] - Training: 100%|██████████| 313/313 [00:51<00:00,  6.09it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [63/80], Train Loss: 0.2448, Train Acc: 91.33%, Val Loss: 0.4403, Val Acc: 85.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [64/80] - Training:   6%|▌         | 18/313 [00:04<01:05,  4.49it/s][codecarbon INFO @ 02:29:16] Energy consumed for RAM : 0.005225 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:29:16] Energy consumed for all GPUs : 0.056458 kWh. Total GPU Power : 43.98078261507513 W\n",
            "[codecarbon INFO @ 02:29:16] Energy consumed for all CPUs : 0.046774 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:29:16] 0.108457 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:29:16] 0.003820 g.CO2eq/s mean an estimation of 120.45978791396482 kg.CO2eq/year\n",
            "Epoch [64/80] - Training:  35%|███▍      | 108/313 [00:19<00:44,  4.61it/s][codecarbon INFO @ 02:29:31] Energy consumed for RAM : 0.005245 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:29:31] Energy consumed for all GPUs : 0.056677 kWh. Total GPU Power : 52.593366944870226 W\n",
            "[codecarbon INFO @ 02:29:31] Energy consumed for all CPUs : 0.046951 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:29:31] 0.108873 kWh of electricity used since the beginning.\n",
            "Epoch [64/80] - Training:  64%|██████▍   | 200/313 [00:34<00:25,  4.43it/s][codecarbon INFO @ 02:29:46] Energy consumed for RAM : 0.005265 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:29:46] Energy consumed for all GPUs : 0.056903 kWh. Total GPU Power : 54.2779390447922 W\n",
            "[codecarbon INFO @ 02:29:46] Energy consumed for all CPUs : 0.047128 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:29:46] 0.109296 kWh of electricity used since the beginning.\n",
            "Epoch [64/80] - Training:  92%|█████████▏| 289/313 [00:49<00:05,  4.72it/s][codecarbon INFO @ 02:30:01] Energy consumed for RAM : 0.005284 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:30:01] Energy consumed for all GPUs : 0.057129 kWh. Total GPU Power : 54.35327629120017 W\n",
            "[codecarbon INFO @ 02:30:01] Energy consumed for all CPUs : 0.047305 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:30:01] 0.109719 kWh of electricity used since the beginning.\n",
            "Epoch [64/80] - Training: 100%|██████████| 313/313 [00:53<00:00,  5.88it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [64/80], Train Loss: 0.2498, Train Acc: 91.37%, Val Loss: 0.4260, Val Acc: 86.30%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch [65/80] - Training:   0%|          | 0/313 [00:00<?, ?it/s][codecarbon INFO @ 02:30:16] Energy consumed for RAM : 0.005304 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:30:16] Energy consumed for all GPUs : 0.057297 kWh. Total GPU Power : 40.23619856414384 W\n",
            "[codecarbon INFO @ 02:30:16] Energy consumed for all CPUs : 0.047483 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:30:16] 0.110084 kWh of electricity used since the beginning.\n",
            "Epoch [65/80] - Training:  28%|██▊       | 87/313 [00:16<00:51,  4.40it/s][codecarbon INFO @ 02:30:31] Energy consumed for RAM : 0.005324 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:30:31] Energy consumed for all GPUs : 0.057515 kWh. Total GPU Power : 52.19081790922403 W\n",
            "[codecarbon INFO @ 02:30:31] Energy consumed for all CPUs : 0.047660 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:30:31] 0.110499 kWh of electricity used since the beginning.\n",
            "Epoch [65/80] - Training:  57%|█████▋    | 177/313 [00:31<00:29,  4.60it/s][codecarbon INFO @ 02:30:46] Energy consumed for RAM : 0.005344 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:30:46] Energy consumed for all GPUs : 0.057744 kWh. Total GPU Power : 54.989549772923716 W\n",
            "[codecarbon INFO @ 02:30:46] Energy consumed for all CPUs : 0.047838 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:30:46] 0.110925 kWh of electricity used since the beginning.\n",
            "Epoch [65/80] - Training:  86%|████████▌ | 268/313 [00:46<00:10,  4.44it/s][codecarbon INFO @ 02:31:01] Energy consumed for RAM : 0.005364 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:31:01] Energy consumed for all GPUs : 0.057975 kWh. Total GPU Power : 55.34585902630715 W\n",
            "[codecarbon INFO @ 02:31:01] Energy consumed for all CPUs : 0.048015 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:31:02] 0.111354 kWh of electricity used since the beginning.\n",
            "Epoch [65/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.91it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:31:16] Energy consumed for RAM : 0.005383 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:31:16] Energy consumed for all GPUs : 0.058167 kWh. Total GPU Power : 46.11732088032129 W\n",
            "[codecarbon INFO @ 02:31:16] Energy consumed for all CPUs : 0.048192 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:31:16] 0.111742 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:31:16] 0.003793 g.CO2eq/s mean an estimation of 119.61470028809393 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [65/80], Train Loss: 0.2418, Train Acc: 91.55%, Val Loss: 0.4330, Val Acc: 85.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [66/80] - Training:  23%|██▎       | 73/313 [00:12<00:55,  4.31it/s][codecarbon INFO @ 02:31:31] Energy consumed for RAM : 0.005403 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:31:31] Energy consumed for all GPUs : 0.058375 kWh. Total GPU Power : 50.108375262443175 W\n",
            "[codecarbon INFO @ 02:31:31] Energy consumed for all CPUs : 0.048369 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:31:31] 0.112148 kWh of electricity used since the beginning.\n",
            "Epoch [66/80] - Training:  53%|█████▎    | 165/313 [00:27<00:36,  4.06it/s][codecarbon INFO @ 02:31:46] Energy consumed for RAM : 0.005423 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:31:46] Energy consumed for all GPUs : 0.058599 kWh. Total GPU Power : 53.68770276304284 W\n",
            "[codecarbon INFO @ 02:31:46] Energy consumed for all CPUs : 0.048546 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:31:46] 0.112568 kWh of electricity used since the beginning.\n",
            "Epoch [66/80] - Training:  82%|████████▏ | 256/313 [00:42<00:13,  4.14it/s][codecarbon INFO @ 02:32:01] Energy consumed for RAM : 0.005443 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:32:02] Energy consumed for all GPUs : 0.058829 kWh. Total GPU Power : 55.22784370269841 W\n",
            "[codecarbon INFO @ 02:32:02] Energy consumed for all CPUs : 0.048723 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:32:02] 0.112995 kWh of electricity used since the beginning.\n",
            "Epoch [66/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.17it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:32:17] Energy consumed for RAM : 0.005463 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:32:17] Energy consumed for all GPUs : 0.059034 kWh. Total GPU Power : 49.038373430027 W\n",
            "[codecarbon INFO @ 02:32:17] Energy consumed for all CPUs : 0.048901 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:32:17] 0.113397 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [66/80], Train Loss: 0.2485, Train Acc: 91.36%, Val Loss: 0.4363, Val Acc: 85.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [67/80] - Training:  20%|██        | 63/313 [00:11<00:52,  4.79it/s][codecarbon INFO @ 02:32:32] Energy consumed for RAM : 0.005482 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:32:32] Energy consumed for all GPUs : 0.059231 kWh. Total GPU Power : 47.36354832695229 W\n",
            "[codecarbon INFO @ 02:32:32] Energy consumed for all CPUs : 0.049078 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:32:32] 0.113791 kWh of electricity used since the beginning.\n",
            "Epoch [67/80] - Training:  50%|████▉     | 155/313 [00:26<00:35,  4.51it/s][codecarbon INFO @ 02:32:47] Energy consumed for RAM : 0.005502 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:32:47] Energy consumed for all GPUs : 0.059455 kWh. Total GPU Power : 53.93533664812825 W\n",
            "[codecarbon INFO @ 02:32:47] Energy consumed for all CPUs : 0.049255 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:32:47] 0.114212 kWh of electricity used since the beginning.\n",
            "Epoch [67/80] - Training:  79%|███████▉  | 248/313 [00:41<00:13,  4.92it/s][codecarbon INFO @ 02:33:02] Energy consumed for RAM : 0.005522 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:33:02] Energy consumed for all GPUs : 0.059682 kWh. Total GPU Power : 54.378309398464694 W\n",
            "[codecarbon INFO @ 02:33:02] Energy consumed for all CPUs : 0.049432 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:33:02] 0.114636 kWh of electricity used since the beginning.\n",
            "Epoch [67/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.19it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:33:17] Energy consumed for RAM : 0.005542 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:33:17] Energy consumed for all GPUs : 0.059895 kWh. Total GPU Power : 51.286715889257295 W\n",
            "[codecarbon INFO @ 02:33:17] Energy consumed for all CPUs : 0.049609 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:33:17] 0.115046 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:33:17] 0.003817 g.CO2eq/s mean an estimation of 120.37770572394928 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [67/80], Train Loss: 0.2406, Train Acc: 91.74%, Val Loss: 0.4356, Val Acc: 85.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [68/80] - Training:  18%|█▊        | 57/313 [00:10<00:37,  6.83it/s][codecarbon INFO @ 02:33:32] Energy consumed for RAM : 0.005561 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:33:32] Energy consumed for all GPUs : 0.060089 kWh. Total GPU Power : 46.320910599706615 W\n",
            "[codecarbon INFO @ 02:33:32] Energy consumed for all CPUs : 0.049786 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:33:32] 0.115436 kWh of electricity used since the beginning.\n",
            "Epoch [68/80] - Training:  48%|████▊     | 150/313 [00:25<00:26,  6.19it/s][codecarbon INFO @ 02:33:47] Energy consumed for RAM : 0.005581 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:33:47] Energy consumed for all GPUs : 0.060317 kWh. Total GPU Power : 54.829285717724325 W\n",
            "[codecarbon INFO @ 02:33:47] Energy consumed for all CPUs : 0.049963 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:33:47] 0.115862 kWh of electricity used since the beginning.\n",
            "Epoch [68/80] - Training:  78%|███████▊  | 243/313 [00:40<00:10,  6.81it/s][codecarbon INFO @ 02:34:02] Energy consumed for RAM : 0.005601 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:34:02] Energy consumed for all GPUs : 0.060547 kWh. Total GPU Power : 55.30260206227121 W\n",
            "[codecarbon INFO @ 02:34:02] Energy consumed for all CPUs : 0.050141 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:34:02] 0.116289 kWh of electricity used since the beginning.\n",
            "Epoch [68/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.20it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:34:17] Energy consumed for RAM : 0.005621 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:34:17] Energy consumed for all GPUs : 0.060768 kWh. Total GPU Power : 53.05465375104043 W\n",
            "[codecarbon INFO @ 02:34:17] Energy consumed for all CPUs : 0.050318 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:34:17] 0.116707 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [68/80], Train Loss: 0.2398, Train Acc: 91.60%, Val Loss: 0.4429, Val Acc: 86.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [69/80] - Training:  18%|█▊        | 55/313 [00:10<00:35,  7.35it/s][codecarbon INFO @ 02:34:32] Energy consumed for RAM : 0.005641 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:34:32] Energy consumed for all GPUs : 0.060957 kWh. Total GPU Power : 45.21497717734546 W\n",
            "[codecarbon INFO @ 02:34:32] Energy consumed for all CPUs : 0.050495 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:34:32] 0.117092 kWh of electricity used since the beginning.\n",
            "Epoch [69/80] - Training:  48%|████▊     | 149/313 [00:25<00:23,  7.08it/s][codecarbon INFO @ 02:34:47] Energy consumed for RAM : 0.005660 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:34:47] Energy consumed for all GPUs : 0.061185 kWh. Total GPU Power : 54.86811631774603 W\n",
            "[codecarbon INFO @ 02:34:47] Energy consumed for all CPUs : 0.050672 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:34:47] 0.117518 kWh of electricity used since the beginning.\n",
            "Epoch [69/80] - Training:  76%|███████▌  | 238/313 [00:40<00:10,  7.11it/s][codecarbon INFO @ 02:35:02] Energy consumed for RAM : 0.005680 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:35:02] Energy consumed for all GPUs : 0.061408 kWh. Total GPU Power : 53.44632898069022 W\n",
            "[codecarbon INFO @ 02:35:02] Energy consumed for all CPUs : 0.050849 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:35:02] 0.117937 kWh of electricity used since the beginning.\n",
            "Epoch [69/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.96it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:35:17] Energy consumed for RAM : 0.005700 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:35:17] Energy consumed for all GPUs : 0.061632 kWh. Total GPU Power : 53.77357843074279 W\n",
            "[codecarbon INFO @ 02:35:17] Energy consumed for all CPUs : 0.051026 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:35:17] 0.118358 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:35:17] 0.003826 g.CO2eq/s mean an estimation of 120.65610700891361 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [69/80], Train Loss: 0.2375, Train Acc: 91.64%, Val Loss: 0.4393, Val Acc: 85.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [70/80] - Training:  13%|█▎        | 42/313 [00:09<00:40,  6.66it/s][codecarbon INFO @ 02:35:32] Energy consumed for RAM : 0.005720 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [70/80] - Training:  14%|█▎        | 43/313 [00:09<00:40,  6.68it/s][codecarbon INFO @ 02:35:32] Energy consumed for all GPUs : 0.061803 kWh. Total GPU Power : 41.12727823381962 W\n",
            "[codecarbon INFO @ 02:35:32] Energy consumed for all CPUs : 0.051204 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:35:32] 0.118727 kWh of electricity used since the beginning.\n",
            "Epoch [70/80] - Training:  43%|████▎     | 134/313 [00:24<00:24,  7.30it/s][codecarbon INFO @ 02:35:47] Energy consumed for RAM : 0.005740 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:35:47] Energy consumed for all GPUs : 0.062027 kWh. Total GPU Power : 53.83451509743162 W\n",
            "[codecarbon INFO @ 02:35:47] Energy consumed for all CPUs : 0.051381 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:35:47] 0.119147 kWh of electricity used since the beginning.\n",
            "Epoch [70/80] - Training:  73%|███████▎  | 227/313 [00:39<00:12,  7.04it/s][codecarbon INFO @ 02:36:02] Energy consumed for RAM : 0.005759 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:36:02] Energy consumed for all GPUs : 0.062253 kWh. Total GPU Power : 54.23982494798397 W\n",
            "[codecarbon INFO @ 02:36:02] Energy consumed for all CPUs : 0.051558 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:36:02] 0.119570 kWh of electricity used since the beginning.\n",
            "Epoch [70/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.94it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:36:17] Energy consumed for RAM : 0.005779 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:36:17] Energy consumed for all GPUs : 0.062485 kWh. Total GPU Power : 55.67936572975298 W\n",
            "[codecarbon INFO @ 02:36:17] Energy consumed for all CPUs : 0.051735 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:36:17] 0.119999 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [70/80], Train Loss: 0.2448, Train Acc: 91.51%, Val Loss: 0.4493, Val Acc: 85.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [71/80] - Training:  12%|█▏        | 36/313 [00:07<00:40,  6.77it/s][codecarbon INFO @ 02:36:32] Energy consumed for RAM : 0.005799 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:36:32] Energy consumed for all GPUs : 0.062655 kWh. Total GPU Power : 40.91173532637257 W\n",
            "[codecarbon INFO @ 02:36:32] Energy consumed for all CPUs : 0.051912 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:36:32] 0.120366 kWh of electricity used since the beginning.\n",
            "Epoch [71/80] - Training:  42%|████▏     | 130/313 [00:22<00:24,  7.62it/s][codecarbon INFO @ 02:36:47] Energy consumed for RAM : 0.005819 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [71/80] - Training:  42%|████▏     | 131/313 [00:22<00:24,  7.29it/s][codecarbon INFO @ 02:36:47] Energy consumed for all GPUs : 0.062882 kWh. Total GPU Power : 54.45193509576639 W\n",
            "[codecarbon INFO @ 02:36:47] Energy consumed for all CPUs : 0.052089 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:36:47] 0.120791 kWh of electricity used since the beginning.\n",
            "Epoch [71/80] - Training:  71%|███████   | 221/313 [00:37<00:12,  7.49it/s][codecarbon INFO @ 02:37:02] Energy consumed for RAM : 0.005839 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:37:02] Energy consumed for all GPUs : 0.063108 kWh. Total GPU Power : 54.14096487477491 W\n",
            "[codecarbon INFO @ 02:37:02] Energy consumed for all CPUs : 0.052266 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:37:02] 0.121212 kWh of electricity used since the beginning.\n",
            "Epoch [71/80] - Training: 100%|██████████| 313/313 [00:52<00:00,  5.99it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:37:17] Energy consumed for RAM : 0.005858 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:37:17] Energy consumed for all GPUs : 0.063336 kWh. Total GPU Power : 54.781037637172595 W\n",
            "[codecarbon INFO @ 02:37:17] Energy consumed for all CPUs : 0.052444 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:37:17] 0.121638 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:37:17] 0.003788 g.CO2eq/s mean an estimation of 119.46367358460137 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [71/80], Train Loss: 0.2366, Train Acc: 91.81%, Val Loss: 0.4339, Val Acc: 85.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [72/80] - Training:  10%|█         | 32/313 [00:06<00:40,  6.98it/s][codecarbon INFO @ 02:37:32] Energy consumed for RAM : 0.005878 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:37:32] Energy consumed for all GPUs : 0.063506 kWh. Total GPU Power : 40.69051692512433 W\n",
            "[codecarbon INFO @ 02:37:32] Energy consumed for all CPUs : 0.052621 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:37:32] 0.122005 kWh of electricity used since the beginning.\n",
            "Epoch [72/80] - Training:  41%|████      | 128/313 [00:21<00:24,  7.62it/s][codecarbon INFO @ 02:37:47] Energy consumed for RAM : 0.005898 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:37:47] Energy consumed for all GPUs : 0.063735 kWh. Total GPU Power : 55.067610583514885 W\n",
            "[codecarbon INFO @ 02:37:47] Energy consumed for all CPUs : 0.052798 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:37:47] 0.122431 kWh of electricity used since the beginning.\n",
            "Epoch [72/80] - Training:  71%|███████   | 221/313 [00:36<00:13,  6.87it/s][codecarbon INFO @ 02:38:02] Energy consumed for RAM : 0.005918 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:38:02] Energy consumed for all GPUs : 0.063966 kWh. Total GPU Power : 55.53619744369526 W\n",
            "[codecarbon INFO @ 02:38:02] Energy consumed for all CPUs : 0.052975 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:38:02] 0.122859 kWh of electricity used since the beginning.\n",
            "Epoch [72/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.16it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:38:17] Energy consumed for RAM : 0.005938 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:38:17] Energy consumed for all GPUs : 0.064195 kWh. Total GPU Power : 54.833998910770575 W\n",
            "[codecarbon INFO @ 02:38:17] Energy consumed for all CPUs : 0.053152 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:38:17] 0.123284 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [72/80], Train Loss: 0.2443, Train Acc: 91.39%, Val Loss: 0.4418, Val Acc: 85.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [73/80] - Training:  11%|█         | 35/313 [00:06<00:39,  7.01it/s][codecarbon INFO @ 02:38:32] Energy consumed for RAM : 0.005957 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:38:32] Energy consumed for all GPUs : 0.064379 kWh. Total GPU Power : 44.41187743292014 W\n",
            "[codecarbon INFO @ 02:38:32] Energy consumed for all CPUs : 0.053329 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:38:32] 0.123666 kWh of electricity used since the beginning.\n",
            "Epoch [73/80] - Training:  41%|████      | 127/313 [00:21<00:27,  6.85it/s][codecarbon INFO @ 02:38:47] Energy consumed for RAM : 0.005977 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:38:47] Energy consumed for all GPUs : 0.064609 kWh. Total GPU Power : 55.217714692838506 W\n",
            "[codecarbon INFO @ 02:38:47] Energy consumed for all CPUs : 0.053506 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:38:47] 0.124092 kWh of electricity used since the beginning.\n",
            "Epoch [73/80] - Training:  71%|███████   | 221/313 [00:36<00:13,  6.97it/s][codecarbon INFO @ 02:39:02] Energy consumed for RAM : 0.005997 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:39:02] Energy consumed for all GPUs : 0.064841 kWh. Total GPU Power : 55.65008749707988 W\n",
            "[codecarbon INFO @ 02:39:02] Energy consumed for all CPUs : 0.053683 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:39:02] 0.124521 kWh of electricity used since the beginning.\n",
            "Epoch [73/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.17it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:39:17] Energy consumed for RAM : 0.006017 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:39:17] Energy consumed for all GPUs : 0.065071 kWh. Total GPU Power : 55.26154262391213 W\n",
            "[codecarbon INFO @ 02:39:17] Energy consumed for all CPUs : 0.053860 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:39:17] 0.124948 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:39:17] 0.003824 g.CO2eq/s mean an estimation of 120.59465907778642 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [73/80], Train Loss: 0.2396, Train Acc: 91.70%, Val Loss: 0.4328, Val Acc: 86.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [74/80] - Training:  10%|▉         | 30/313 [00:05<00:38,  7.31it/s][codecarbon INFO @ 02:39:32] Energy consumed for RAM : 0.006036 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:39:32] Energy consumed for all GPUs : 0.065249 kWh. Total GPU Power : 42.85745043110066 W\n",
            "[codecarbon INFO @ 02:39:32] Energy consumed for all CPUs : 0.054037 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:39:32] 0.125323 kWh of electricity used since the beginning.\n",
            "Epoch [74/80] - Training:  40%|███▉      | 124/313 [00:20<00:26,  7.05it/s][codecarbon INFO @ 02:39:47] Energy consumed for RAM : 0.006056 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:39:47] Energy consumed for all GPUs : 0.065475 kWh. Total GPU Power : 53.951239324668215 W\n",
            "[codecarbon INFO @ 02:39:47] Energy consumed for all CPUs : 0.054215 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:39:47] 0.125746 kWh of electricity used since the beginning.\n",
            "Epoch [74/80] - Training:  70%|██████▉   | 219/313 [00:35<00:13,  6.93it/s][codecarbon INFO @ 02:40:02] Energy consumed for RAM : 0.006076 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:40:02] Energy consumed for all GPUs : 0.065704 kWh. Total GPU Power : 55.19171961802378 W\n",
            "[codecarbon INFO @ 02:40:02] Energy consumed for all CPUs : 0.054392 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:40:02] 0.126172 kWh of electricity used since the beginning.\n",
            "Epoch [74/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.26it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:40:17] Energy consumed for RAM : 0.006096 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:40:17] Energy consumed for all GPUs : 0.065934 kWh. Total GPU Power : 54.97383900768035 W\n",
            "[codecarbon INFO @ 02:40:17] Energy consumed for all CPUs : 0.054569 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:40:17] 0.126598 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [74/80], Train Loss: 0.2395, Train Acc: 91.77%, Val Loss: 0.4227, Val Acc: 86.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [75/80] - Training:   9%|▊         | 27/313 [00:04<00:41,  6.83it/s][codecarbon INFO @ 02:40:32] Energy consumed for RAM : 0.006116 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:40:32] Energy consumed for all GPUs : 0.066106 kWh. Total GPU Power : 41.33815028959648 W\n",
            "[codecarbon INFO @ 02:40:32] Energy consumed for all CPUs : 0.054747 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:40:32] 0.126968 kWh of electricity used since the beginning.\n",
            "Epoch [75/80] - Training:  39%|███▊      | 121/313 [00:19<00:28,  6.70it/s][codecarbon INFO @ 02:40:47] Energy consumed for RAM : 0.006135 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:40:47] Energy consumed for all GPUs : 0.066333 kWh. Total GPU Power : 54.56010899662124 W\n",
            "[codecarbon INFO @ 02:40:47] Energy consumed for all CPUs : 0.054923 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:40:47] 0.127392 kWh of electricity used since the beginning.\n",
            "Epoch [75/80] - Training:  68%|██████▊   | 213/313 [00:34<00:14,  6.99it/s][codecarbon INFO @ 02:41:02] Energy consumed for RAM : 0.006155 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:41:02] Energy consumed for all GPUs : 0.066566 kWh. Total GPU Power : 55.94877139442794 W\n",
            "[codecarbon INFO @ 02:41:02] Energy consumed for all CPUs : 0.055101 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:41:02] 0.127822 kWh of electricity used since the beginning.\n",
            "Epoch [75/80] - Training:  98%|█████████▊| 307/313 [00:49<00:00,  8.33it/s][codecarbon INFO @ 02:41:17] Energy consumed for RAM : 0.006175 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:41:17] Energy consumed for all GPUs : 0.066802 kWh. Total GPU Power : 56.69635736923393 W\n",
            "[codecarbon INFO @ 02:41:17] Energy consumed for all CPUs : 0.055278 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:41:17] 0.128255 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:41:17] 0.003820 g.CO2eq/s mean an estimation of 120.46450267779514 kg.CO2eq/year\n",
            "Epoch [75/80] - Training: 100%|██████████| 313/313 [00:50<00:00,  6.20it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [75/80], Train Loss: 0.2369, Train Acc: 91.76%, Val Loss: 0.4327, Val Acc: 85.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [76/80] - Training:   7%|▋         | 23/313 [00:04<00:45,  6.38it/s][codecarbon INFO @ 02:41:32] Energy consumed for RAM : 0.006195 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:41:32] Energy consumed for all GPUs : 0.066985 kWh. Total GPU Power : 43.81669979830647 W\n",
            "[codecarbon INFO @ 02:41:32] Energy consumed for all CPUs : 0.055455 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:41:32] 0.128634 kWh of electricity used since the beginning.\n",
            "Epoch [76/80] - Training:  38%|███▊      | 118/313 [00:19<00:26,  7.38it/s][codecarbon INFO @ 02:41:47] Energy consumed for RAM : 0.006215 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:41:47] Energy consumed for all GPUs : 0.067216 kWh. Total GPU Power : 55.45847884828982 W\n",
            "[codecarbon INFO @ 02:41:47] Energy consumed for all CPUs : 0.055632 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:41:47] 0.129062 kWh of electricity used since the beginning.\n",
            "Epoch [76/80] - Training:  68%|██████▊   | 212/313 [00:34<00:12,  7.92it/s][codecarbon INFO @ 02:42:02] Energy consumed for RAM : 0.006234 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:42:02] Energy consumed for all GPUs : 0.067449 kWh. Total GPU Power : 56.16074886851873 W\n",
            "Epoch [76/80] - Training:  68%|██████▊   | 213/313 [00:34<00:13,  7.68it/s][codecarbon INFO @ 02:42:02] Energy consumed for all CPUs : 0.055809 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:42:02] 0.129492 kWh of electricity used since the beginning.\n",
            "Epoch [76/80] - Training:  99%|█████████▊| 309/313 [00:49<00:00,  9.70it/s][codecarbon INFO @ 02:42:17] Energy consumed for RAM : 0.006254 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:42:17] Energy consumed for all GPUs : 0.067680 kWh. Total GPU Power : 55.31697133317447 W\n",
            "[codecarbon INFO @ 02:42:17] Energy consumed for all CPUs : 0.055986 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:42:17] 0.129920 kWh of electricity used since the beginning.\n",
            "Epoch [76/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.31it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [76/80], Train Loss: 0.2383, Train Acc: 91.79%, Val Loss: 0.4289, Val Acc: 86.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [77/80] - Training:   8%|▊         | 25/313 [00:04<00:41,  6.95it/s][codecarbon INFO @ 02:42:32] Energy consumed for RAM : 0.006274 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:42:32] Energy consumed for all GPUs : 0.067860 kWh. Total GPU Power : 43.23275966508035 W\n",
            "[codecarbon INFO @ 02:42:32] Energy consumed for all CPUs : 0.056163 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:42:32] 0.130297 kWh of electricity used since the beginning.\n",
            "Epoch [77/80] - Training:  39%|███▊      | 121/313 [00:19<00:27,  6.98it/s][codecarbon INFO @ 02:42:47] Energy consumed for RAM : 0.006294 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:42:47] Energy consumed for all GPUs : 0.068092 kWh. Total GPU Power : 55.751454595538235 W\n",
            "[codecarbon INFO @ 02:42:47] Energy consumed for all CPUs : 0.056340 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:42:47] 0.130726 kWh of electricity used since the beginning.\n",
            "Epoch [77/80] - Training:  69%|██████▉   | 216/313 [00:34<00:14,  6.68it/s][codecarbon INFO @ 02:43:02] Energy consumed for RAM : 0.006314 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:43:02] Energy consumed for all GPUs : 0.068324 kWh. Total GPU Power : 55.60828592324948 W\n",
            "[codecarbon INFO @ 02:43:02] Energy consumed for all CPUs : 0.056517 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:43:02] 0.131154 kWh of electricity used since the beginning.\n",
            "Epoch [77/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.36it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:43:17] Energy consumed for RAM : 0.006333 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:43:17] Energy consumed for all GPUs : 0.068556 kWh. Total GPU Power : 55.86137252694358 W\n",
            "[codecarbon INFO @ 02:43:17] Energy consumed for all CPUs : 0.056694 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:43:17] 0.131584 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:43:17] 0.003846 g.CO2eq/s mean an estimation of 121.3024606982146 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [77/80], Train Loss: 0.2377, Train Acc: 91.89%, Val Loss: 0.4349, Val Acc: 85.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [78/80] - Training:  10%|▉         | 30/313 [00:05<00:48,  5.79it/s][codecarbon INFO @ 02:43:32] Energy consumed for RAM : 0.006353 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:43:32] Energy consumed for all GPUs : 0.068738 kWh. Total GPU Power : 43.490432019728935 W\n",
            "[codecarbon INFO @ 02:43:32] Energy consumed for all CPUs : 0.056872 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:43:32] 0.131963 kWh of electricity used since the beginning.\n",
            "Epoch [78/80] - Training:  40%|███▉      | 125/313 [00:20<00:33,  5.67it/s][codecarbon INFO @ 02:43:47] Energy consumed for RAM : 0.006373 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:43:47] Energy consumed for all GPUs : 0.068966 kWh. Total GPU Power : 54.81602259347315 W\n",
            "[codecarbon INFO @ 02:43:47] Energy consumed for all CPUs : 0.057049 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:43:47] 0.132389 kWh of electricity used since the beginning.\n",
            "Epoch [78/80] - Training:  70%|███████   | 220/313 [00:35<00:17,  5.34it/s][codecarbon INFO @ 02:44:02] Energy consumed for RAM : 0.006393 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:44:02] Energy consumed for all GPUs : 0.069198 kWh. Total GPU Power : 55.512052745762084 W\n",
            "[codecarbon INFO @ 02:44:02] Energy consumed for all CPUs : 0.057227 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:44:02] 0.132817 kWh of electricity used since the beginning.\n",
            "Epoch [78/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.35it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:44:17] Energy consumed for RAM : 0.006413 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:44:17] Energy consumed for all GPUs : 0.069430 kWh. Total GPU Power : 55.63998865007404 W\n",
            "[codecarbon INFO @ 02:44:17] Energy consumed for all CPUs : 0.057404 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:44:17] 0.133246 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [78/80], Train Loss: 0.2408, Train Acc: 91.62%, Val Loss: 0.4416, Val Acc: 85.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [79/80] - Training:  10%|▉         | 31/313 [00:05<00:54,  5.18it/s][codecarbon INFO @ 02:44:32] Energy consumed for RAM : 0.006432 kWh. RAM Power : 4.7530388832092285 W\n",
            "Epoch [79/80] - Training:  10%|█         | 32/313 [00:05<00:57,  4.91it/s][codecarbon INFO @ 02:44:32] Energy consumed for all GPUs : 0.069606 kWh. Total GPU Power : 42.49344338239711 W\n",
            "[codecarbon INFO @ 02:44:32] Energy consumed for all CPUs : 0.057581 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:44:32] 0.133619 kWh of electricity used since the beginning.\n",
            "Epoch [79/80] - Training:  40%|████      | 126/313 [00:20<00:39,  4.76it/s][codecarbon INFO @ 02:44:47] Energy consumed for RAM : 0.006452 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:44:47] Energy consumed for all GPUs : 0.069836 kWh. Total GPU Power : 55.19287239147934 W\n",
            "[codecarbon INFO @ 02:44:47] Energy consumed for all CPUs : 0.057758 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:44:47] 0.134047 kWh of electricity used since the beginning.\n",
            "Epoch [79/80] - Training:  71%|███████   | 221/313 [00:35<00:17,  5.14it/s][codecarbon INFO @ 02:45:02] Energy consumed for RAM : 0.006472 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:45:02] Energy consumed for all GPUs : 0.070068 kWh. Total GPU Power : 55.445824431763036 W\n",
            "[codecarbon INFO @ 02:45:02] Energy consumed for all CPUs : 0.057935 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:45:02] 0.134475 kWh of electricity used since the beginning.\n",
            "Epoch [79/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.30it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:45:17] Energy consumed for RAM : 0.006492 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:45:17] Energy consumed for all GPUs : 0.070298 kWh. Total GPU Power : 55.26342350955145 W\n",
            "[codecarbon INFO @ 02:45:17] Energy consumed for all CPUs : 0.058112 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:45:17] 0.134902 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:45:17] 0.003830 g.CO2eq/s mean an estimation of 120.77355923711463 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [79/80], Train Loss: 0.2346, Train Acc: 91.99%, Val Loss: 0.4328, Val Acc: 86.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [80/80] - Training:  11%|█         | 33/313 [00:06<00:58,  4.75it/s][codecarbon INFO @ 02:45:32] Energy consumed for RAM : 0.006511 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:45:32] Energy consumed for all GPUs : 0.070479 kWh. Total GPU Power : 43.56424785606477 W\n",
            "[codecarbon INFO @ 02:45:32] Energy consumed for all CPUs : 0.058290 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:45:32] 0.135280 kWh of electricity used since the beginning.\n",
            "Epoch [80/80] - Training:  41%|████      | 129/313 [00:21<00:41,  4.39it/s][codecarbon INFO @ 02:45:47] Energy consumed for RAM : 0.006531 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:45:47] Energy consumed for all GPUs : 0.070706 kWh. Total GPU Power : 54.470039148762865 W\n",
            "[codecarbon INFO @ 02:45:47] Energy consumed for all CPUs : 0.058467 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:45:47] 0.135705 kWh of electricity used since the beginning.\n",
            "Epoch [80/80] - Training:  72%|███████▏  | 224/313 [00:36<00:18,  4.87it/s][codecarbon INFO @ 02:46:02] Energy consumed for RAM : 0.006551 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:46:02] Energy consumed for all GPUs : 0.070936 kWh. Total GPU Power : 55.06749254638658 W\n",
            "[codecarbon INFO @ 02:46:02] Energy consumed for all CPUs : 0.058644 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:46:02] 0.136132 kWh of electricity used since the beginning.\n",
            "Epoch [80/80] - Training: 100%|██████████| 313/313 [00:49<00:00,  6.29it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 02:46:17] Energy consumed for RAM : 0.006571 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:46:17] Energy consumed for all GPUs : 0.071172 kWh. Total GPU Power : 56.52147736021275 W\n",
            "[codecarbon INFO @ 02:46:17] Energy consumed for all CPUs : 0.058822 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:46:17] 0.136564 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 02:46:25] Energy consumed for RAM : 0.006581 kWh. RAM Power : 4.7530388832092285 W\n",
            "[codecarbon INFO @ 02:46:25] Energy consumed for all GPUs : 0.071251 kWh. Total GPU Power : 36.22123589516555 W\n",
            "[codecarbon INFO @ 02:46:25] Energy consumed for all CPUs : 0.058915 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 02:46:25] 0.136747 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [80/80], Train Loss: 0.2417, Train Acc: 91.62%, Val Loss: 0.4384, Val Acc: 85.78%\n",
            "\n",
            "--- Model Analysis ---\n",
            "Parameter Count: 23528522\n",
            "Model Size: 90.06 MB\n",
            "FLOPs: 0.08 GFLOPs\n",
            "Training Time: 4993.14 seconds\n",
            "Average Inference Time: 0.005944 seconds\n",
            "\n",
            "--- Energy and Emissions Report ---\n",
            "CO2 Emissions: 0.018974 kg\n",
            "Average GPU Power Consumption: 59.58 W\n",
            "Total GPU Energy Consumption: 1491.906710 kWh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test dataset\n",
        "teacher_model.eval()\n",
        "correct_test, total_test = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = teacher_model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "        total_test += labels.size(0)\n",
        "\n",
        "test_accuracy = 100 * correct_test / total_test\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU6dnv7dtFOZ",
        "outputId": "b002fa30-8739-4705-e0b9-c8df8e63da33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 88.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plot loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "483VOROztlKT",
        "outputId": "5596f8ea-8b53-41af-f12e-7f828062bb32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6NDz3zUtpZA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}