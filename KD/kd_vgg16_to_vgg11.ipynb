{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kphlI_nRNb7i",
        "outputId": "2adcc649-f3ff-47be-c211-2e2668449afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: codecarbon in /usr/local/lib/python3.10/dist-packages (2.7.4)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from codecarbon) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon) (8.1.7)\n",
            "Requirement already satisfied: fief-client[cli] in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.2.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon) (9.0.0)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from codecarbon) (11.5.3)\n",
            "Requirement already satisfied: questionary in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.0.1)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from codecarbon) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.32.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from codecarbon) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.9.0.20241003)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (0.27.2)\n",
            "Requirement already satisfied: jwcrypto<2.0.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (1.5.6)\n",
            "Requirement already satisfied: yaspin in /usr/local/lib/python3.10/dist-packages (from fief-client[cli]->codecarbon) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (1.26.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2024.2)\n",
            "Requirement already satisfied: prompt_toolkit<=3.0.36,>=2.0 in /usr/local/lib/python3.10/dist-packages (from questionary->codecarbon) (3.0.36)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->codecarbon) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->codecarbon) (1.5.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (0.14.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.10/dist-packages (from jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (43.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->codecarbon) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt_toolkit<=3.0.36,>=2.0->questionary->codecarbon) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
            "Requirement already satisfied: termcolor<2.4.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from yaspin->fief-client[cli]->codecarbon) (2.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (1.17.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.21.3->fief-client[cli]->codecarbon) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto<2.0.0,>=1.4->fief-client[cli]->codecarbon) (2.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install codecarbon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTaxkqsltpRz",
        "outputId": "0b0991d7-9096-4f73-9d15-fd22bcd7051f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzB2k71JpRpK",
        "outputId": "a9d4942e-46ad-445f-e94d-0620f553f8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 29.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 40000\n",
            "Validation set size: 10000\n",
            "Test set size: 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 156MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 21:21:28] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 21:21:28] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 21:21:28] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 21:21:28] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 21:21:28] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 21:21:29] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 21:21:29] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 21:21:29] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 21:21:29]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 21:21:29]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 21:21:29]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 21:21:29]   Available RAM : 12.675 GB\n",
            "[codecarbon INFO @ 21:21:29]   CPU count: 2\n",
            "[codecarbon INFO @ 21:21:29]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 21:21:29]   GPU count: 1\n",
            "[codecarbon INFO @ 21:21:29]   GPU model: 1 x Tesla T4\n",
            "[codecarbon INFO @ 21:21:30] Saving emissions data to file /content/emissions.csv\n",
            "Epoch 1/30 - Training:   0%|          | 0/625 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/30 - Training:  21%|██▏       | 133/625 [00:14<00:44, 11.10it/s][codecarbon INFO @ 21:21:45] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:21:45] Energy consumed for all GPUs : 0.000235 kWh. Total GPU Power : 56.18816926215433 W\n",
            "[codecarbon INFO @ 21:21:45] Energy consumed for all CPUs : 0.000178 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:21:45] 0.000432 kWh of electricity used since the beginning.\n",
            "Epoch 1/30 - Training:  45%|████▍     | 281/625 [00:29<00:31, 10.99it/s][codecarbon INFO @ 21:22:00] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:22:00] Energy consumed for all GPUs : 0.000489 kWh. Total GPU Power : 61.34177360821846 W\n",
            "[codecarbon INFO @ 21:22:00] Energy consumed for all CPUs : 0.000355 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:22:00] 0.000883 kWh of electricity used since the beginning.\n",
            "Epoch 1/30 - Training:  63%|██████▎   | 392/625 [00:44<00:24,  9.67it/s][codecarbon INFO @ 21:22:15] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:22:15] Energy consumed for all GPUs : 0.000723 kWh. Total GPU Power : 56.075861118090316 W\n",
            "[codecarbon INFO @ 21:22:15] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:22:15] 0.001313 kWh of electricity used since the beginning.\n",
            "Epoch 1/30 - Training:  87%|████████▋ | 542/625 [00:59<00:08,  9.98it/s][codecarbon INFO @ 21:22:30] Energy consumed for RAM : 0.000079 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:22:30] Energy consumed for all GPUs : 0.000984 kWh. Total GPU Power : 62.689415783327746 W\n",
            "[codecarbon INFO @ 21:22:30] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:22:30] 0.001771 kWh of electricity used since the beginning.\n",
            "Epoch 1/30 - Training: 100%|██████████| 625/625 [01:08<00:00,  9.09it/s]\n",
            "Epoch 1/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/30 - Validation:  63%|██████▎   | 99/157 [00:06<00:03, 15.23it/s][codecarbon INFO @ 21:22:45] Energy consumed for RAM : 0.000099 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:22:45] Energy consumed for all GPUs : 0.001211 kWh. Total GPU Power : 54.4541942903843 W\n",
            "[codecarbon INFO @ 21:22:45] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:22:45] 0.002196 kWh of electricity used since the beginning.\n",
            "Epoch 1/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Train Loss: 1.3559, Train Accuracy: 52.44%\n",
            "Epoch [1/30], Val Loss: 1.0245, Val Accuracy: 66.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training:  15%|█▍        | 93/625 [00:09<00:58,  9.15it/s][codecarbon INFO @ 21:23:00] Energy consumed for RAM : 0.000119 kWh. RAM Power : 4.753036022186279 W\n",
            "Epoch 2/30 - Training:  15%|█▌        | 94/625 [00:09<01:01,  8.59it/s][codecarbon INFO @ 21:23:00] Energy consumed for all GPUs : 0.001433 kWh. Total GPU Power : 53.44364452085457 W\n",
            "[codecarbon INFO @ 21:23:00] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:23:00] 0.002615 kWh of electricity used since the beginning.\n",
            "Epoch 2/30 - Training:  38%|███▊      | 240/625 [00:24<00:49,  7.71it/s][codecarbon INFO @ 21:23:15] Energy consumed for RAM : 0.000138 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:23:15] Energy consumed for all GPUs : 0.001699 kWh. Total GPU Power : 63.965578723097316 W\n",
            "[codecarbon INFO @ 21:23:15] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:23:15] 0.003078 kWh of electricity used since the beginning.\n",
            "Epoch 2/30 - Training:  61%|██████    | 380/625 [00:39<00:49,  4.99it/s][codecarbon INFO @ 21:23:30] Energy consumed for RAM : 0.000158 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:23:30] Energy consumed for all GPUs : 0.001965 kWh. Total GPU Power : 63.90988542291426 W\n",
            "[codecarbon INFO @ 21:23:30] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:23:30] 0.003541 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:23:30] 0.007889 g.CO2eq/s mean an estimation of 248.78041100642548 kg.CO2eq/year\n",
            "Epoch 2/30 - Training:  84%|████████▍ | 528/625 [00:54<00:12,  8.04it/s][codecarbon INFO @ 21:23:45] Energy consumed for RAM : 0.000178 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:23:45] Energy consumed for all GPUs : 0.002236 kWh. Total GPU Power : 64.83596618195945 W\n",
            "[codecarbon INFO @ 21:23:45] Energy consumed for all CPUs : 0.001595 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:23:45] 0.004008 kWh of electricity used since the beginning.\n",
            "Epoch 2/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.74it/s]\n",
            "Epoch 2/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 2/30 - Validation:  44%|████▍     | 69/157 [00:05<00:07, 11.48it/s][codecarbon INFO @ 21:24:00] Energy consumed for RAM : 0.000198 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:24:00] Energy consumed for all GPUs : 0.002477 kWh. Total GPU Power : 58.03537692567506 W\n",
            "[codecarbon INFO @ 21:24:00] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:24:00] 0.004446 kWh of electricity used since the beginning.\n",
            "Epoch 2/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30], Train Loss: 0.8584, Train Accuracy: 72.26%\n",
            "Epoch [2/30], Val Loss: 0.8070, Val Accuracy: 73.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training:  14%|█▎        | 85/625 [00:09<01:08,  7.90it/s][codecarbon INFO @ 21:24:15] Energy consumed for RAM : 0.000218 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:24:15] Energy consumed for all GPUs : 0.002698 kWh. Total GPU Power : 52.94810984434628 W\n",
            "[codecarbon INFO @ 21:24:15] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:24:15] 0.004864 kWh of electricity used since the beginning.\n",
            "Epoch 3/30 - Training:  37%|███▋      | 232/625 [00:24<00:48,  8.05it/s][codecarbon INFO @ 21:24:30] Energy consumed for RAM : 0.000237 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:24:30] Energy consumed for all GPUs : 0.002965 kWh. Total GPU Power : 64.09951096983039 W\n",
            "[codecarbon INFO @ 21:24:30] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:24:30] 0.005328 kWh of electricity used since the beginning.\n",
            "Epoch 3/30 - Training:  60%|██████    | 378/625 [00:38<00:29,  8.39it/s][codecarbon INFO @ 21:24:45] Energy consumed for RAM : 0.000257 kWh. RAM Power : 4.753036022186279 W\n",
            "Epoch 3/30 - Training:  61%|██████    | 379/625 [00:39<00:31,  7.77it/s][codecarbon INFO @ 21:24:45] Energy consumed for all GPUs : 0.003232 kWh. Total GPU Power : 64.28239846879892 W\n",
            "[codecarbon INFO @ 21:24:45] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:24:45] 0.005793 kWh of electricity used since the beginning.\n",
            "Epoch 3/30 - Training:  84%|████████▍ | 524/625 [00:53<00:12,  7.80it/s][codecarbon INFO @ 21:25:00] Energy consumed for RAM : 0.000277 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:25:00] Energy consumed for all GPUs : 0.003502 kWh. Total GPU Power : 64.87026084437592 W\n",
            "[codecarbon INFO @ 21:25:00] Energy consumed for all CPUs : 0.002480 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:25:00] 0.006259 kWh of electricity used since the beginning.\n",
            "Epoch 3/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.80it/s]\n",
            "Epoch 3/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 3/30 - Validation:  39%|███▉      | 61/157 [00:05<00:10,  9.35it/s][codecarbon INFO @ 21:25:15] Energy consumed for RAM : 0.000297 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:25:15] Energy consumed for all GPUs : 0.003741 kWh. Total GPU Power : 57.37132212391019 W\n",
            "[codecarbon INFO @ 21:25:15] Energy consumed for all CPUs : 0.002657 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:25:15] 0.006695 kWh of electricity used since the beginning.\n",
            "Epoch 3/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30], Train Loss: 0.7116, Train Accuracy: 76.84%\n",
            "Epoch [3/30], Val Loss: 0.7199, Val Accuracy: 76.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training:  13%|█▎        | 80/625 [00:08<01:09,  7.86it/s][codecarbon INFO @ 21:25:30] Energy consumed for RAM : 0.000317 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:25:30] Energy consumed for all GPUs : 0.003962 kWh. Total GPU Power : 53.21832670406298 W\n",
            "[codecarbon INFO @ 21:25:30] Energy consumed for all CPUs : 0.002834 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:25:30] 0.007113 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:25:30] 0.007960 g.CO2eq/s mean an estimation of 251.03530977335495 kg.CO2eq/year\n",
            "Epoch 4/30 - Training:  37%|███▋      | 229/625 [00:23<00:51,  7.69it/s][codecarbon INFO @ 21:25:45] Energy consumed for RAM : 0.000336 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:25:45] Energy consumed for all GPUs : 0.004231 kWh. Total GPU Power : 64.67640777984005 W\n",
            "[codecarbon INFO @ 21:25:45] Energy consumed for all CPUs : 0.003011 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:25:45] 0.007579 kWh of electricity used since the beginning.\n",
            "Epoch 4/30 - Training:  60%|██████    | 378/625 [00:38<00:32,  7.71it/s][codecarbon INFO @ 21:26:00] Energy consumed for RAM : 0.000356 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:26:00] Energy consumed for all GPUs : 0.004504 kWh. Total GPU Power : 65.2916099449359 W\n",
            "[codecarbon INFO @ 21:26:00] Energy consumed for all CPUs : 0.003188 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:26:00] 0.008048 kWh of electricity used since the beginning.\n",
            "Epoch 4/30 - Training:  84%|████████▍ | 527/625 [00:53<00:10,  9.36it/s][codecarbon INFO @ 21:26:15] Energy consumed for RAM : 0.000376 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:26:15] Energy consumed for all GPUs : 0.004773 kWh. Total GPU Power : 64.57290214428419 W\n",
            "[codecarbon INFO @ 21:26:15] Energy consumed for all CPUs : 0.003366 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:26:15] 0.008514 kWh of electricity used since the beginning.\n",
            "Epoch 4/30 - Training: 100%|██████████| 625/625 [01:02<00:00,  9.93it/s]\n",
            "Epoch 4/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 4/30 - Validation:  39%|███▉      | 62/157 [00:05<00:07, 11.90it/s][codecarbon INFO @ 21:26:30] Energy consumed for RAM : 0.000396 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:26:30] Energy consumed for all GPUs : 0.005008 kWh. Total GPU Power : 56.61545250971863 W\n",
            "[codecarbon INFO @ 21:26:30] Energy consumed for all CPUs : 0.003543 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:26:30] 0.008947 kWh of electricity used since the beginning.\n",
            "Epoch 4/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30], Train Loss: 0.6334, Train Accuracy: 79.45%\n",
            "Epoch [4/30], Val Loss: 0.6520, Val Accuracy: 78.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training:  14%|█▍        | 86/625 [00:09<00:51, 10.46it/s][codecarbon INFO @ 21:26:45] Energy consumed for RAM : 0.000415 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:26:45] Energy consumed for all GPUs : 0.005233 kWh. Total GPU Power : 53.89499754831265 W\n",
            "[codecarbon INFO @ 21:26:45] Energy consumed for all CPUs : 0.003720 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:26:45] 0.009368 kWh of electricity used since the beginning.\n",
            "Epoch 5/30 - Training:  37%|███▋      | 234/625 [00:24<00:36, 10.78it/s][codecarbon INFO @ 21:27:00] Energy consumed for RAM : 0.000435 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:27:00] Energy consumed for all GPUs : 0.005502 kWh. Total GPU Power : 64.58889864483625 W\n",
            "[codecarbon INFO @ 21:27:00] Energy consumed for all CPUs : 0.003897 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:27:00] 0.009834 kWh of electricity used since the beginning.\n",
            "Epoch 5/30 - Training:  61%|██████▏   | 383/625 [00:39<00:22, 10.90it/s][codecarbon INFO @ 21:27:15] Energy consumed for RAM : 0.000455 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:27:15] Energy consumed for all GPUs : 0.005776 kWh. Total GPU Power : 65.82926373474629 W\n",
            "[codecarbon INFO @ 21:27:15] Energy consumed for all CPUs : 0.004074 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:27:15] 0.010305 kWh of electricity used since the beginning.\n",
            "Epoch 5/30 - Training:  85%|████████▍ | 531/625 [00:54<00:08, 10.63it/s][codecarbon INFO @ 21:27:30] Energy consumed for RAM : 0.000475 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:27:30] Energy consumed for all GPUs : 0.006044 kWh. Total GPU Power : 64.55385488388903 W\n",
            "[codecarbon INFO @ 21:27:30] Energy consumed for all CPUs : 0.004251 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:27:30] 0.010770 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:27:30] 0.008151 g.CO2eq/s mean an estimation of 257.0606136563787 kg.CO2eq/year\n",
            "Epoch 5/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.89it/s]\n",
            "Epoch 5/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 5/30 - Validation:  50%|█████     | 79/157 [00:06<00:04, 17.99it/s][codecarbon INFO @ 21:27:45] Energy consumed for RAM : 0.000495 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:27:45] Energy consumed for all GPUs : 0.006277 kWh. Total GPU Power : 55.77805066339562 W\n",
            "[codecarbon INFO @ 21:27:45] Energy consumed for all CPUs : 0.004428 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:27:45] 0.011200 kWh of electricity used since the beginning.\n",
            "Epoch 5/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 14.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30], Train Loss: 0.5813, Train Accuracy: 81.03%\n",
            "Epoch [5/30], Val Loss: 0.6195, Val Accuracy: 78.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training:  15%|█▌        | 94/625 [00:10<00:48, 11.06it/s][codecarbon INFO @ 21:28:00] Energy consumed for RAM : 0.000514 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:28:00] Energy consumed for all GPUs : 0.006508 kWh. Total GPU Power : 55.27309196769945 W\n",
            "[codecarbon INFO @ 21:28:00] Energy consumed for all CPUs : 0.004606 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:28:00] 0.011628 kWh of electricity used since the beginning.\n",
            "Epoch 6/30 - Training:  37%|███▋      | 233/625 [00:25<00:44,  8.89it/s][codecarbon INFO @ 21:28:15] Energy consumed for RAM : 0.000534 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:28:15] Energy consumed for all GPUs : 0.006772 kWh. Total GPU Power : 63.66435521066533 W\n",
            "[codecarbon INFO @ 21:28:15] Energy consumed for all CPUs : 0.004783 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:28:15] 0.012089 kWh of electricity used since the beginning.\n",
            "Epoch 6/30 - Training:  61%|██████▏   | 383/625 [00:40<00:22, 10.62it/s][codecarbon INFO @ 21:28:30] Energy consumed for RAM : 0.000554 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:28:30] Energy consumed for all GPUs : 0.007044 kWh. Total GPU Power : 65.16856180246424 W\n",
            "[codecarbon INFO @ 21:28:30] Energy consumed for all CPUs : 0.004960 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:28:30] 0.012558 kWh of electricity used since the beginning.\n",
            "Epoch 6/30 - Training:  85%|████████▍ | 531/625 [00:55<00:08, 11.00it/s][codecarbon INFO @ 21:28:45] Energy consumed for RAM : 0.000574 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:28:45] Energy consumed for all GPUs : 0.007315 kWh. Total GPU Power : 65.12339242986465 W\n",
            "[codecarbon INFO @ 21:28:45] Energy consumed for all CPUs : 0.005137 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:28:45] 0.013026 kWh of electricity used since the beginning.\n",
            "Epoch 6/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.72it/s]\n",
            "Epoch 6/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 6/30 - Validation:  52%|█████▏    | 82/157 [00:06<00:04, 17.04it/s][codecarbon INFO @ 21:29:00] Energy consumed for RAM : 0.000594 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:29:00] Energy consumed for all GPUs : 0.007550 kWh. Total GPU Power : 56.44603439687152 W\n",
            "[codecarbon INFO @ 21:29:00] Energy consumed for all CPUs : 0.005314 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:29:00] 0.013458 kWh of electricity used since the beginning.\n",
            "Epoch 6/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 14.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30], Train Loss: 0.5405, Train Accuracy: 82.34%\n",
            "Epoch [6/30], Val Loss: 0.5613, Val Accuracy: 81.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training:  15%|█▌        | 94/625 [00:10<00:48, 10.93it/s][codecarbon INFO @ 21:29:15] Energy consumed for RAM : 0.000613 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:29:15] Energy consumed for all GPUs : 0.007778 kWh. Total GPU Power : 54.73327510950793 W\n",
            "[codecarbon INFO @ 21:29:15] Energy consumed for all CPUs : 0.005491 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:29:15] 0.013883 kWh of electricity used since the beginning.\n",
            "Epoch 7/30 - Training:  39%|███▊      | 241/625 [00:25<00:34, 10.99it/s][codecarbon INFO @ 21:29:30] Energy consumed for RAM : 0.000633 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:29:30] Energy consumed for all GPUs : 0.008048 kWh. Total GPU Power : 64.55729987078519 W\n",
            "[codecarbon INFO @ 21:29:30] Energy consumed for all CPUs : 0.005668 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:29:30] 0.014349 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:29:30] 0.007974 g.CO2eq/s mean an estimation of 251.4747173488424 kg.CO2eq/year\n",
            "Epoch 7/30 - Training:  62%|██████▏   | 389/625 [00:40<00:21, 11.17it/s][codecarbon INFO @ 21:29:45] Energy consumed for RAM : 0.000653 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:29:45] Energy consumed for all GPUs : 0.008319 kWh. Total GPU Power : 65.12360708413081 W\n",
            "[codecarbon INFO @ 21:29:45] Energy consumed for all CPUs : 0.005846 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:29:45] 0.014817 kWh of electricity used since the beginning.\n",
            "Epoch 7/30 - Training:  86%|████████▌ | 537/625 [00:55<00:08, 10.65it/s][codecarbon INFO @ 21:30:00] Energy consumed for RAM : 0.000673 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:30:00] Energy consumed for all GPUs : 0.008587 kWh. Total GPU Power : 64.50742851393032 W\n",
            "[codecarbon INFO @ 21:30:00] Energy consumed for all CPUs : 0.006023 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:30:00] 0.015283 kWh of electricity used since the beginning.\n",
            "Epoch 7/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.73it/s]\n",
            "Epoch 7/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 7/30 - Validation:  62%|██████▏   | 97/157 [00:06<00:03, 17.03it/s][codecarbon INFO @ 21:30:15] Energy consumed for RAM : 0.000693 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:30:15] Energy consumed for all GPUs : 0.008821 kWh. Total GPU Power : 56.236849772207265 W\n",
            "[codecarbon INFO @ 21:30:15] Energy consumed for all CPUs : 0.006200 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:30:15] 0.015714 kWh of electricity used since the beginning.\n",
            "Epoch 7/30 - Validation: 100%|██████████| 157/157 [00:09<00:00, 16.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Train Loss: 0.5102, Train Accuracy: 83.31%\n",
            "Epoch [7/30], Val Loss: 0.5916, Val Accuracy: 81.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training:  17%|█▋        | 105/625 [00:11<00:48, 10.82it/s][codecarbon INFO @ 21:30:30] Energy consumed for RAM : 0.000712 kWh. RAM Power : 4.753036022186279 W\n",
            "Epoch 8/30 - Training:  17%|█▋        | 107/625 [00:11<00:49, 10.39it/s][codecarbon INFO @ 21:30:30] Energy consumed for all GPUs : 0.009061 kWh. Total GPU Power : 57.39062414859962 W\n",
            "[codecarbon INFO @ 21:30:30] Energy consumed for all CPUs : 0.006377 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:30:30] 0.016150 kWh of electricity used since the beginning.\n",
            "Epoch 8/30 - Training:  41%|████      | 254/625 [00:26<00:34, 10.83it/s][codecarbon INFO @ 21:30:45] Energy consumed for RAM : 0.000732 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:30:45] Energy consumed for all GPUs : 0.009329 kWh. Total GPU Power : 64.47568757561956 W\n",
            "[codecarbon INFO @ 21:30:45] Energy consumed for all CPUs : 0.006554 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:30:45] 0.016615 kWh of electricity used since the beginning.\n",
            "Epoch 8/30 - Training:  64%|██████▍   | 402/625 [00:41<00:20, 10.75it/s][codecarbon INFO @ 21:31:00] Energy consumed for RAM : 0.000752 kWh. RAM Power : 4.753036022186279 W\n",
            "Epoch 8/30 - Training:  65%|██████▍   | 404/625 [00:41<00:20, 11.01it/s][codecarbon INFO @ 21:31:00] Energy consumed for all GPUs : 0.009601 kWh. Total GPU Power : 65.34276123844397 W\n",
            "[codecarbon INFO @ 21:31:00] Energy consumed for all CPUs : 0.006731 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:31:00] 0.017085 kWh of electricity used since the beginning.\n",
            "Epoch 8/30 - Training:  88%|████████▊ | 552/625 [00:56<00:06, 11.03it/s][codecarbon INFO @ 21:31:15] Energy consumed for RAM : 0.000772 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:31:15] Energy consumed for all GPUs : 0.009870 kWh. Total GPU Power : 64.59329260799848 W\n",
            "[codecarbon INFO @ 21:31:15] Energy consumed for all CPUs : 0.006909 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:31:15] 0.017551 kWh of electricity used since the beginning.\n",
            "Epoch 8/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.66it/s]\n",
            "Epoch 8/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 8/30 - Validation:  71%|███████   | 111/157 [00:07<00:02, 16.18it/s][codecarbon INFO @ 21:31:30] Energy consumed for RAM : 0.000791 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:31:30] Energy consumed for all GPUs : 0.010096 kWh. Total GPU Power : 54.19718714830158 W\n",
            "[codecarbon INFO @ 21:31:30] Energy consumed for all CPUs : 0.007086 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:31:30] 0.017973 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:31:30] 0.008075 g.CO2eq/s mean an estimation of 254.66249931464662 kg.CO2eq/year\n",
            "Epoch 8/30 - Validation: 100%|██████████| 157/157 [00:09<00:00, 15.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Train Loss: 0.4762, Train Accuracy: 84.36%\n",
            "Epoch [8/30], Val Loss: 0.5487, Val Accuracy: 82.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training:  18%|█▊        | 112/625 [00:12<00:46, 11.02it/s][codecarbon INFO @ 21:31:45] Energy consumed for RAM : 0.000811 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:31:45] Energy consumed for all GPUs : 0.010334 kWh. Total GPU Power : 57.18071805853214 W\n",
            "[codecarbon INFO @ 21:31:45] Energy consumed for all CPUs : 0.007263 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:31:45] 0.018408 kWh of electricity used since the beginning.\n",
            "Epoch 9/30 - Training:  41%|████▏     | 258/625 [00:26<00:33, 10.85it/s][codecarbon INFO @ 21:32:00] Energy consumed for RAM : 0.000831 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:32:00] Energy consumed for all GPUs : 0.010603 kWh. Total GPU Power : 64.59201246743457 W\n",
            "[codecarbon INFO @ 21:32:00] Energy consumed for all CPUs : 0.007440 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:32:00] 0.018874 kWh of electricity used since the beginning.\n",
            "Epoch 9/30 - Training:  65%|██████▌   | 408/625 [00:42<00:19, 10.96it/s][codecarbon INFO @ 21:32:15] Energy consumed for RAM : 0.000851 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:32:15] Energy consumed for all GPUs : 0.010875 kWh. Total GPU Power : 65.20956821359069 W\n",
            "[codecarbon INFO @ 21:32:15] Energy consumed for all CPUs : 0.007617 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:32:15] 0.019343 kWh of electricity used since the beginning.\n",
            "Epoch 9/30 - Training:  89%|████████▉ | 555/625 [00:57<00:06, 11.03it/s][codecarbon INFO @ 21:32:30] Energy consumed for RAM : 0.000871 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:32:30] Energy consumed for all GPUs : 0.011144 kWh. Total GPU Power : 64.54629952293911 W\n",
            "Epoch 9/30 - Training:  89%|████████▉ | 557/625 [00:57<00:06, 10.98it/s][codecarbon INFO @ 21:32:30] Energy consumed for all CPUs : 0.007794 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:32:30] 0.019809 kWh of electricity used since the beginning.\n",
            "Epoch 9/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.65it/s]\n",
            "Epoch 9/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 9/30 - Validation:  75%|███████▍  | 117/157 [00:07<00:02, 16.38it/s][codecarbon INFO @ 21:32:45] Energy consumed for RAM : 0.000890 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:32:45] Energy consumed for all GPUs : 0.011369 kWh. Total GPU Power : 54.13246110149918 W\n",
            "[codecarbon INFO @ 21:32:45] Energy consumed for all CPUs : 0.007971 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:32:45] 0.020231 kWh of electricity used since the beginning.\n",
            "Epoch 9/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Train Loss: 0.4576, Train Accuracy: 84.91%\n",
            "Epoch [9/30], Val Loss: 0.5269, Val Accuracy: 82.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training:  19%|█▊        | 116/625 [00:11<00:59,  8.59it/s][codecarbon INFO @ 21:33:00] Energy consumed for RAM : 0.000910 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:33:00] Energy consumed for all GPUs : 0.011609 kWh. Total GPU Power : 57.52258803700996 W\n",
            "[codecarbon INFO @ 21:33:00] Energy consumed for all CPUs : 0.008149 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:33:00] 0.020668 kWh of electricity used since the beginning.\n",
            "Epoch 10/30 - Training:  42%|████▏     | 264/625 [00:26<00:43,  8.28it/s][codecarbon INFO @ 21:33:15] Energy consumed for RAM : 0.000930 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:33:15] Energy consumed for all GPUs : 0.011878 kWh. Total GPU Power : 64.67189912206952 W\n",
            "[codecarbon INFO @ 21:33:15] Energy consumed for all CPUs : 0.008326 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:33:15] 0.021134 kWh of electricity used since the beginning.\n",
            "Epoch 10/30 - Training:  66%|██████▌   | 412/625 [00:41<00:25,  8.36it/s][codecarbon INFO @ 21:33:30] Energy consumed for RAM : 0.000950 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:33:30] Energy consumed for all GPUs : 0.012149 kWh. Total GPU Power : 65.07401451279435 W\n",
            "[codecarbon INFO @ 21:33:30] Energy consumed for all CPUs : 0.008503 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:33:30] 0.021602 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:33:30] 0.008087 g.CO2eq/s mean an estimation of 255.02574369988506 kg.CO2eq/year\n",
            "Epoch 10/30 - Training:  89%|████████▉ | 559/625 [00:56<00:08,  7.92it/s][codecarbon INFO @ 21:33:45] Energy consumed for RAM : 0.000970 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:33:45] Energy consumed for all GPUs : 0.012416 kWh. Total GPU Power : 63.90739380063587 W\n",
            "[codecarbon INFO @ 21:33:45] Energy consumed for all CPUs : 0.008680 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:33:45] 0.022066 kWh of electricity used since the beginning.\n",
            "Epoch 10/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.77it/s]\n",
            "Epoch 10/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 10/30 - Validation:  72%|███████▏  | 113/157 [00:07<00:04, 10.81it/s][codecarbon INFO @ 21:34:00] Energy consumed for RAM : 0.000989 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:34:00] Energy consumed for all GPUs : 0.012636 kWh. Total GPU Power : 52.825348546665225 W\n",
            "[codecarbon INFO @ 21:34:00] Energy consumed for all CPUs : 0.008857 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:34:00] 0.022483 kWh of electricity used since the beginning.\n",
            "Epoch 10/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Train Loss: 0.4346, Train Accuracy: 85.80%\n",
            "Epoch [10/30], Val Loss: 0.4975, Val Accuracy: 83.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training:  18%|█▊        | 111/625 [00:11<01:06,  7.70it/s][codecarbon INFO @ 21:34:15] Energy consumed for RAM : 0.001009 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:34:15] Energy consumed for all GPUs : 0.012874 kWh. Total GPU Power : 57.06173960099389 W\n",
            "[codecarbon INFO @ 21:34:15] Energy consumed for all CPUs : 0.009034 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:34:15] 0.022918 kWh of electricity used since the beginning.\n",
            "Epoch 11/30 - Training:  41%|████▏     | 258/625 [00:26<00:43,  8.47it/s][codecarbon INFO @ 21:34:30] Energy consumed for RAM : 0.001029 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:34:30] Energy consumed for all GPUs : 0.013142 kWh. Total GPU Power : 64.309558723837 W\n",
            "[codecarbon INFO @ 21:34:30] Energy consumed for all CPUs : 0.009211 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:34:30] 0.023382 kWh of electricity used since the beginning.\n",
            "Epoch 11/30 - Training:  65%|██████▍   | 405/625 [00:41<00:26,  8.45it/s][codecarbon INFO @ 21:34:45] Energy consumed for RAM : 0.001049 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:34:45] Energy consumed for all GPUs : 0.013413 kWh. Total GPU Power : 64.95398164611456 W\n",
            "[codecarbon INFO @ 21:34:45] Energy consumed for all CPUs : 0.009389 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:34:45] 0.023850 kWh of electricity used since the beginning.\n",
            "Epoch 11/30 - Training:  88%|████████▊ | 553/625 [00:56<00:08,  8.25it/s][codecarbon INFO @ 21:35:00] Energy consumed for RAM : 0.001069 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:35:00] Energy consumed for all GPUs : 0.013683 kWh. Total GPU Power : 64.80688357551645 W\n",
            "[codecarbon INFO @ 21:35:00] Energy consumed for all CPUs : 0.009566 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:35:00] 0.024317 kWh of electricity used since the beginning.\n",
            "Epoch 11/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.81it/s]\n",
            "Epoch 11/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 11/30 - Validation:  67%|██████▋   | 105/157 [00:07<00:04, 10.88it/s][codecarbon INFO @ 21:35:15] Energy consumed for RAM : 0.001088 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:35:15] Energy consumed for all GPUs : 0.013904 kWh. Total GPU Power : 53.174621454007365 W\n",
            "[codecarbon INFO @ 21:35:15] Energy consumed for all CPUs : 0.009743 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:35:15] 0.024736 kWh of electricity used since the beginning.\n",
            "Epoch 11/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Train Loss: 0.4227, Train Accuracy: 86.31%\n",
            "Epoch [11/30], Val Loss: 0.5483, Val Accuracy: 81.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training:  17%|█▋        | 109/625 [00:11<01:09,  7.47it/s][codecarbon INFO @ 21:35:30] Energy consumed for RAM : 0.001108 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:35:30] Energy consumed for all GPUs : 0.014140 kWh. Total GPU Power : 56.71972158081107 W\n",
            "[codecarbon INFO @ 21:35:30] Energy consumed for all CPUs : 0.009920 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:35:30] 0.025168 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:35:30] 0.007946 g.CO2eq/s mean an estimation of 250.59658251058784 kg.CO2eq/year\n",
            "Epoch 12/30 - Training:  41%|████▏     | 258/625 [00:26<00:50,  7.32it/s][codecarbon INFO @ 21:35:45] Energy consumed for RAM : 0.001128 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:35:45] Energy consumed for all GPUs : 0.014409 kWh. Total GPU Power : 64.45757186677858 W\n",
            "[codecarbon INFO @ 21:35:45] Energy consumed for all CPUs : 0.010098 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:35:45] 0.025635 kWh of electricity used since the beginning.\n",
            "Epoch 12/30 - Training:  65%|██████▍   | 404/625 [00:41<00:30,  7.27it/s][codecarbon INFO @ 21:36:00] Energy consumed for RAM : 0.001148 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:36:00] Energy consumed for all GPUs : 0.014680 kWh. Total GPU Power : 65.07053122896389 W\n",
            "[codecarbon INFO @ 21:36:00] Energy consumed for all CPUs : 0.010274 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:36:00] 0.026102 kWh of electricity used since the beginning.\n",
            "Epoch 12/30 - Training:  88%|████████▊ | 552/625 [00:56<00:09,  7.79it/s][codecarbon INFO @ 21:36:15] Energy consumed for RAM : 0.001168 kWh. RAM Power : 4.753036022186279 W\n",
            "Epoch 12/30 - Training:  88%|████████▊ | 553/625 [00:56<00:09,  7.49it/s][codecarbon INFO @ 21:36:15] Energy consumed for all GPUs : 0.014950 kWh. Total GPU Power : 64.71281325804094 W\n",
            "[codecarbon INFO @ 21:36:15] Energy consumed for all CPUs : 0.010452 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:36:15] 0.026569 kWh of electricity used since the beginning.\n",
            "Epoch 12/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.83it/s]\n",
            "Epoch 12/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 12/30 - Validation:  68%|██████▊   | 106/157 [00:07<00:04, 10.22it/s][codecarbon INFO @ 21:36:30] Energy consumed for RAM : 0.001187 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:36:30] Energy consumed for all GPUs : 0.015172 kWh. Total GPU Power : 53.431303965840584 W\n",
            "[codecarbon INFO @ 21:36:30] Energy consumed for all CPUs : 0.010629 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:36:30] 0.026989 kWh of electricity used since the beginning.\n",
            "Epoch 12/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Train Loss: 0.4098, Train Accuracy: 86.44%\n",
            "Epoch [12/30], Val Loss: 0.4752, Val Accuracy: 84.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Training:  18%|█▊        | 110/625 [00:11<01:10,  7.32it/s][codecarbon INFO @ 21:36:45] Energy consumed for RAM : 0.001207 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:36:45] Energy consumed for all GPUs : 0.015411 kWh. Total GPU Power : 57.355183224342234 W\n",
            "[codecarbon INFO @ 21:36:45] Energy consumed for all CPUs : 0.010806 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:36:45] 0.027425 kWh of electricity used since the beginning.\n",
            "Epoch 13/30 - Training:  41%|████      | 257/625 [00:26<00:53,  6.88it/s][codecarbon INFO @ 21:37:00] Energy consumed for RAM : 0.001227 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:37:00] Energy consumed for all GPUs : 0.015679 kWh. Total GPU Power : 64.3265984244439 W\n",
            "[codecarbon INFO @ 21:37:00] Energy consumed for all CPUs : 0.010983 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:37:00] 0.027888 kWh of electricity used since the beginning.\n",
            "Epoch 13/30 - Training:  65%|██████▍   | 404/625 [00:41<00:29,  7.47it/s][codecarbon INFO @ 21:37:15] Energy consumed for RAM : 0.001247 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:37:15] Energy consumed for all GPUs : 0.015951 kWh. Total GPU Power : 65.47050450314293 W\n",
            "[codecarbon INFO @ 21:37:15] Energy consumed for all CPUs : 0.011160 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:37:15] 0.028358 kWh of electricity used since the beginning.\n",
            "Epoch 13/30 - Training:  88%|████████▊ | 553/625 [00:56<00:08,  8.39it/s][codecarbon INFO @ 21:37:30] Energy consumed for RAM : 0.001267 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:37:30] Energy consumed for all GPUs : 0.016222 kWh. Total GPU Power : 64.76430959254839 W\n",
            "[codecarbon INFO @ 21:37:30] Energy consumed for all CPUs : 0.011338 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:37:30] 0.028826 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:37:30] 0.008148 g.CO2eq/s mean an estimation of 256.9548009456393 kg.CO2eq/year\n",
            "Epoch 13/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.87it/s]\n",
            "Epoch 13/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 13/30 - Validation:  66%|██████▌   | 103/157 [00:08<00:04, 11.70it/s][codecarbon INFO @ 21:37:45] Energy consumed for RAM : 0.001286 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:37:45] Energy consumed for all GPUs : 0.016442 kWh. Total GPU Power : 52.98558457446545 W\n",
            "[codecarbon INFO @ 21:37:45] Energy consumed for all CPUs : 0.011515 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:37:45] 0.029244 kWh of electricity used since the beginning.\n",
            "Epoch 13/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Train Loss: 0.3882, Train Accuracy: 87.36%\n",
            "Epoch [13/30], Val Loss: 0.4915, Val Accuracy: 84.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Training:  17%|█▋        | 109/625 [00:11<00:53,  9.68it/s][codecarbon INFO @ 21:38:00] Energy consumed for RAM : 0.001306 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:38:00] Energy consumed for all GPUs : 0.016684 kWh. Total GPU Power : 57.9731763898084 W\n",
            "[codecarbon INFO @ 21:38:00] Energy consumed for all CPUs : 0.011692 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:38:00] 0.029682 kWh of electricity used since the beginning.\n",
            "Epoch 14/30 - Training:  41%|████      | 256/625 [00:26<00:38,  9.68it/s][codecarbon INFO @ 21:38:15] Energy consumed for RAM : 0.001326 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:38:15] Energy consumed for all GPUs : 0.016952 kWh. Total GPU Power : 64.36000537247266 W\n",
            "[codecarbon INFO @ 21:38:15] Energy consumed for all CPUs : 0.011869 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:38:15] 0.030147 kWh of electricity used since the beginning.\n",
            "Epoch 14/30 - Training:  64%|██████▎   | 398/625 [00:41<00:28,  8.01it/s][codecarbon INFO @ 21:38:30] Energy consumed for RAM : 0.001346 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:38:30] Energy consumed for all GPUs : 0.017220 kWh. Total GPU Power : 64.4010449281506 W\n",
            "[codecarbon INFO @ 21:38:30] Energy consumed for all CPUs : 0.012046 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:38:30] 0.030612 kWh of electricity used since the beginning.\n",
            "Epoch 14/30 - Training:  87%|████████▋ | 542/625 [00:57<00:10,  8.01it/s][codecarbon INFO @ 21:38:45] Energy consumed for RAM : 0.001366 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:38:45] Energy consumed for all GPUs : 0.017488 kWh. Total GPU Power : 64.38221346899921 W\n",
            "[codecarbon INFO @ 21:38:45] Energy consumed for all CPUs : 0.012223 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:38:45] 0.031077 kWh of electricity used since the beginning.\n",
            "Epoch 14/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.62it/s]\n",
            "Epoch 14/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 14/30 - Validation:  46%|████▋     | 73/157 [00:06<00:08,  9.57it/s][codecarbon INFO @ 21:39:00] Energy consumed for RAM : 0.001385 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:39:00] Energy consumed for all GPUs : 0.017713 kWh. Total GPU Power : 53.97686383250905 W\n",
            "[codecarbon INFO @ 21:39:00] Energy consumed for all CPUs : 0.012401 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:39:00] 0.031499 kWh of electricity used since the beginning.\n",
            "Epoch 14/30 - Validation: 100%|██████████| 157/157 [00:12<00:00, 12.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Train Loss: 0.3850, Train Accuracy: 87.32%\n",
            "Epoch [14/30], Val Loss: 0.5119, Val Accuracy: 83.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Training:  13%|█▎        | 80/625 [00:09<01:19,  6.85it/s][codecarbon INFO @ 21:39:15] Energy consumed for RAM : 0.001405 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:39:15] Energy consumed for all GPUs : 0.017933 kWh. Total GPU Power : 52.624361332522724 W\n",
            "[codecarbon INFO @ 21:39:15] Energy consumed for all CPUs : 0.012578 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:39:15] 0.031915 kWh of electricity used since the beginning.\n",
            "Epoch 15/30 - Training:  35%|███▌      | 221/625 [00:24<00:57,  6.97it/s][codecarbon INFO @ 21:39:30] Energy consumed for RAM : 0.001425 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:39:30] Energy consumed for all GPUs : 0.018197 kWh. Total GPU Power : 63.47628941494066 W\n",
            "[codecarbon INFO @ 21:39:30] Energy consumed for all CPUs : 0.012755 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:39:30] 0.032377 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:39:30] 0.007913 g.CO2eq/s mean an estimation of 249.54306556260755 kg.CO2eq/year\n",
            "Epoch 15/30 - Training:  58%|█████▊    | 364/625 [00:39<00:37,  6.96it/s][codecarbon INFO @ 21:39:45] Energy consumed for RAM : 0.001445 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:39:45] Energy consumed for all GPUs : 0.018468 kWh. Total GPU Power : 64.99491247576634 W\n",
            "[codecarbon INFO @ 21:39:45] Energy consumed for all CPUs : 0.012932 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:39:45] 0.032844 kWh of electricity used since the beginning.\n",
            "Epoch 15/30 - Training:  82%|████████▏ | 511/625 [00:54<00:14,  7.66it/s][codecarbon INFO @ 21:40:00] Energy consumed for RAM : 0.001464 kWh. RAM Power : 4.753036022186279 W\n",
            "Epoch 15/30 - Training:  82%|████████▏ | 512/625 [00:54<00:15,  7.40it/s][codecarbon INFO @ 21:40:00] Energy consumed for all GPUs : 0.018738 kWh. Total GPU Power : 65.03192996912568 W\n",
            "[codecarbon INFO @ 21:40:00] Energy consumed for all CPUs : 0.013109 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:40:00] 0.033312 kWh of electricity used since the beginning.\n",
            "Epoch 15/30 - Training: 100%|██████████| 625/625 [01:05<00:00,  9.55it/s]\n",
            "Epoch 15/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 15/30 - Validation:  26%|██▌       | 41/157 [00:04<00:10, 10.62it/s][codecarbon INFO @ 21:40:15] Energy consumed for RAM : 0.001484 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:40:15] Energy consumed for all GPUs : 0.018983 kWh. Total GPU Power : 58.85477886280852 W\n",
            "[codecarbon INFO @ 21:40:15] Energy consumed for all CPUs : 0.013286 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:40:15] 0.033753 kWh of electricity used since the beginning.\n",
            "Epoch 15/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 14.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Train Loss: 0.3708, Train Accuracy: 87.97%\n",
            "Epoch [15/30], Val Loss: 0.5204, Val Accuracy: 82.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Training:  11%|█         | 70/625 [00:08<00:54, 10.13it/s][codecarbon INFO @ 21:40:30] Energy consumed for RAM : 0.001504 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:40:30] Energy consumed for all GPUs : 0.019199 kWh. Total GPU Power : 51.717875069197135 W\n",
            "[codecarbon INFO @ 21:40:30] Energy consumed for all CPUs : 0.013463 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:40:30] 0.034166 kWh of electricity used since the beginning.\n",
            "Epoch 16/30 - Training:  35%|███▍      | 217/625 [00:23<00:39, 10.34it/s][codecarbon INFO @ 21:40:45] Energy consumed for RAM : 0.001524 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:40:45] Energy consumed for all GPUs : 0.019467 kWh. Total GPU Power : 64.54068288752106 W\n",
            "[codecarbon INFO @ 21:40:45] Energy consumed for all CPUs : 0.013640 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:40:45] 0.034631 kWh of electricity used since the beginning.\n",
            "Epoch 16/30 - Training:  58%|█████▊    | 365/625 [00:38<00:24, 10.56it/s][codecarbon INFO @ 21:41:00] Energy consumed for RAM : 0.001544 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:41:00] Energy consumed for all GPUs : 0.019739 kWh. Total GPU Power : 65.32072928232033 W\n",
            "[codecarbon INFO @ 21:41:00] Energy consumed for all CPUs : 0.013817 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:41:00] 0.035100 kWh of electricity used since the beginning.\n",
            "Epoch 16/30 - Training:  82%|████████▏ | 512/625 [00:53<00:10, 10.69it/s][codecarbon INFO @ 21:41:15] Energy consumed for RAM : 0.001563 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:41:16] Energy consumed for all GPUs : 0.020009 kWh. Total GPU Power : 64.58902180071131 W\n",
            "[codecarbon INFO @ 21:41:16] Energy consumed for all CPUs : 0.013994 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:41:16] 0.035566 kWh of electricity used since the beginning.\n",
            "Epoch 16/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.75it/s]\n",
            "Epoch 16/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 16/30 - Validation:  37%|███▋      | 58/157 [00:04<00:05, 16.64it/s][codecarbon INFO @ 21:41:31] Energy consumed for RAM : 0.001583 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:41:31] Energy consumed for all GPUs : 0.020257 kWh. Total GPU Power : 59.55879843163274 W\n",
            "[codecarbon INFO @ 21:41:31] Energy consumed for all CPUs : 0.014172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:41:31] 0.036012 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:41:31] 0.008102 g.CO2eq/s mean an estimation of 255.50268227039516 kg.CO2eq/year\n",
            "Epoch 16/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Train Loss: 0.3621, Train Accuracy: 88.12%\n",
            "Epoch [16/30], Val Loss: 0.4491, Val Accuracy: 85.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Training:  12%|█▏        | 76/625 [00:09<00:51, 10.72it/s][codecarbon INFO @ 21:41:46] Energy consumed for RAM : 0.001603 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:41:46] Energy consumed for all GPUs : 0.020474 kWh. Total GPU Power : 52.11198558139673 W\n",
            "[codecarbon INFO @ 21:41:46] Energy consumed for all CPUs : 0.014349 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:41:46] 0.036426 kWh of electricity used since the beginning.\n",
            "Epoch 17/30 - Training:  36%|███▌      | 223/625 [00:24<00:37, 10.85it/s][codecarbon INFO @ 21:42:01] Energy consumed for RAM : 0.001623 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:42:01] Energy consumed for all GPUs : 0.020742 kWh. Total GPU Power : 64.4254749862841 W\n",
            "[codecarbon INFO @ 21:42:01] Energy consumed for all CPUs : 0.014526 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:42:01] 0.036891 kWh of electricity used since the beginning.\n",
            "Epoch 17/30 - Training:  59%|█████▉    | 369/625 [00:38<00:23, 10.83it/s][codecarbon INFO @ 21:42:16] Energy consumed for RAM : 0.001643 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:42:16] Energy consumed for all GPUs : 0.021014 kWh. Total GPU Power : 65.12785245079557 W\n",
            "[codecarbon INFO @ 21:42:16] Energy consumed for all CPUs : 0.014703 kWh. Total CPU Power : 42.5 W\n",
            "Epoch 17/30 - Training:  59%|█████▉    | 371/625 [00:39<00:23, 10.82it/s][codecarbon INFO @ 21:42:16] 0.037359 kWh of electricity used since the beginning.\n",
            "Epoch 17/30 - Training:  83%|████████▎ | 519/625 [00:54<00:09, 11.03it/s][codecarbon INFO @ 21:42:31] Energy consumed for RAM : 0.001662 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:42:31] Energy consumed for all GPUs : 0.021285 kWh. Total GPU Power : 65.08831713065491 W\n",
            "[codecarbon INFO @ 21:42:31] Energy consumed for all CPUs : 0.014880 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:42:31] 0.037827 kWh of electricity used since the beginning.\n",
            "Epoch 17/30 - Training: 100%|██████████| 625/625 [01:05<00:00,  9.58it/s]\n",
            "Epoch 17/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 17/30 - Validation:  38%|███▊      | 59/157 [00:03<00:05, 18.16it/s][codecarbon INFO @ 21:42:46] Energy consumed for RAM : 0.001682 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:42:46] Energy consumed for all GPUs : 0.021532 kWh. Total GPU Power : 59.336304021080515 W\n",
            "[codecarbon INFO @ 21:42:46] Energy consumed for all CPUs : 0.015057 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:42:46] 0.038271 kWh of electricity used since the beginning.\n",
            "Epoch 17/30 - Validation: 100%|██████████| 157/157 [00:09<00:00, 16.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Train Loss: 0.3556, Train Accuracy: 88.45%\n",
            "Epoch [17/30], Val Loss: 0.4653, Val Accuracy: 84.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Training:  12%|█▏        | 77/625 [00:09<00:51, 10.56it/s][codecarbon INFO @ 21:43:01] Energy consumed for RAM : 0.001702 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:43:01] Energy consumed for all GPUs : 0.021750 kWh. Total GPU Power : 52.34060812752732 W\n",
            "[codecarbon INFO @ 21:43:01] Energy consumed for all CPUs : 0.015234 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:43:01] 0.038686 kWh of electricity used since the beginning.\n",
            "Epoch 18/30 - Training:  36%|███▌      | 226/625 [00:24<00:37, 10.68it/s][codecarbon INFO @ 21:43:16] Energy consumed for RAM : 0.001722 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:43:16] Energy consumed for all GPUs : 0.022019 kWh. Total GPU Power : 64.58144356727396 W\n",
            "[codecarbon INFO @ 21:43:16] Energy consumed for all CPUs : 0.015411 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:43:16] 0.039152 kWh of electricity used since the beginning.\n",
            "Epoch 18/30 - Training:  60%|█████▉    | 372/625 [00:39<00:23, 10.92it/s][codecarbon INFO @ 21:43:31] Energy consumed for RAM : 0.001742 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:43:31] Energy consumed for all GPUs : 0.022288 kWh. Total GPU Power : 64.80056652423652 W\n",
            "[codecarbon INFO @ 21:43:31] Energy consumed for all CPUs : 0.015588 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:43:31] 0.039618 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:43:31] 0.008037 g.CO2eq/s mean an estimation of 253.4502685876618 kg.CO2eq/year\n",
            "Epoch 18/30 - Training:  83%|████████▎ | 517/625 [00:54<00:10, 10.65it/s][codecarbon INFO @ 21:43:46] Energy consumed for RAM : 0.001761 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:43:46] Energy consumed for all GPUs : 0.022557 kWh. Total GPU Power : 64.66732107589203 W\n",
            "[codecarbon INFO @ 21:43:46] Energy consumed for all CPUs : 0.015765 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:43:46] 0.040084 kWh of electricity used since the beginning.\n",
            "Epoch 18/30 - Training: 100%|██████████| 625/625 [01:05<00:00,  9.53it/s]\n",
            "Epoch 18/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 18/30 - Validation:  36%|███▋      | 57/157 [00:03<00:06, 16.31it/s][codecarbon INFO @ 21:44:01] Energy consumed for RAM : 0.001781 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:44:01] Energy consumed for all GPUs : 0.022808 kWh. Total GPU Power : 60.20751574526149 W\n",
            "[codecarbon INFO @ 21:44:01] Energy consumed for all CPUs : 0.015943 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:44:01] 0.040533 kWh of electricity used since the beginning.\n",
            "Epoch 18/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Train Loss: 0.3400, Train Accuracy: 88.78%\n",
            "Epoch [18/30], Val Loss: 0.4629, Val Accuracy: 85.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30 - Training:  12%|█▏        | 74/625 [00:08<00:50, 10.96it/s][codecarbon INFO @ 21:44:16] Energy consumed for RAM : 0.001801 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:44:16] Energy consumed for all GPUs : 0.023018 kWh. Total GPU Power : 50.5857006962342 W\n",
            "[codecarbon INFO @ 21:44:16] Energy consumed for all CPUs : 0.016120 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:44:16] 0.040939 kWh of electricity used since the beginning.\n",
            "Epoch 19/30 - Training:  36%|███▌      | 222/625 [00:23<00:37, 10.88it/s][codecarbon INFO @ 21:44:31] Energy consumed for RAM : 0.001821 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:44:31] Energy consumed for all GPUs : 0.023288 kWh. Total GPU Power : 64.85758391662326 W\n",
            "[codecarbon INFO @ 21:44:31] Energy consumed for all CPUs : 0.016297 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:44:31] 0.041405 kWh of electricity used since the beginning.\n",
            "Epoch 19/30 - Training:  59%|█████▉    | 370/625 [00:38<00:24, 10.60it/s][codecarbon INFO @ 21:44:46] Energy consumed for RAM : 0.001840 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:44:46] Energy consumed for all GPUs : 0.023560 kWh. Total GPU Power : 65.21234982133896 W\n",
            "[codecarbon INFO @ 21:44:46] Energy consumed for all CPUs : 0.016474 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:44:46] 0.041874 kWh of electricity used since the beginning.\n",
            "Epoch 19/30 - Training:  83%|████████▎ | 518/625 [00:53<00:09, 10.97it/s][codecarbon INFO @ 21:45:01] Energy consumed for RAM : 0.001860 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:45:01] Energy consumed for all GPUs : 0.023832 kWh. Total GPU Power : 65.33578641814752 W\n",
            "[codecarbon INFO @ 21:45:01] Energy consumed for all CPUs : 0.016651 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:45:01] 0.042343 kWh of electricity used since the beginning.\n",
            "Epoch 19/30 - Training: 100%|██████████| 625/625 [01:04<00:00,  9.68it/s]\n",
            "Epoch 19/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 19/30 - Validation:  38%|███▊      | 60/157 [00:03<00:05, 18.76it/s][codecarbon INFO @ 21:45:16] Energy consumed for RAM : 0.001880 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:45:16] Energy consumed for all GPUs : 0.024079 kWh. Total GPU Power : 59.358473288647005 W\n",
            "[codecarbon INFO @ 21:45:16] Energy consumed for all CPUs : 0.016828 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:45:16] 0.042787 kWh of electricity used since the beginning.\n",
            "Epoch 19/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 14.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Train Loss: 0.3406, Train Accuracy: 88.83%\n",
            "Epoch [19/30], Val Loss: 0.4761, Val Accuracy: 84.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30 - Training:  13%|█▎        | 79/625 [00:07<00:49, 10.99it/s][codecarbon INFO @ 21:45:31] Energy consumed for RAM : 0.001900 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:45:31] Energy consumed for all GPUs : 0.024295 kWh. Total GPU Power : 51.908447427784296 W\n",
            "[codecarbon INFO @ 21:45:31] Energy consumed for all CPUs : 0.017005 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:45:31] 0.043200 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:45:31] 0.007983 g.CO2eq/s mean an estimation of 251.73654460326122 kg.CO2eq/year\n",
            "Epoch 20/30 - Training:  36%|███▌      | 225/625 [00:22<00:37, 10.78it/s][codecarbon INFO @ 21:45:46] Energy consumed for RAM : 0.001919 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:45:46] Energy consumed for all GPUs : 0.024562 kWh. Total GPU Power : 64.30033602746379 W\n",
            "[codecarbon INFO @ 21:45:46] Energy consumed for all CPUs : 0.017182 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:45:46] 0.043664 kWh of electricity used since the beginning.\n",
            "Epoch 20/30 - Training:  60%|██████    | 376/625 [00:37<00:22, 10.93it/s][codecarbon INFO @ 21:46:01] Energy consumed for RAM : 0.001939 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:46:01] Energy consumed for all GPUs : 0.024835 kWh. Total GPU Power : 65.37745613017697 W\n",
            "[codecarbon INFO @ 21:46:01] Energy consumed for all CPUs : 0.017359 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:46:01] 0.044133 kWh of electricity used since the beginning.\n",
            "Epoch 20/30 - Training:  84%|████████▎ | 523/625 [00:52<00:09, 10.60it/s][codecarbon INFO @ 21:46:16] Energy consumed for RAM : 0.001959 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:46:16] Energy consumed for all GPUs : 0.025105 kWh. Total GPU Power : 64.83470946354656 W\n",
            "[codecarbon INFO @ 21:46:16] Energy consumed for all CPUs : 0.017536 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:46:16] 0.044600 kWh of electricity used since the beginning.\n",
            "Epoch 20/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.85it/s]\n",
            "Epoch 20/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 20/30 - Validation:  44%|████▍     | 69/157 [00:04<00:05, 16.69it/s][codecarbon INFO @ 21:46:31] Energy consumed for RAM : 0.001979 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:46:31] Energy consumed for all GPUs : 0.025349 kWh. Total GPU Power : 58.75009908928383 W\n",
            "[codecarbon INFO @ 21:46:31] Energy consumed for all CPUs : 0.017713 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:46:31] 0.045041 kWh of electricity used since the beginning.\n",
            "Epoch 20/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Train Loss: 0.3338, Train Accuracy: 89.01%\n",
            "Epoch [20/30], Val Loss: 0.4837, Val Accuracy: 84.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30 - Training:  13%|█▎        | 83/625 [00:08<00:50, 10.79it/s][codecarbon INFO @ 21:46:46] Energy consumed for RAM : 0.001999 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:46:46] Energy consumed for all GPUs : 0.025569 kWh. Total GPU Power : 52.64435635860468 W\n",
            "[codecarbon INFO @ 21:46:46] Energy consumed for all CPUs : 0.017891 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:46:46] 0.045458 kWh of electricity used since the beginning.\n",
            "Epoch 21/30 - Training:  37%|███▋      | 232/625 [00:23<00:35, 11.00it/s][codecarbon INFO @ 21:47:01] Energy consumed for RAM : 0.002018 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:47:01] Energy consumed for all GPUs : 0.025836 kWh. Total GPU Power : 64.04425572650759 W\n",
            "[codecarbon INFO @ 21:47:01] Energy consumed for all CPUs : 0.018068 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:47:01] 0.045922 kWh of electricity used since the beginning.\n",
            "Epoch 21/30 - Training:  61%|██████    | 379/625 [00:38<00:24, 10.00it/s][codecarbon INFO @ 21:47:16] Energy consumed for RAM : 0.002038 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:47:16] Energy consumed for all GPUs : 0.026108 kWh. Total GPU Power : 65.46705730920891 W\n",
            "[codecarbon INFO @ 21:47:16] Energy consumed for all CPUs : 0.018245 kWh. Total CPU Power : 42.5 W\n",
            "Epoch 21/30 - Training:  61%|██████    | 381/625 [00:38<00:26,  9.26it/s][codecarbon INFO @ 21:47:16] 0.046392 kWh of electricity used since the beginning.\n",
            "Epoch 21/30 - Training:  85%|████████▍ | 529/625 [00:53<00:10,  9.42it/s][codecarbon INFO @ 21:47:31] Energy consumed for RAM : 0.002058 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:47:31] Energy consumed for all GPUs : 0.026379 kWh. Total GPU Power : 64.97739746166027 W\n",
            "[codecarbon INFO @ 21:47:31] Energy consumed for all CPUs : 0.018422 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:47:31] 0.046859 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:47:31] 0.008155 g.CO2eq/s mean an estimation of 257.16322044450925 kg.CO2eq/year\n",
            "Epoch 21/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.86it/s]\n",
            "Epoch 21/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 21/30 - Validation:  43%|████▎     | 68/157 [00:04<00:06, 13.58it/s][codecarbon INFO @ 21:47:46] Energy consumed for RAM : 0.002078 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:47:46] Energy consumed for all GPUs : 0.026621 kWh. Total GPU Power : 58.21046582477298 W\n",
            "[codecarbon INFO @ 21:47:46] Energy consumed for all CPUs : 0.018599 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:47:46] 0.047298 kWh of electricity used since the beginning.\n",
            "Epoch 21/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Train Loss: 0.1959, Train Accuracy: 93.58%\n",
            "Epoch [21/30], Val Loss: 0.3398, Val Accuracy: 88.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30 - Training:  13%|█▎        | 84/625 [00:08<01:04,  8.43it/s][codecarbon INFO @ 21:48:01] Energy consumed for RAM : 0.002098 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:48:01] Energy consumed for all GPUs : 0.026842 kWh. Total GPU Power : 52.89167095656549 W\n",
            "[codecarbon INFO @ 21:48:01] Energy consumed for all CPUs : 0.018776 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:48:01] 0.047715 kWh of electricity used since the beginning.\n",
            "Epoch 22/30 - Training:  37%|███▋      | 230/625 [00:23<00:49,  8.05it/s][codecarbon INFO @ 21:48:16] Energy consumed for RAM : 0.002117 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:48:16] Energy consumed for all GPUs : 0.027108 kWh. Total GPU Power : 64.01712622599287 W\n",
            "[codecarbon INFO @ 21:48:16] Energy consumed for all CPUs : 0.018953 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:48:16] 0.048179 kWh of electricity used since the beginning.\n",
            "Epoch 22/30 - Training:  60%|██████    | 378/625 [00:38<00:31,  7.82it/s][codecarbon INFO @ 21:48:31] Energy consumed for RAM : 0.002137 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:48:31] Energy consumed for all GPUs : 0.027379 kWh. Total GPU Power : 65.17035066411502 W\n",
            "[codecarbon INFO @ 21:48:31] Energy consumed for all CPUs : 0.019130 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:48:31] 0.048647 kWh of electricity used since the beginning.\n",
            "Epoch 22/30 - Training:  84%|████████▍ | 524/625 [00:53<00:13,  7.68it/s][codecarbon INFO @ 21:48:46] Energy consumed for RAM : 0.002157 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:48:46] Energy consumed for all GPUs : 0.027649 kWh. Total GPU Power : 64.8217114239873 W\n",
            "[codecarbon INFO @ 21:48:46] Energy consumed for all CPUs : 0.019307 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:48:46] 0.049114 kWh of electricity used since the beginning.\n",
            "Epoch 22/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.81it/s]\n",
            "Epoch 22/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 22/30 - Validation:  39%|███▉      | 61/157 [00:04<00:08, 11.21it/s][codecarbon INFO @ 21:49:01] Energy consumed for RAM : 0.002177 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:49:01] Energy consumed for all GPUs : 0.027891 kWh. Total GPU Power : 58.05943019579496 W\n",
            "[codecarbon INFO @ 21:49:01] Energy consumed for all CPUs : 0.019485 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:49:01] 0.049552 kWh of electricity used since the beginning.\n",
            "Epoch 22/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Train Loss: 0.1636, Train Accuracy: 94.44%\n",
            "Epoch [22/30], Val Loss: 0.3372, Val Accuracy: 89.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30 - Training:  12%|█▏        | 78/625 [00:08<01:10,  7.81it/s][codecarbon INFO @ 21:49:16] Energy consumed for RAM : 0.002196 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:49:16] Energy consumed for all GPUs : 0.028108 kWh. Total GPU Power : 52.072025028146015 W\n",
            "[codecarbon INFO @ 21:49:16] Energy consumed for all CPUs : 0.019661 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:49:16] 0.049966 kWh of electricity used since the beginning.\n",
            "Epoch 23/30 - Training:  36%|███▌      | 226/625 [00:23<00:48,  8.23it/s][codecarbon INFO @ 21:49:31] Energy consumed for RAM : 0.002216 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:49:31] Energy consumed for all GPUs : 0.028376 kWh. Total GPU Power : 64.26407746107881 W\n",
            "[codecarbon INFO @ 21:49:31] Energy consumed for all CPUs : 0.019839 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:49:31] 0.050431 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:49:31] 0.007961 g.CO2eq/s mean an estimation of 251.0673935918359 kg.CO2eq/year\n",
            "Epoch 23/30 - Training:  60%|█████▉    | 373/625 [00:38<00:31,  7.99it/s][codecarbon INFO @ 21:49:46] Energy consumed for RAM : 0.002236 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:49:46] Energy consumed for all GPUs : 0.028649 kWh. Total GPU Power : 65.52633006005016 W\n",
            "[codecarbon INFO @ 21:49:46] Energy consumed for all CPUs : 0.020016 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:49:46] 0.050901 kWh of electricity used since the beginning.\n",
            "Epoch 23/30 - Training:  83%|████████▎ | 520/625 [00:53<00:13,  7.77it/s][codecarbon INFO @ 21:50:01] Energy consumed for RAM : 0.002256 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:50:01] Energy consumed for all GPUs : 0.028919 kWh. Total GPU Power : 64.92414100739272 W\n",
            "[codecarbon INFO @ 21:50:01] Energy consumed for all CPUs : 0.020193 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:50:01] 0.051369 kWh of electricity used since the beginning.\n",
            "Epoch 23/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.83it/s]\n",
            "Epoch 23/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 23/30 - Validation:  31%|███       | 49/157 [00:04<00:11,  9.22it/s][codecarbon INFO @ 21:50:16] Energy consumed for RAM : 0.002276 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:50:16] Energy consumed for all GPUs : 0.029160 kWh. Total GPU Power : 57.62293551760882 W\n",
            "Epoch 23/30 - Validation:  34%|███▍      | 53/157 [00:05<00:10,  9.46it/s][codecarbon INFO @ 21:50:16] Energy consumed for all CPUs : 0.020371 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:50:16] 0.051806 kWh of electricity used since the beginning.\n",
            "Epoch 23/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Train Loss: 0.1442, Train Accuracy: 95.20%\n",
            "Epoch [23/30], Val Loss: 0.3364, Val Accuracy: 89.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30 - Training:  12%|█▏        | 78/625 [00:08<01:10,  7.75it/s][codecarbon INFO @ 21:50:31] Energy consumed for RAM : 0.002295 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:50:31] Energy consumed for all GPUs : 0.029381 kWh. Total GPU Power : 53.15268535742208 W\n",
            "[codecarbon INFO @ 21:50:31] Energy consumed for all CPUs : 0.020548 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:50:31] 0.052225 kWh of electricity used since the beginning.\n",
            "Epoch 24/30 - Training:  36%|███▋      | 228/625 [00:23<00:52,  7.61it/s][codecarbon INFO @ 21:50:46] Energy consumed for RAM : 0.002315 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:50:46] Energy consumed for all GPUs : 0.029650 kWh. Total GPU Power : 64.59294743892877 W\n",
            "[codecarbon INFO @ 21:50:46] Energy consumed for all CPUs : 0.020725 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:50:46] 0.052691 kWh of electricity used since the beginning.\n",
            "Epoch 24/30 - Training:  60%|██████    | 377/625 [00:38<00:33,  7.48it/s][codecarbon INFO @ 21:51:01] Energy consumed for RAM : 0.002335 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:51:01] Energy consumed for all GPUs : 0.029923 kWh. Total GPU Power : 65.52118827824765 W\n",
            "[codecarbon INFO @ 21:51:01] Energy consumed for all CPUs : 0.020902 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:51:01] 0.053160 kWh of electricity used since the beginning.\n",
            "Epoch 24/30 - Training:  84%|████████▍ | 525/625 [00:53<00:14,  7.08it/s][codecarbon INFO @ 21:51:16] Energy consumed for RAM : 0.002355 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:51:16] Energy consumed for all GPUs : 0.030192 kWh. Total GPU Power : 64.61960909810817 W\n",
            "[codecarbon INFO @ 21:51:16] Energy consumed for all CPUs : 0.021079 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:51:16] 0.053626 kWh of electricity used since the beginning.\n",
            "Epoch 24/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.91it/s]\n",
            "Epoch 24/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 24/30 - Validation:  39%|███▉      | 62/157 [00:05<00:09,  9.80it/s][codecarbon INFO @ 21:51:31] Energy consumed for RAM : 0.002375 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:51:31] Energy consumed for all GPUs : 0.030429 kWh. Total GPU Power : 56.91339480786743 W\n",
            "[codecarbon INFO @ 21:51:31] Energy consumed for all CPUs : 0.021256 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:51:31] 0.054060 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:51:31] 0.008084 g.CO2eq/s mean an estimation of 254.94238120973287 kg.CO2eq/year\n",
            "Epoch 24/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 14.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Train Loss: 0.1371, Train Accuracy: 95.45%\n",
            "Epoch [24/30], Val Loss: 0.3431, Val Accuracy: 89.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30 - Training:  13%|█▎        | 83/625 [00:09<01:14,  7.24it/s][codecarbon INFO @ 21:51:46] Energy consumed for RAM : 0.002394 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:51:46] Energy consumed for all GPUs : 0.030654 kWh. Total GPU Power : 53.99571432646184 W\n",
            "[codecarbon INFO @ 21:51:46] Energy consumed for all CPUs : 0.021434 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:51:46] 0.054482 kWh of electricity used since the beginning.\n",
            "Epoch 25/30 - Training:  37%|███▋      | 231/625 [00:24<00:50,  7.79it/s][codecarbon INFO @ 21:52:01] Energy consumed for RAM : 0.002414 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:52:01] Energy consumed for all GPUs : 0.030922 kWh. Total GPU Power : 64.50555934279313 W\n",
            "[codecarbon INFO @ 21:52:01] Energy consumed for all CPUs : 0.021610 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:52:01] 0.054946 kWh of electricity used since the beginning.\n",
            "Epoch 25/30 - Training:  61%|██████    | 382/625 [00:39<00:28,  8.65it/s][codecarbon INFO @ 21:52:16] Energy consumed for RAM : 0.002434 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:52:16] Energy consumed for all GPUs : 0.031194 kWh. Total GPU Power : 65.22999097873974 W\n",
            "[codecarbon INFO @ 21:52:16] Energy consumed for all CPUs : 0.021788 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:52:16] 0.055415 kWh of electricity used since the beginning.\n",
            "Epoch 25/30 - Training:  85%|████████▌ | 533/625 [00:54<00:08, 10.36it/s][codecarbon INFO @ 21:52:31] Energy consumed for RAM : 0.002454 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:52:31] Energy consumed for all GPUs : 0.031465 kWh. Total GPU Power : 65.03475427948395 W\n",
            "[codecarbon INFO @ 21:52:31] Energy consumed for all CPUs : 0.021965 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:52:31] 0.055883 kWh of electricity used since the beginning.\n",
            "Epoch 25/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.92it/s]\n",
            "Epoch 25/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 25/30 - Validation:  47%|████▋     | 74/157 [00:06<00:06, 12.60it/s][codecarbon INFO @ 21:52:46] Energy consumed for RAM : 0.002474 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:52:46] Energy consumed for all GPUs : 0.031695 kWh. Total GPU Power : 55.332505856747765 W\n",
            "[codecarbon INFO @ 21:52:46] Energy consumed for all CPUs : 0.022142 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:52:46] 0.056310 kWh of electricity used since the beginning.\n",
            "Epoch 25/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Train Loss: 0.1343, Train Accuracy: 95.58%\n",
            "Epoch [25/30], Val Loss: 0.3307, Val Accuracy: 89.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30 - Training:  15%|█▍        | 93/625 [00:10<00:48, 10.94it/s][codecarbon INFO @ 21:53:01] Energy consumed for RAM : 0.002493 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:53:01] Energy consumed for all GPUs : 0.031925 kWh. Total GPU Power : 55.10818405813705 W\n",
            "[codecarbon INFO @ 21:53:01] Energy consumed for all CPUs : 0.022319 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:53:01] 0.056737 kWh of electricity used since the beginning.\n",
            "Epoch 26/30 - Training:  39%|███▉      | 243/625 [00:25<00:36, 10.37it/s][codecarbon INFO @ 21:53:16] Energy consumed for RAM : 0.002513 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:53:16] Energy consumed for all GPUs : 0.032194 kWh. Total GPU Power : 64.63189487301203 W\n",
            "[codecarbon INFO @ 21:53:16] Energy consumed for all CPUs : 0.022496 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:53:16] 0.057203 kWh of electricity used since the beginning.\n",
            "Epoch 26/30 - Training:  63%|██████▎   | 394/625 [00:40<00:21, 10.98it/s][codecarbon INFO @ 21:53:31] Energy consumed for RAM : 0.002533 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:53:31] Energy consumed for all GPUs : 0.032468 kWh. Total GPU Power : 65.68672974702508 W\n",
            "[codecarbon INFO @ 21:53:31] Energy consumed for all CPUs : 0.022673 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:53:31] 0.057675 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:53:31] 0.008054 g.CO2eq/s mean an estimation of 253.98558110567305 kg.CO2eq/year\n",
            "Epoch 26/30 - Training:  87%|████████▋ | 545/625 [00:55<00:07, 11.08it/s][codecarbon INFO @ 21:53:46] Energy consumed for RAM : 0.002553 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:53:46] Energy consumed for all GPUs : 0.032740 kWh. Total GPU Power : 65.32605638014846 W\n",
            "[codecarbon INFO @ 21:53:46] Energy consumed for all CPUs : 0.022851 kWh. Total CPU Power : 42.5 W\n",
            "Epoch 26/30 - Training:  88%|████████▊ | 547/625 [00:55<00:07, 10.99it/s][codecarbon INFO @ 21:53:46] 0.058144 kWh of electricity used since the beginning.\n",
            "Epoch 26/30 - Training: 100%|██████████| 625/625 [01:02<00:00, 10.00it/s]\n",
            "Epoch 26/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 26/30 - Validation:  63%|██████▎   | 99/157 [00:07<00:03, 16.80it/s][codecarbon INFO @ 21:54:01] Energy consumed for RAM : 0.002573 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:54:01] Energy consumed for all GPUs : 0.032964 kWh. Total GPU Power : 53.648755459930065 W\n",
            "[codecarbon INFO @ 21:54:01] Energy consumed for all CPUs : 0.023028 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:54:01] 0.058564 kWh of electricity used since the beginning.\n",
            "Epoch 26/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 14.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Train Loss: 0.1312, Train Accuracy: 95.64%\n",
            "Epoch [26/30], Val Loss: 0.3359, Val Accuracy: 89.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30 - Training:  18%|█▊        | 110/625 [00:11<00:46, 11.03it/s][codecarbon INFO @ 21:54:16] Energy consumed for RAM : 0.002592 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:54:16] Energy consumed for all GPUs : 0.033205 kWh. Total GPU Power : 57.93247939266332 W\n",
            "[codecarbon INFO @ 21:54:16] Energy consumed for all CPUs : 0.023205 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:54:16] 0.059002 kWh of electricity used since the beginning.\n",
            "Epoch 27/30 - Training:  41%|████▏     | 258/625 [00:26<00:33, 11.07it/s][codecarbon INFO @ 21:54:31] Energy consumed for RAM : 0.002612 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:54:31] Energy consumed for all GPUs : 0.033474 kWh. Total GPU Power : 64.68136913110595 W\n",
            "[codecarbon INFO @ 21:54:31] Energy consumed for all CPUs : 0.023382 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:54:31] 0.059468 kWh of electricity used since the beginning.\n",
            "Epoch 27/30 - Training:  66%|██████▌   | 410/625 [00:41<00:19, 11.02it/s][codecarbon INFO @ 21:54:46] Energy consumed for RAM : 0.002632 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:54:46] Energy consumed for all GPUs : 0.033746 kWh. Total GPU Power : 65.16004161707626 W\n",
            "[codecarbon INFO @ 21:54:46] Energy consumed for all CPUs : 0.023559 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:54:46] 0.059937 kWh of electricity used since the beginning.\n",
            "Epoch 27/30 - Training:  90%|████████▉ | 561/625 [00:56<00:05, 11.00it/s][codecarbon INFO @ 21:55:01] Energy consumed for RAM : 0.002652 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:55:01] Energy consumed for all GPUs : 0.034018 kWh. Total GPU Power : 65.39097499726793 W\n",
            "[codecarbon INFO @ 21:55:01] Energy consumed for all CPUs : 0.023736 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:55:01] 0.060406 kWh of electricity used since the beginning.\n",
            "Epoch 27/30 - Training: 100%|██████████| 625/625 [01:02<00:00,  9.99it/s]\n",
            "Epoch 27/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 27/30 - Validation:  83%|████████▎ | 131/157 [00:09<00:01, 18.13it/s][codecarbon INFO @ 21:55:16] Energy consumed for RAM : 0.002671 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:55:16] Energy consumed for all GPUs : 0.034232 kWh. Total GPU Power : 51.327638488312424 W\n",
            "[codecarbon INFO @ 21:55:16] Energy consumed for all CPUs : 0.023913 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:55:16] 0.060816 kWh of electricity used since the beginning.\n",
            "Epoch 27/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 14.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Train Loss: 0.1220, Train Accuracy: 95.92%\n",
            "Epoch [27/30], Val Loss: 0.3300, Val Accuracy: 90.17%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30 - Training:  21%|██        | 129/625 [00:13<00:45, 11.01it/s][codecarbon INFO @ 21:55:31] Energy consumed for RAM : 0.002691 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:55:31] Energy consumed for all GPUs : 0.034484 kWh. Total GPU Power : 60.73230050134842 W\n",
            "[codecarbon INFO @ 21:55:31] Energy consumed for all CPUs : 0.024090 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:55:31] 0.061266 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:55:31] 0.008001 g.CO2eq/s mean an estimation of 252.32795418256052 kg.CO2eq/year\n",
            "Epoch 28/30 - Training:  45%|████▍     | 280/625 [00:28<00:31, 10.82it/s][codecarbon INFO @ 21:55:46] Energy consumed for RAM : 0.002711 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:55:46] Energy consumed for all GPUs : 0.034755 kWh. Total GPU Power : 64.97126448131692 W\n",
            "[codecarbon INFO @ 21:55:46] Energy consumed for all CPUs : 0.024267 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:55:46] 0.061734 kWh of electricity used since the beginning.\n",
            "Epoch 28/30 - Training:  68%|██████▊   | 428/625 [00:43<00:18, 10.84it/s][codecarbon INFO @ 21:56:01] Energy consumed for RAM : 0.002731 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:56:01] Energy consumed for all GPUs : 0.035026 kWh. Total GPU Power : 65.06022454554783 W\n",
            "[codecarbon INFO @ 21:56:01] Energy consumed for all CPUs : 0.024445 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:56:01] 0.062202 kWh of electricity used since the beginning.\n",
            "Epoch 28/30 - Training:  92%|█████████▏| 578/625 [00:58<00:04, 11.03it/s][codecarbon INFO @ 21:56:16] Energy consumed for RAM : 0.002751 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:56:16] Energy consumed for all GPUs : 0.035295 kWh. Total GPU Power : 64.61421106123933 W\n",
            "[codecarbon INFO @ 21:56:16] Energy consumed for all CPUs : 0.024622 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:56:16] 0.062668 kWh of electricity used since the beginning.\n",
            "Epoch 28/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.91it/s]\n",
            "Epoch 28/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 28/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 15.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Train Loss: 0.1188, Train Accuracy: 95.89%\n",
            "Epoch [28/30], Val Loss: 0.3258, Val Accuracy: 89.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 29/30 - Training:   0%|          | 0/625 [00:00<?, ?it/s][codecarbon INFO @ 21:56:31] Energy consumed for RAM : 0.002770 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:56:31] Energy consumed for all GPUs : 0.035502 kWh. Total GPU Power : 49.5397217325232 W\n",
            "[codecarbon INFO @ 21:56:31] Energy consumed for all CPUs : 0.024799 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:56:31] 0.063071 kWh of electricity used since the beginning.\n",
            "Epoch 29/30 - Training:  23%|██▎       | 146/625 [00:15<00:43, 11.01it/s][codecarbon INFO @ 21:56:46] Energy consumed for RAM : 0.002790 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:56:46] Energy consumed for all GPUs : 0.035764 kWh. Total GPU Power : 62.80500163678455 W\n",
            "[codecarbon INFO @ 21:56:46] Energy consumed for all CPUs : 0.024976 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:56:46] 0.063530 kWh of electricity used since the beginning.\n",
            "Epoch 29/30 - Training:  47%|████▋     | 294/625 [00:30<00:29, 11.12it/s][codecarbon INFO @ 21:57:01] Energy consumed for RAM : 0.002810 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:57:01] Energy consumed for all GPUs : 0.036033 kWh. Total GPU Power : 64.74273483169993 W\n",
            "Epoch 29/30 - Training:  47%|████▋     | 296/625 [00:30<00:29, 11.02it/s][codecarbon INFO @ 21:57:01] Energy consumed for all CPUs : 0.025153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:57:01] 0.063997 kWh of electricity used since the beginning.\n",
            "Epoch 29/30 - Training:  71%|███████   | 445/625 [00:45<00:16, 10.87it/s][codecarbon INFO @ 21:57:16] Energy consumed for RAM : 0.002830 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:57:16] Energy consumed for all GPUs : 0.036308 kWh. Total GPU Power : 65.8588732866018 W\n",
            "[codecarbon INFO @ 21:57:16] Energy consumed for all CPUs : 0.025330 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:57:16] 0.064468 kWh of electricity used since the beginning.\n",
            "Epoch 29/30 - Training:  95%|█████████▌| 594/625 [01:00<00:02, 11.01it/s][codecarbon INFO @ 21:57:31] Energy consumed for RAM : 0.002850 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:57:31] Energy consumed for all GPUs : 0.036577 kWh. Total GPU Power : 64.7224568539854 W\n",
            "[codecarbon INFO @ 21:57:31] Energy consumed for all CPUs : 0.025508 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:57:31] 0.064935 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 21:57:31] 0.008174 g.CO2eq/s mean an estimation of 257.77600065434746 kg.CO2eq/year\n",
            "Epoch 29/30 - Training: 100%|██████████| 625/625 [01:03<00:00,  9.91it/s]\n",
            "Epoch 29/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 29/30 - Validation: 100%|██████████| 157/157 [00:10<00:00, 14.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Train Loss: 0.1124, Train Accuracy: 96.23%\n",
            "Epoch [29/30], Val Loss: 0.3297, Val Accuracy: 89.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30 - Training:   2%|▏         | 10/625 [00:01<01:02,  9.90it/s][codecarbon INFO @ 21:57:46] Energy consumed for RAM : 0.002869 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:57:46] Energy consumed for all GPUs : 0.036778 kWh. Total GPU Power : 48.21986379037768 W\n",
            "[codecarbon INFO @ 21:57:46] Energy consumed for all CPUs : 0.025685 kWh. Total CPU Power : 42.5 W\n",
            "Epoch 30/30 - Training:   2%|▏         | 12/625 [00:01<01:01,  9.93it/s][codecarbon INFO @ 21:57:46] 0.065333 kWh of electricity used since the beginning.\n",
            "Epoch 30/30 - Training:  26%|██▌       | 160/625 [00:16<00:42, 10.86it/s][codecarbon INFO @ 21:58:01] Energy consumed for RAM : 0.002889 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:58:01] Energy consumed for all GPUs : 0.037046 kWh. Total GPU Power : 64.2501436318214 W\n",
            "[codecarbon INFO @ 21:58:01] Energy consumed for all CPUs : 0.025862 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:58:01] 0.065797 kWh of electricity used since the beginning.\n",
            "Epoch 30/30 - Training:  50%|█████     | 313/625 [00:31<00:28, 11.04it/s][codecarbon INFO @ 21:58:16] Energy consumed for RAM : 0.002909 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:58:16] Energy consumed for all GPUs : 0.037317 kWh. Total GPU Power : 65.2689414003716 W\n",
            "[codecarbon INFO @ 21:58:16] Energy consumed for all CPUs : 0.026039 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:58:16] 0.066264 kWh of electricity used since the beginning.\n",
            "Epoch 30/30 - Training:  74%|███████▍  | 463/625 [00:46<00:14, 10.97it/s][codecarbon INFO @ 21:58:31] Energy consumed for RAM : 0.002929 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:58:31] Energy consumed for all GPUs : 0.037589 kWh. Total GPU Power : 65.45277409258085 W\n",
            "[codecarbon INFO @ 21:58:31] Energy consumed for all CPUs : 0.026216 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:58:31] 0.066734 kWh of electricity used since the beginning.\n",
            "Epoch 30/30 - Training:  98%|█████████▊| 614/625 [01:01<00:01, 10.94it/s][codecarbon INFO @ 21:58:46] Energy consumed for RAM : 0.002948 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:58:46] Energy consumed for all GPUs : 0.037859 kWh. Total GPU Power : 64.76919562782827 W\n",
            "[codecarbon INFO @ 21:58:46] Energy consumed for all CPUs : 0.026393 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:58:46] 0.067200 kWh of electricity used since the beginning.\n",
            "Epoch 30/30 - Training: 100%|██████████| 625/625 [01:02<00:00,  9.96it/s]\n",
            "Epoch 30/30 - Validation:   0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 30/30 - Validation: 100%|██████████| 157/157 [00:11<00:00, 13.80it/s]\n",
            "[codecarbon INFO @ 21:58:59] Energy consumed for RAM : 0.002965 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 21:58:59] Energy consumed for all GPUs : 0.038012 kWh. Total GPU Power : 44.08213445934943 W\n",
            "[codecarbon INFO @ 21:58:59] Energy consumed for all CPUs : 0.026541 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 21:58:59] 0.067517 kWh of electricity used since the beginning.\n",
            "/usr/local/lib/python3.10/dist-packages/codecarbon/output_methods/file.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, pd.DataFrame.from_records([dict(total.values)])])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Train Loss: 0.1100, Train Accuracy: 96.37%\n",
            "Epoch [30/30], Val Loss: 0.3232, Val Accuracy: 90.37%\n",
            "\n",
            "--- Model Analysis ---\n",
            "Parameter Count: 134301514\n",
            "Model Size: 512.33 MB\n",
            "FLOPs: 0.43 GFLOPs\n",
            "Training Time: 2249.39 seconds\n",
            "Average Inference Time: 0.003655 seconds\n",
            "\n",
            "--- Energy and Emissions Report ---\n",
            "CO2 Emissions (CodeCarbon): 0.018069 kg\n",
            "Average GPU Power Consumption: 64.05 W\n",
            "Total GPU Energy Consumption: 40.018244 kWh\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models, datasets, transforms\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import codecarbon\n",
        "from thop import profile\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the transforms for the dataset with additional augmentations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "full_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Split the full training dataset into training and validation sets (80% train, 20% validation)\n",
        "train_size = int(0.8 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders for the train, validation, and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Print dataset sizes for debugging\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")\n",
        "\n",
        "# Load the pretrained VGG16 model and modify the classifier\n",
        "model = models.vgg16(pretrained=True)\n",
        "input_lastLayer = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Sequential(\n",
        "    nn.Dropout(0.5),  # Increased dropout for regularization\n",
        "    nn.Linear(input_lastLayer, 10)\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer with learning rate scheduler\n",
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# Tracking metrics for analysis\n",
        "train_losses, val_losses = [], []\n",
        "train_accuracies, val_accuracies = [], []\n",
        "\n",
        "# Use CodeCarbon for system-wide energy consumption tracking\n",
        "tracker = codecarbon.EmissionsTracker()\n",
        "tracker.start()\n",
        "\n",
        "# Function to get GPU power consumption using nvidia-smi\n",
        "def get_gpu_power():\n",
        "    try:\n",
        "        # Query power.draw from nvidia-smi\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,nounits,noheader'],\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True\n",
        "        )\n",
        "        power_draws = result.stdout.strip().split('\\n')\n",
        "        power_draws = [float(p) for p in power_draws]\n",
        "        avg_power_draw = sum(power_draws) / len(power_draws)  # Average power across GPUs\n",
        "        return avg_power_draw  # in watts\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting GPU power: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# Tracking GPU-specific energy consumption\n",
        "gpu_power_readings = []\n",
        "\n",
        "# Training loop with GPU power monitoring\n",
        "epochs = 30\n",
        "start_training_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        # Record GPU power usage\n",
        "        gpu_power_readings.append(get_gpu_power())\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "    # Append metrics for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_val_loss += loss.item()\n",
        "\n",
        "            # Calculate validation accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = running_val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "\n",
        "    # Append metrics for plotting\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Adjust learning rate based on validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "training_time = time.time() - start_training_time\n",
        "\n",
        "# Stop the CodeCarbon tracker after training\n",
        "emissions = tracker.stop()\n",
        "\n",
        "# Calculate average GPU power and total GPU energy consumption (in kWh)\n",
        "avg_gpu_power = sum(gpu_power_readings) / len(gpu_power_readings) if gpu_power_readings else 0.0\n",
        "energy_consumption_gpu = (avg_gpu_power * training_time) / 3600  # Convert to kWh\n",
        "\n",
        "# Save the model after training\n",
        "model_path = \"trained_vgg16_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "\n",
        "# Model analysis metrics\n",
        "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "torch.save(model.state_dict(), \"temp_model.pth\")\n",
        "model_size = os.path.getsize(\"temp_model.pth\") / (1024 * 1024)  # Convert bytes to MB\n",
        "os.remove(\"temp_model.pth\")\n",
        "\n",
        "# FLOPs calculation\n",
        "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "flops, _ = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "\n",
        "# Inference time calculation\n",
        "model.eval()\n",
        "inference_start = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = model(dummy_input)\n",
        "inference_time = (time.time() - inference_start) / 100\n",
        "\n",
        "# Final energy and emissions report\n",
        "print(\"\\n--- Model Analysis ---\")\n",
        "print(f\"Parameter Count: {param_count}\")\n",
        "print(f\"Model Size: {model_size:.2f} MB\")\n",
        "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Average Inference Time: {inference_time:.6f} seconds\")\n",
        "\n",
        "print(\"\\n--- Energy and Emissions Report ---\")\n",
        "print(f\"CO2 Emissions (CodeCarbon): {emissions:.6f} kg\")\n",
        "print(f\"Average GPU Power Consumption: {avg_gpu_power:.2f} W\")\n",
        "print(f\"Total GPU Energy Consumption: {energy_consumption_gpu:.6f} kWh\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EbFQrp5sXlSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81fb75b6-5ad4-4670-9494-c3835e339c5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-6-b462679c7e6e>:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  teacher_model.load_state_dict(torch.load(\"trained_vgg16_model.pth\"))  # Load the downloaded teacher model\n",
            "[codecarbon INFO @ 22:01:17] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 22:01:17] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 22:01:17] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 22:01:17] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 22:01:17] No CPU tracking mode found. Falling back on CPU constant mode. \n",
            " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
            "\n",
            "[codecarbon WARNING @ 22:01:18] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 22:01:18] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 22:01:18] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 22:01:18]   Platform system: Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "[codecarbon INFO @ 22:01:18]   Python version: 3.10.12\n",
            "[codecarbon INFO @ 22:01:18]   CodeCarbon version: 2.7.4\n",
            "[codecarbon INFO @ 22:01:18]   Available RAM : 12.675 GB\n",
            "[codecarbon INFO @ 22:01:18]   CPU count: 2\n",
            "[codecarbon INFO @ 22:01:18]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "[codecarbon INFO @ 22:01:18]   GPU count: 1\n",
            "[codecarbon INFO @ 22:01:18]   GPU model: 1 x Tesla T4\n",
            "[codecarbon INFO @ 22:01:18] Saving emissions data to file /content/emissions.csv\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:01:33] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:01:33] Energy consumed for all GPUs : 0.000266 kWh. Total GPU Power : 63.64868926076116 W\n",
            "[codecarbon INFO @ 22:01:33] Energy consumed for all CPUs : 0.000178 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:01:33] 0.000463 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:01:48] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:01:48] Energy consumed for all GPUs : 0.000543 kWh. Total GPU Power : 66.6526273221675 W\n",
            "[codecarbon INFO @ 22:01:48] Energy consumed for all CPUs : 0.000355 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:01:48] 0.000937 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:02:03] Energy consumed for RAM : 0.000059 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:02:03] Energy consumed for all GPUs : 0.000820 kWh. Total GPU Power : 66.47755136703745 W\n",
            "[codecarbon INFO @ 22:02:03] Energy consumed for all CPUs : 0.000532 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:02:03] 0.001411 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:02:18] Energy consumed for RAM : 0.000079 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:02:18] Energy consumed for all GPUs : 0.001095 kWh. Total GPU Power : 66.03250724540419 W\n",
            "[codecarbon INFO @ 22:02:18] Energy consumed for all CPUs : 0.000709 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:02:18] 0.001883 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:02:33] Energy consumed for RAM : 0.000099 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:02:33] Energy consumed for all GPUs : 0.001369 kWh. Total GPU Power : 65.70279088500673 W\n",
            "[codecarbon INFO @ 22:02:33] Energy consumed for all CPUs : 0.000886 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:02:33] 0.002353 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 6.3950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:02:48] Energy consumed for RAM : 0.000119 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:02:48] Energy consumed for all GPUs : 0.001639 kWh. Total GPU Power : 64.81371435116044 W\n",
            "[codecarbon INFO @ 22:02:48] Energy consumed for all CPUs : 0.001063 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:02:48] 0.002821 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:03:03] Energy consumed for RAM : 0.000139 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:03:03] Energy consumed for all GPUs : 0.001914 kWh. Total GPU Power : 66.04753882456647 W\n",
            "[codecarbon INFO @ 22:03:03] Energy consumed for all CPUs : 0.001240 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:03:03] 0.003293 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:03:18] Energy consumed for RAM : 0.000158 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:03:18] Energy consumed for all GPUs : 0.002189 kWh. Total GPU Power : 66.16657185108218 W\n",
            "[codecarbon INFO @ 22:03:18] Energy consumed for all CPUs : 0.001417 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:03:18] 0.003765 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:03:18] 0.008390 g.CO2eq/s mean an estimation of 264.5715767903906 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:03:33] Energy consumed for RAM : 0.000178 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:03:33] Energy consumed for all GPUs : 0.002466 kWh. Total GPU Power : 66.37552115122267 W\n",
            "[codecarbon INFO @ 22:03:33] Energy consumed for all CPUs : 0.001595 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:03:33] 0.004238 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:03:48] Energy consumed for RAM : 0.000198 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:03:48] Energy consumed for all GPUs : 0.002740 kWh. Total GPU Power : 65.90891972245498 W\n",
            "[codecarbon INFO @ 22:03:48] Energy consumed for all CPUs : 0.001771 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:03:48] 0.004709 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30], Loss: 5.4064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:04:03] Energy consumed for RAM : 0.000218 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:04:03] Energy consumed for all GPUs : 0.003014 kWh. Total GPU Power : 65.64827189095755 W\n",
            "[codecarbon INFO @ 22:04:03] Energy consumed for all CPUs : 0.001949 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:04:03] 0.005180 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:04:18] Energy consumed for RAM : 0.000237 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:04:18] Energy consumed for all GPUs : 0.003289 kWh. Total GPU Power : 65.9838910091664 W\n",
            "[codecarbon INFO @ 22:04:18] Energy consumed for all CPUs : 0.002126 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:04:18] 0.005652 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:04:33] Energy consumed for RAM : 0.000257 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:04:33] Energy consumed for all GPUs : 0.003565 kWh. Total GPU Power : 66.1085512234769 W\n",
            "[codecarbon INFO @ 22:04:33] Energy consumed for all CPUs : 0.002303 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:04:33] 0.006125 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:04:48] Energy consumed for RAM : 0.000277 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:04:48] Energy consumed for all GPUs : 0.003840 kWh. Total GPU Power : 66.15208357642761 W\n",
            "[codecarbon INFO @ 22:04:48] Energy consumed for all CPUs : 0.002481 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:04:48] 0.006598 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:05:03] Energy consumed for RAM : 0.000297 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:05:03] Energy consumed for all GPUs : 0.004114 kWh. Total GPU Power : 65.799242628245 W\n",
            "[codecarbon INFO @ 22:05:03] Energy consumed for all CPUs : 0.002658 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:05:03] 0.007069 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30], Loss: 4.4441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:05:18] Energy consumed for RAM : 0.000317 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:05:18] Energy consumed for all GPUs : 0.004388 kWh. Total GPU Power : 65.68682484131229 W\n",
            "[codecarbon INFO @ 22:05:18] Energy consumed for all CPUs : 0.002835 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:05:18] 0.007540 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:05:18] 0.008411 g.CO2eq/s mean an estimation of 265.23825364210956 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:05:33] Energy consumed for RAM : 0.000337 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:05:33] Energy consumed for all GPUs : 0.004663 kWh. Total GPU Power : 65.9093364160082 W\n",
            "[codecarbon INFO @ 22:05:33] Energy consumed for all CPUs : 0.003012 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:05:33] 0.008011 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:05:48] Energy consumed for RAM : 0.000356 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:05:48] Energy consumed for all GPUs : 0.004938 kWh. Total GPU Power : 66.09770533261157 W\n",
            "[codecarbon INFO @ 22:05:48] Energy consumed for all CPUs : 0.003189 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:05:48] 0.008483 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:06:03] Energy consumed for RAM : 0.000376 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:06:03] Energy consumed for all GPUs : 0.005213 kWh. Total GPU Power : 65.90575296266834 W\n",
            "[codecarbon INFO @ 22:06:03] Energy consumed for all CPUs : 0.003366 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:06:03] 0.008955 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:06:18] Energy consumed for RAM : 0.000396 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:06:18] Energy consumed for all GPUs : 0.005487 kWh. Total GPU Power : 65.89469817856606 W\n",
            "[codecarbon INFO @ 22:06:18] Energy consumed for all CPUs : 0.003543 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:06:18] 0.009426 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30], Loss: 3.7963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:06:33] Energy consumed for RAM : 0.000416 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:06:33] Energy consumed for all GPUs : 0.005757 kWh. Total GPU Power : 64.76916082350151 W\n",
            "[codecarbon INFO @ 22:06:33] Energy consumed for all CPUs : 0.003720 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:06:33] 0.009893 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:06:48] Energy consumed for RAM : 0.000435 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:06:48] Energy consumed for all GPUs : 0.006032 kWh. Total GPU Power : 66.0129879800904 W\n",
            "[codecarbon INFO @ 22:06:48] Energy consumed for all CPUs : 0.003898 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:06:48] 0.010365 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:07:03] Energy consumed for RAM : 0.000455 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:07:03] Energy consumed for all GPUs : 0.006307 kWh. Total GPU Power : 66.18263169744547 W\n",
            "[codecarbon INFO @ 22:07:03] Energy consumed for all CPUs : 0.004075 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:07:03] 0.010837 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:07:18] Energy consumed for RAM : 0.000475 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:07:18] Energy consumed for all GPUs : 0.006581 kWh. Total GPU Power : 65.81841752317393 W\n",
            "[codecarbon INFO @ 22:07:18] Energy consumed for all CPUs : 0.004252 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:07:18] 0.011308 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:07:18] 0.008401 g.CO2eq/s mean an estimation of 264.9247120637458 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:07:33] Energy consumed for RAM : 0.000495 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:07:33] Energy consumed for all GPUs : 0.006856 kWh. Total GPU Power : 65.83157722845314 W\n",
            "[codecarbon INFO @ 22:07:33] Energy consumed for all CPUs : 0.004429 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:07:33] 0.011779 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30], Loss: 3.3189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:07:48] Energy consumed for RAM : 0.000515 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:07:48] Energy consumed for all GPUs : 0.007122 kWh. Total GPU Power : 63.875822750916775 W\n",
            "[codecarbon INFO @ 22:07:48] Energy consumed for all CPUs : 0.004606 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:07:48] 0.012242 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:08:03] Energy consumed for RAM : 0.000534 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:08:03] Energy consumed for all GPUs : 0.007397 kWh. Total GPU Power : 65.9009419561148 W\n",
            "[codecarbon INFO @ 22:08:03] Energy consumed for all CPUs : 0.004783 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:08:03] 0.012714 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:08:18] Energy consumed for RAM : 0.000554 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:08:18] Energy consumed for all GPUs : 0.007671 kWh. Total GPU Power : 65.75934736688558 W\n",
            "[codecarbon INFO @ 22:08:18] Energy consumed for all CPUs : 0.004960 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:08:18] 0.013185 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:08:33] Energy consumed for RAM : 0.000574 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:08:33] Energy consumed for all GPUs : 0.007946 kWh. Total GPU Power : 66.0858825131499 W\n",
            "[codecarbon INFO @ 22:08:33] Energy consumed for all CPUs : 0.005138 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:08:33] 0.013658 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:08:48] Energy consumed for RAM : 0.000594 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:08:48] Energy consumed for all GPUs : 0.008220 kWh. Total GPU Power : 65.72708059801606 W\n",
            "[codecarbon INFO @ 22:08:48] Energy consumed for all CPUs : 0.005315 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:08:48] 0.014128 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30], Loss: 2.8526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:09:03] Energy consumed for RAM : 0.000614 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:09:03] Energy consumed for all GPUs : 0.008491 kWh. Total GPU Power : 65.15775458465848 W\n",
            "[codecarbon INFO @ 22:09:03] Energy consumed for all CPUs : 0.005492 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:09:03] 0.014598 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:09:18] Energy consumed for RAM : 0.000633 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:09:18] Energy consumed for all GPUs : 0.008766 kWh. Total GPU Power : 66.0087203631445 W\n",
            "[codecarbon INFO @ 22:09:18] Energy consumed for all CPUs : 0.005670 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:09:18] 0.015070 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:09:18] 0.008377 g.CO2eq/s mean an estimation of 264.17263742298115 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:09:33] Energy consumed for RAM : 0.000653 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:09:33] Energy consumed for all GPUs : 0.009043 kWh. Total GPU Power : 66.40535090825473 W\n",
            "[codecarbon INFO @ 22:09:33] Energy consumed for all CPUs : 0.005847 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:09:33] 0.015543 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:09:48] Energy consumed for RAM : 0.000673 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:09:48] Energy consumed for all GPUs : 0.009318 kWh. Total GPU Power : 65.92800770626374 W\n",
            "[codecarbon INFO @ 22:09:48] Energy consumed for all CPUs : 0.006024 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:09:48] 0.016015 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:10:03] Energy consumed for RAM : 0.000693 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:10:03] Energy consumed for all GPUs : 0.009593 kWh. Total GPU Power : 65.99369114910633 W\n",
            "[codecarbon INFO @ 22:10:03] Energy consumed for all CPUs : 0.006201 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:10:03] 0.016487 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Loss: 2.5362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:10:18] Energy consumed for RAM : 0.000713 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:10:18] Energy consumed for all GPUs : 0.009865 kWh. Total GPU Power : 65.14127184296409 W\n",
            "[codecarbon INFO @ 22:10:18] Energy consumed for all CPUs : 0.006379 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:10:18] 0.016956 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:10:33] Energy consumed for RAM : 0.000732 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:10:33] Energy consumed for all GPUs : 0.010138 kWh. Total GPU Power : 65.69884727583403 W\n",
            "[codecarbon INFO @ 22:10:33] Energy consumed for all CPUs : 0.006555 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:10:33] 0.017426 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:10:48] Energy consumed for RAM : 0.000752 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:10:48] Energy consumed for all GPUs : 0.010412 kWh. Total GPU Power : 65.7827011066298 W\n",
            "[codecarbon INFO @ 22:10:48] Energy consumed for all CPUs : 0.006732 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:10:48] 0.017896 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:11:03] Energy consumed for RAM : 0.000772 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:11:03] Energy consumed for all GPUs : 0.010686 kWh. Total GPU Power : 65.77974809776624 W\n",
            "[codecarbon INFO @ 22:11:03] Energy consumed for all CPUs : 0.006910 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:11:03] 0.018368 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:11:18] Energy consumed for RAM : 0.000792 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:11:18] Energy consumed for all GPUs : 0.010961 kWh. Total GPU Power : 66.07561497001036 W\n",
            "[codecarbon INFO @ 22:11:18] Energy consumed for all CPUs : 0.007087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:11:18] 0.018839 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:11:18] 0.008402 g.CO2eq/s mean an estimation of 264.97999062583955 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Loss: 2.2563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:11:33] Energy consumed for RAM : 0.000812 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:11:33] Energy consumed for all GPUs : 0.011231 kWh. Total GPU Power : 64.91991548886676 W\n",
            "[codecarbon INFO @ 22:11:33] Energy consumed for all CPUs : 0.007264 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:11:33] 0.019307 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:11:48] Energy consumed for RAM : 0.000831 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:11:48] Energy consumed for all GPUs : 0.011506 kWh. Total GPU Power : 65.85593879297296 W\n",
            "[codecarbon INFO @ 22:11:48] Energy consumed for all CPUs : 0.007441 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:11:48] 0.019778 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:12:03] Energy consumed for RAM : 0.000851 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:12:03] Energy consumed for all GPUs : 0.011781 kWh. Total GPU Power : 66.01552456591091 W\n",
            "[codecarbon INFO @ 22:12:03] Energy consumed for all CPUs : 0.007618 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:12:03] 0.020250 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:12:18] Energy consumed for RAM : 0.000871 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:12:18] Energy consumed for all GPUs : 0.012055 kWh. Total GPU Power : 65.95859705874284 W\n",
            "[codecarbon INFO @ 22:12:18] Energy consumed for all CPUs : 0.007795 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:12:18] 0.020722 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:12:33] Energy consumed for RAM : 0.000891 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:12:33] Energy consumed for all GPUs : 0.012331 kWh. Total GPU Power : 66.03027315204994 W\n",
            "[codecarbon INFO @ 22:12:33] Energy consumed for all CPUs : 0.007972 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:12:33] 0.021194 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Loss: 2.0755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:12:48] Energy consumed for RAM : 0.000911 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:12:48] Energy consumed for all GPUs : 0.012602 kWh. Total GPU Power : 65.22799069813699 W\n",
            "[codecarbon INFO @ 22:12:48] Energy consumed for all CPUs : 0.008150 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:12:48] 0.021663 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:13:03] Energy consumed for RAM : 0.000930 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:13:03] Energy consumed for all GPUs : 0.012876 kWh. Total GPU Power : 65.74045672744568 W\n",
            "[codecarbon INFO @ 22:13:03] Energy consumed for all CPUs : 0.008327 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:13:03] 0.022133 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:13:18] Energy consumed for RAM : 0.000950 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:13:18] Energy consumed for all GPUs : 0.013150 kWh. Total GPU Power : 65.79531899838459 W\n",
            "[codecarbon INFO @ 22:13:18] Energy consumed for all CPUs : 0.008504 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:13:18] 0.022604 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:13:18] 0.008391 g.CO2eq/s mean an estimation of 264.621034824018 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:13:33] Energy consumed for RAM : 0.000970 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:13:33] Energy consumed for all GPUs : 0.013426 kWh. Total GPU Power : 66.26515222204044 W\n",
            "[codecarbon INFO @ 22:13:33] Energy consumed for all CPUs : 0.008681 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:13:33] 0.023077 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:13:48] Energy consumed for RAM : 0.000990 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:13:49] Energy consumed for all GPUs : 0.013702 kWh. Total GPU Power : 66.0247567381818 W\n",
            "[codecarbon INFO @ 22:13:49] Energy consumed for all CPUs : 0.008858 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:13:49] 0.023550 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Loss: 1.9930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:14:04] Energy consumed for RAM : 0.001010 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:14:04] Energy consumed for all GPUs : 0.013972 kWh. Total GPU Power : 64.91607431928436 W\n",
            "[codecarbon INFO @ 22:14:04] Energy consumed for all CPUs : 0.009035 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:14:04] 0.024017 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:14:19] Energy consumed for RAM : 0.001029 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:14:19] Energy consumed for all GPUs : 0.014246 kWh. Total GPU Power : 65.85726694776348 W\n",
            "[codecarbon INFO @ 22:14:19] Energy consumed for all CPUs : 0.009212 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:14:19] 0.024488 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:14:34] Energy consumed for RAM : 0.001049 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:14:34] Energy consumed for all GPUs : 0.014522 kWh. Total GPU Power : 66.187248770634 W\n",
            "[codecarbon INFO @ 22:14:34] Energy consumed for all CPUs : 0.009389 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:14:34] 0.024960 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:14:49] Energy consumed for RAM : 0.001069 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:14:49] Energy consumed for all GPUs : 0.014797 kWh. Total GPU Power : 65.933150425012 W\n",
            "[codecarbon INFO @ 22:14:49] Energy consumed for all CPUs : 0.009567 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:14:49] 0.025432 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:15:04] Energy consumed for RAM : 0.001089 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:15:04] Energy consumed for all GPUs : 0.015070 kWh. Total GPU Power : 65.61420536148847 W\n",
            "[codecarbon INFO @ 22:15:04] Energy consumed for all CPUs : 0.009744 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:15:04] 0.025904 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Loss: 1.9661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:15:19] Energy consumed for RAM : 0.001109 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:15:19] Energy consumed for all GPUs : 0.015341 kWh. Total GPU Power : 64.88115351860287 W\n",
            "[codecarbon INFO @ 22:15:19] Energy consumed for all CPUs : 0.009921 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:15:19] 0.026370 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:15:19] 0.008391 g.CO2eq/s mean an estimation of 264.6244667411025 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:15:34] Energy consumed for RAM : 0.001128 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:15:34] Energy consumed for all GPUs : 0.015614 kWh. Total GPU Power : 65.68017251951866 W\n",
            "[codecarbon INFO @ 22:15:34] Energy consumed for all CPUs : 0.010098 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:15:34] 0.026841 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:15:49] Energy consumed for RAM : 0.001148 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:15:49] Energy consumed for all GPUs : 0.015889 kWh. Total GPU Power : 66.0129939201467 W\n",
            "[codecarbon INFO @ 22:15:49] Energy consumed for all CPUs : 0.010275 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:15:49] 0.027312 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:16:04] Energy consumed for RAM : 0.001168 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:16:04] Energy consumed for all GPUs : 0.016164 kWh. Total GPU Power : 65.94336144711387 W\n",
            "[codecarbon INFO @ 22:16:04] Energy consumed for all CPUs : 0.010453 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:16:04] 0.027784 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:16:19] Energy consumed for RAM : 0.001188 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:16:19] Energy consumed for all GPUs : 0.016438 kWh. Total GPU Power : 65.87468094610485 W\n",
            "[codecarbon INFO @ 22:16:19] Energy consumed for all CPUs : 0.010630 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:16:19] 0.028256 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Loss: 1.9530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:16:34] Energy consumed for RAM : 0.001208 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:16:34] Energy consumed for all GPUs : 0.016710 kWh. Total GPU Power : 65.19676229823902 W\n",
            "[codecarbon INFO @ 22:16:34] Energy consumed for all CPUs : 0.010807 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:16:34] 0.028725 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:16:49] Energy consumed for RAM : 0.001227 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:16:49] Energy consumed for all GPUs : 0.016986 kWh. Total GPU Power : 66.38893500074958 W\n",
            "[codecarbon INFO @ 22:16:49] Energy consumed for all CPUs : 0.010984 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:16:49] 0.029197 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:17:04] Energy consumed for RAM : 0.001247 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:17:04] Energy consumed for all GPUs : 0.017262 kWh. Total GPU Power : 66.0901907502307 W\n",
            "[codecarbon INFO @ 22:17:04] Energy consumed for all CPUs : 0.011161 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:17:04] 0.029670 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:17:19] Energy consumed for RAM : 0.001267 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:17:19] Energy consumed for all GPUs : 0.017537 kWh. Total GPU Power : 66.14496473020162 W\n",
            "[codecarbon INFO @ 22:17:19] Energy consumed for all CPUs : 0.011339 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:17:19] 0.030143 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:17:19] 0.008406 g.CO2eq/s mean an estimation of 265.1052076212373 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Loss: 1.9680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:17:34] Energy consumed for RAM : 0.001287 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:17:34] Energy consumed for all GPUs : 0.017809 kWh. Total GPU Power : 65.24596640697624 W\n",
            "[codecarbon INFO @ 22:17:34] Energy consumed for all CPUs : 0.011516 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:17:34] 0.030612 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:17:49] Energy consumed for RAM : 0.001306 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:17:49] Energy consumed for all GPUs : 0.018084 kWh. Total GPU Power : 65.9166933007098 W\n",
            "[codecarbon INFO @ 22:17:49] Energy consumed for all CPUs : 0.011693 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:17:49] 0.031083 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:18:04] Energy consumed for RAM : 0.001326 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:18:04] Energy consumed for all GPUs : 0.018360 kWh. Total GPU Power : 66.22192113858497 W\n",
            "[codecarbon INFO @ 22:18:04] Energy consumed for all CPUs : 0.011870 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:18:04] 0.031556 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:18:19] Energy consumed for RAM : 0.001346 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:18:19] Energy consumed for all GPUs : 0.018635 kWh. Total GPU Power : 66.16058348562109 W\n",
            "[codecarbon INFO @ 22:18:19] Energy consumed for all CPUs : 0.012047 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:18:19] 0.032028 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:18:34] Energy consumed for RAM : 0.001366 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:18:34] Energy consumed for all GPUs : 0.018909 kWh. Total GPU Power : 65.76975660416925 W\n",
            "[codecarbon INFO @ 22:18:34] Energy consumed for all CPUs : 0.012224 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:18:34] 0.032499 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Loss: 1.9882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:18:49] Energy consumed for RAM : 0.001386 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:18:49] Energy consumed for all GPUs : 0.019181 kWh. Total GPU Power : 65.23447001517026 W\n",
            "[codecarbon INFO @ 22:18:49] Energy consumed for all CPUs : 0.012401 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:18:49] 0.032968 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:19:04] Energy consumed for RAM : 0.001405 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:19:04] Energy consumed for all GPUs : 0.019456 kWh. Total GPU Power : 66.12185620027654 W\n",
            "[codecarbon INFO @ 22:19:04] Energy consumed for all CPUs : 0.012578 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:19:04] 0.033440 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:19:19] Energy consumed for RAM : 0.001425 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:19:19] Energy consumed for all GPUs : 0.019733 kWh. Total GPU Power : 66.32285949585005 W\n",
            "[codecarbon INFO @ 22:19:19] Energy consumed for all CPUs : 0.012756 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:19:19] 0.033914 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:19:19] 0.008404 g.CO2eq/s mean an estimation of 265.02101098482706 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:19:34] Energy consumed for RAM : 0.001445 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:19:34] Energy consumed for all GPUs : 0.020008 kWh. Total GPU Power : 66.10263967484909 W\n",
            "[codecarbon INFO @ 22:19:34] Energy consumed for all CPUs : 0.012933 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:19:34] 0.034385 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:19:49] Energy consumed for RAM : 0.001465 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:19:49] Energy consumed for all GPUs : 0.020283 kWh. Total GPU Power : 66.16968061548822 W\n",
            "[codecarbon INFO @ 22:19:49] Energy consumed for all CPUs : 0.013110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:19:49] 0.034858 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Loss: 1.9947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:20:04] Energy consumed for RAM : 0.001485 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:20:04] Energy consumed for all GPUs : 0.020557 kWh. Total GPU Power : 65.84203796803003 W\n",
            "[codecarbon INFO @ 22:20:04] Energy consumed for all CPUs : 0.013287 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:20:04] 0.035329 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:20:19] Energy consumed for RAM : 0.001504 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:20:19] Energy consumed for all GPUs : 0.020832 kWh. Total GPU Power : 65.9999967184987 W\n",
            "[codecarbon INFO @ 22:20:19] Energy consumed for all CPUs : 0.013464 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:20:19] 0.035801 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:20:34] Energy consumed for RAM : 0.001524 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:20:34] Energy consumed for all GPUs : 0.021107 kWh. Total GPU Power : 65.88463461217522 W\n",
            "[codecarbon INFO @ 22:20:34] Energy consumed for all CPUs : 0.013641 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:20:34] 0.036272 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:20:49] Energy consumed for RAM : 0.001544 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:20:49] Energy consumed for all GPUs : 0.021383 kWh. Total GPU Power : 66.19523557220926 W\n",
            "[codecarbon INFO @ 22:20:49] Energy consumed for all CPUs : 0.013819 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:20:49] 0.036746 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:21:04] Energy consumed for RAM : 0.001564 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:21:04] Energy consumed for all GPUs : 0.021657 kWh. Total GPU Power : 66.02517952893868 W\n",
            "[codecarbon INFO @ 22:21:04] Energy consumed for all CPUs : 0.013996 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:21:04] 0.037217 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/30], Loss: 2.0454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:21:19] Energy consumed for RAM : 0.001584 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:21:19] Energy consumed for all GPUs : 0.021926 kWh. Total GPU Power : 64.61341310437305 W\n",
            "[codecarbon INFO @ 22:21:19] Energy consumed for all CPUs : 0.014173 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:21:19] 0.037683 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:21:19] 0.008398 g.CO2eq/s mean an estimation of 264.8497054323926 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:21:34] Energy consumed for RAM : 0.001603 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:21:34] Energy consumed for all GPUs : 0.022201 kWh. Total GPU Power : 66.11876414439838 W\n",
            "[codecarbon INFO @ 22:21:34] Energy consumed for all CPUs : 0.014350 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:21:34] 0.038154 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:21:49] Energy consumed for RAM : 0.001623 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:21:49] Energy consumed for all GPUs : 0.022477 kWh. Total GPU Power : 66.36931372187307 W\n",
            "[codecarbon INFO @ 22:21:49] Energy consumed for all CPUs : 0.014527 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:21:49] 0.038627 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:22:04] Energy consumed for RAM : 0.001643 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:22:04] Energy consumed for all GPUs : 0.022753 kWh. Total GPU Power : 66.0232987538533 W\n",
            "[codecarbon INFO @ 22:22:04] Energy consumed for all CPUs : 0.014704 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:22:04] 0.039100 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:22:19] Energy consumed for RAM : 0.001663 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:22:19] Energy consumed for all GPUs : 0.023028 kWh. Total GPU Power : 66.12226987931528 W\n",
            "[codecarbon INFO @ 22:22:19] Energy consumed for all CPUs : 0.014881 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:22:19] 0.039572 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/30], Loss: 2.1075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:22:34] Energy consumed for RAM : 0.001682 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:22:34] Energy consumed for all GPUs : 0.023302 kWh. Total GPU Power : 65.63640987697372 W\n",
            "[codecarbon INFO @ 22:22:34] Energy consumed for all CPUs : 0.015059 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:22:34] 0.040043 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:22:49] Energy consumed for RAM : 0.001702 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:22:49] Energy consumed for all GPUs : 0.023578 kWh. Total GPU Power : 66.23593365720967 W\n",
            "[codecarbon INFO @ 22:22:49] Energy consumed for all CPUs : 0.015236 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:22:49] 0.040516 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:23:04] Energy consumed for RAM : 0.001722 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:23:04] Energy consumed for all GPUs : 0.023855 kWh. Total GPU Power : 66.41005426961507 W\n",
            "[codecarbon INFO @ 22:23:04] Energy consumed for all CPUs : 0.015413 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:23:04] 0.040990 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:23:19] Energy consumed for RAM : 0.001742 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:23:19] Energy consumed for all GPUs : 0.024130 kWh. Total GPU Power : 66.18357168019024 W\n",
            "[codecarbon INFO @ 22:23:19] Energy consumed for all CPUs : 0.015590 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:23:19] 0.041462 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:23:19] 0.008423 g.CO2eq/s mean an estimation of 265.64223859231913 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:23:34] Energy consumed for RAM : 0.001762 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:23:34] Energy consumed for all GPUs : 0.024406 kWh. Total GPU Power : 66.18588758607167 W\n",
            "[codecarbon INFO @ 22:23:34] Energy consumed for all CPUs : 0.015767 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:23:34] 0.041935 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/30], Loss: 2.1231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:23:49] Energy consumed for RAM : 0.001781 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:23:49] Energy consumed for all GPUs : 0.024678 kWh. Total GPU Power : 65.3970290941926 W\n",
            "[codecarbon INFO @ 22:23:49] Energy consumed for all CPUs : 0.015944 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:23:49] 0.042404 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:24:04] Energy consumed for RAM : 0.001801 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:24:04] Energy consumed for all GPUs : 0.024953 kWh. Total GPU Power : 66.06905273359006 W\n",
            "[codecarbon INFO @ 22:24:04] Energy consumed for all CPUs : 0.016121 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:24:04] 0.042876 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:24:19] Energy consumed for RAM : 0.001821 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:24:19] Energy consumed for all GPUs : 0.025228 kWh. Total GPU Power : 65.91843750879804 W\n",
            "[codecarbon INFO @ 22:24:19] Energy consumed for all CPUs : 0.016299 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:24:19] 0.043347 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:24:34] Energy consumed for RAM : 0.001841 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:24:34] Energy consumed for all GPUs : 0.025504 kWh. Total GPU Power : 66.18772184516165 W\n",
            "[codecarbon INFO @ 22:24:34] Energy consumed for all CPUs : 0.016476 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:24:34] 0.043820 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:24:49] Energy consumed for RAM : 0.001861 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:24:49] Energy consumed for all GPUs : 0.025779 kWh. Total GPU Power : 66.0731996299989 W\n",
            "[codecarbon INFO @ 22:24:49] Energy consumed for all CPUs : 0.016653 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:24:49] 0.044293 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/30], Loss: 2.1308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:25:04] Energy consumed for RAM : 0.001880 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:25:04] Energy consumed for all GPUs : 0.026051 kWh. Total GPU Power : 65.32376614694974 W\n",
            "[codecarbon INFO @ 22:25:04] Energy consumed for all CPUs : 0.016830 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:25:04] 0.044761 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:25:19] Energy consumed for RAM : 0.001900 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:25:19] Energy consumed for all GPUs : 0.026324 kWh. Total GPU Power : 65.70890928551646 W\n",
            "[codecarbon INFO @ 22:25:19] Energy consumed for all CPUs : 0.017007 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:25:19] 0.045232 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:25:19] 0.008401 g.CO2eq/s mean an estimation of 264.9248244517525 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:25:34] Energy consumed for RAM : 0.001920 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:25:34] Energy consumed for all GPUs : 0.026598 kWh. Total GPU Power : 65.78889222094145 W\n",
            "[codecarbon INFO @ 22:25:34] Energy consumed for all CPUs : 0.017184 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:25:34] 0.045702 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:25:49] Energy consumed for RAM : 0.001940 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:25:49] Energy consumed for all GPUs : 0.026872 kWh. Total GPU Power : 65.75905212922665 W\n",
            "[codecarbon INFO @ 22:25:49] Energy consumed for all CPUs : 0.017361 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:25:49] 0.046173 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:26:04] Energy consumed for RAM : 0.001960 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:26:04] Energy consumed for all GPUs : 0.027147 kWh. Total GPU Power : 65.82599254292812 W\n",
            "[codecarbon INFO @ 22:26:04] Energy consumed for all CPUs : 0.017539 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:26:04] 0.046645 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/30], Loss: 2.1104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:26:19] Energy consumed for RAM : 0.001979 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:26:19] Energy consumed for all GPUs : 0.027417 kWh. Total GPU Power : 64.84315156692406 W\n",
            "[codecarbon INFO @ 22:26:19] Energy consumed for all CPUs : 0.017716 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:26:19] 0.047112 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:26:34] Energy consumed for RAM : 0.001999 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:26:34] Energy consumed for all GPUs : 0.027694 kWh. Total GPU Power : 66.52870341869884 W\n",
            "[codecarbon INFO @ 22:26:34] Energy consumed for all CPUs : 0.017893 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:26:34] 0.047587 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:26:49] Energy consumed for RAM : 0.002019 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:26:49] Energy consumed for all GPUs : 0.027969 kWh. Total GPU Power : 65.94990394420124 W\n",
            "[codecarbon INFO @ 22:26:49] Energy consumed for all CPUs : 0.018070 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:26:49] 0.048058 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:27:04] Energy consumed for RAM : 0.002039 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:27:04] Energy consumed for all GPUs : 0.028245 kWh. Total GPU Power : 66.27003504027067 W\n",
            "[codecarbon INFO @ 22:27:04] Energy consumed for all CPUs : 0.018247 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:27:04] 0.048531 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:27:19] Energy consumed for RAM : 0.002059 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:27:19] Energy consumed for all GPUs : 0.028519 kWh. Total GPU Power : 65.86211745832976 W\n",
            "[codecarbon INFO @ 22:27:19] Energy consumed for all CPUs : 0.018424 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:27:19] 0.049002 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:27:19] 0.008403 g.CO2eq/s mean an estimation of 264.9977650994741 kg.CO2eq/year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/30], Loss: 2.0440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:27:34] Energy consumed for RAM : 0.002078 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:27:34] Energy consumed for all GPUs : 0.028793 kWh. Total GPU Power : 65.65806266955735 W\n",
            "[codecarbon INFO @ 22:27:34] Energy consumed for all CPUs : 0.018602 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:27:34] 0.049473 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:27:49] Energy consumed for RAM : 0.002098 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:27:49] Energy consumed for all GPUs : 0.029067 kWh. Total GPU Power : 65.88248700734493 W\n",
            "[codecarbon INFO @ 22:27:49] Energy consumed for all CPUs : 0.018779 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:27:49] 0.049944 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:28:04] Energy consumed for RAM : 0.002118 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:28:04] Energy consumed for all GPUs : 0.029343 kWh. Total GPU Power : 66.20719788562764 W\n",
            "[codecarbon INFO @ 22:28:04] Energy consumed for all CPUs : 0.018956 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:28:04] 0.050417 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:28:19] Energy consumed for RAM : 0.002138 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:28:19] Energy consumed for all GPUs : 0.029619 kWh. Total GPU Power : 66.37007748508576 W\n",
            "[codecarbon INFO @ 22:28:19] Energy consumed for all CPUs : 0.019133 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:28:19] 0.050890 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:28:34] Energy consumed for RAM : 0.002157 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:28:34] Energy consumed for all GPUs : 0.029894 kWh. Total GPU Power : 65.99406750290967 W\n",
            "[codecarbon INFO @ 22:28:34] Energy consumed for all CPUs : 0.019310 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:28:34] 0.051362 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/30], Loss: 1.9466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:28:49] Energy consumed for RAM : 0.002177 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:28:49] Energy consumed for all GPUs : 0.030164 kWh. Total GPU Power : 64.90378690922164 W\n",
            "[codecarbon INFO @ 22:28:49] Energy consumed for all CPUs : 0.019487 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:28:49] 0.051829 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:29:04] Energy consumed for RAM : 0.002197 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:29:04] Energy consumed for all GPUs : 0.030439 kWh. Total GPU Power : 65.97776070651881 W\n",
            "[codecarbon INFO @ 22:29:04] Energy consumed for all CPUs : 0.019664 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:29:04] 0.052300 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:29:19] Energy consumed for RAM : 0.002217 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:29:19] Energy consumed for all GPUs : 0.030714 kWh. Total GPU Power : 65.95387188851193 W\n",
            "[codecarbon INFO @ 22:29:19] Energy consumed for all CPUs : 0.019841 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:29:19] 0.052772 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:29:19] 0.008403 g.CO2eq/s mean an estimation of 265.0085503949729 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:29:34] Energy consumed for RAM : 0.002237 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:29:34] Energy consumed for all GPUs : 0.030988 kWh. Total GPU Power : 65.90316990403824 W\n",
            "[codecarbon INFO @ 22:29:34] Energy consumed for all CPUs : 0.020019 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:29:34] 0.053244 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:29:49] Energy consumed for RAM : 0.002256 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:29:49] Energy consumed for all GPUs : 0.031262 kWh. Total GPU Power : 65.59057905497205 W\n",
            "[codecarbon INFO @ 22:29:49] Energy consumed for all CPUs : 0.020196 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:29:49] 0.053714 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/30], Loss: 1.8406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:30:04] Energy consumed for RAM : 0.002276 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:30:04] Energy consumed for all GPUs : 0.031533 kWh. Total GPU Power : 65.18657912518951 W\n",
            "[codecarbon INFO @ 22:30:04] Energy consumed for all CPUs : 0.020373 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:30:04] 0.054182 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:30:19] Energy consumed for RAM : 0.002296 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:30:19] Energy consumed for all GPUs : 0.031807 kWh. Total GPU Power : 65.92628503866827 W\n",
            "[codecarbon INFO @ 22:30:19] Energy consumed for all CPUs : 0.020550 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:30:19] 0.054653 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:30:34] Energy consumed for RAM : 0.002316 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:30:34] Energy consumed for all GPUs : 0.032082 kWh. Total GPU Power : 65.94157742534037 W\n",
            "[codecarbon INFO @ 22:30:34] Energy consumed for all CPUs : 0.020727 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:30:34] 0.055125 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:30:49] Energy consumed for RAM : 0.002336 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:30:49] Energy consumed for all GPUs : 0.032357 kWh. Total GPU Power : 65.97174832422004 W\n",
            "[codecarbon INFO @ 22:30:49] Energy consumed for all CPUs : 0.020904 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:30:49] 0.055596 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:31:04] Energy consumed for RAM : 0.002355 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:31:04] Energy consumed for all GPUs : 0.032631 kWh. Total GPU Power : 65.6696739096289 W\n",
            "[codecarbon INFO @ 22:31:04] Energy consumed for all CPUs : 0.021081 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:31:04] 0.056067 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/30], Loss: 1.7073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:31:19] Energy consumed for RAM : 0.002375 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:31:19] Energy consumed for all GPUs : 0.032902 kWh. Total GPU Power : 65.01340736256054 W\n",
            "[codecarbon INFO @ 22:31:19] Energy consumed for all CPUs : 0.021259 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:31:19] 0.056535 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:31:19] 0.008386 g.CO2eq/s mean an estimation of 264.4473599914614 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:31:34] Energy consumed for RAM : 0.002395 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:31:34] Energy consumed for all GPUs : 0.033175 kWh. Total GPU Power : 65.75091128418617 W\n",
            "[codecarbon INFO @ 22:31:34] Energy consumed for all CPUs : 0.021436 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:31:34] 0.057005 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:31:49] Energy consumed for RAM : 0.002415 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:31:49] Energy consumed for all GPUs : 0.033449 kWh. Total GPU Power : 65.85569297371177 W\n",
            "[codecarbon INFO @ 22:31:49] Energy consumed for all CPUs : 0.021613 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:31:49] 0.057476 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:32:04] Energy consumed for RAM : 0.002434 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:32:04] Energy consumed for all GPUs : 0.033722 kWh. Total GPU Power : 65.56651819197283 W\n",
            "[codecarbon INFO @ 22:32:04] Energy consumed for all CPUs : 0.021789 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:32:04] 0.057945 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:32:19] Energy consumed for RAM : 0.002454 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:32:19] Energy consumed for all GPUs : 0.033995 kWh. Total GPU Power : 65.71462375316905 W\n",
            "[codecarbon INFO @ 22:32:19] Energy consumed for all CPUs : 0.021967 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:32:19] 0.058416 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/30], Loss: 1.5541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:32:34] Energy consumed for RAM : 0.002474 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:32:34] Energy consumed for all GPUs : 0.034269 kWh. Total GPU Power : 65.6043224900126 W\n",
            "[codecarbon INFO @ 22:32:34] Energy consumed for all CPUs : 0.022144 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:32:34] 0.058886 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:32:49] Energy consumed for RAM : 0.002494 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:32:49] Energy consumed for all GPUs : 0.034542 kWh. Total GPU Power : 65.57774639563019 W\n",
            "[codecarbon INFO @ 22:32:49] Energy consumed for all CPUs : 0.022321 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:32:49] 0.059356 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:33:04] Energy consumed for RAM : 0.002514 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:33:04] Energy consumed for all GPUs : 0.034816 kWh. Total GPU Power : 65.86946515404716 W\n",
            "[codecarbon INFO @ 22:33:04] Energy consumed for all CPUs : 0.022498 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:33:04] 0.059828 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:33:19] Energy consumed for RAM : 0.002533 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:33:19] Energy consumed for all GPUs : 0.035090 kWh. Total GPU Power : 65.66031930683063 W\n",
            "[codecarbon INFO @ 22:33:19] Energy consumed for all CPUs : 0.022675 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:33:19] 0.060298 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:33:19] 0.008388 g.CO2eq/s mean an estimation of 264.5295587054896 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:33:34] Energy consumed for RAM : 0.002553 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:33:34] Energy consumed for all GPUs : 0.035366 kWh. Total GPU Power : 66.3068108614062 W\n",
            "[codecarbon INFO @ 22:33:34] Energy consumed for all CPUs : 0.022852 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:33:34] 0.060771 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/30], Loss: 1.4169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:33:49] Energy consumed for RAM : 0.002573 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:33:49] Energy consumed for all GPUs : 0.035636 kWh. Total GPU Power : 64.94617572486386 W\n",
            "[codecarbon INFO @ 22:33:49] Energy consumed for all CPUs : 0.023029 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:33:49] 0.061239 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:34:04] Energy consumed for RAM : 0.002593 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:34:04] Energy consumed for all GPUs : 0.035909 kWh. Total GPU Power : 65.51466002623758 W\n",
            "[codecarbon INFO @ 22:34:04] Energy consumed for all CPUs : 0.023206 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:34:04] 0.061708 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:34:19] Energy consumed for RAM : 0.002613 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:34:19] Energy consumed for all GPUs : 0.036184 kWh. Total GPU Power : 66.10687944991324 W\n",
            "[codecarbon INFO @ 22:34:19] Energy consumed for all CPUs : 0.023383 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:34:19] 0.062180 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:34:34] Energy consumed for RAM : 0.002632 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:34:34] Energy consumed for all GPUs : 0.036459 kWh. Total GPU Power : 66.01381449986395 W\n",
            "[codecarbon INFO @ 22:34:34] Energy consumed for all CPUs : 0.023560 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:34:34] 0.062651 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:34:49] Energy consumed for RAM : 0.002652 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:34:49] Energy consumed for all GPUs : 0.036734 kWh. Total GPU Power : 66.2122444751719 W\n",
            "[codecarbon INFO @ 22:34:49] Energy consumed for all CPUs : 0.023737 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:34:49] 0.063124 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/30], Loss: 1.2752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:35:04] Energy consumed for RAM : 0.002672 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:35:04] Energy consumed for all GPUs : 0.037005 kWh. Total GPU Power : 64.9815966882948 W\n",
            "[codecarbon INFO @ 22:35:04] Energy consumed for all CPUs : 0.023915 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:35:04] 0.063592 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:35:19] Energy consumed for RAM : 0.002692 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:35:19] Energy consumed for all GPUs : 0.037280 kWh. Total GPU Power : 65.99728775497528 W\n",
            "[codecarbon INFO @ 22:35:19] Energy consumed for all CPUs : 0.024092 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:35:19] 0.064064 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:35:19] 0.008393 g.CO2eq/s mean an estimation of 264.6881012825315 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:35:34] Energy consumed for RAM : 0.002711 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:35:34] Energy consumed for all GPUs : 0.037554 kWh. Total GPU Power : 65.9403427878884 W\n",
            "[codecarbon INFO @ 22:35:34] Energy consumed for all CPUs : 0.024269 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:35:34] 0.064535 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:35:49] Energy consumed for RAM : 0.002731 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:35:49] Energy consumed for all GPUs : 0.037829 kWh. Total GPU Power : 65.87997818237974 W\n",
            "[codecarbon INFO @ 22:35:49] Energy consumed for all CPUs : 0.024446 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:35:49] 0.065006 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:36:04] Energy consumed for RAM : 0.002751 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:36:04] Energy consumed for all GPUs : 0.038104 kWh. Total GPU Power : 65.95777079743236 W\n",
            "[codecarbon INFO @ 22:36:04] Energy consumed for all CPUs : 0.024623 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:36:04] 0.065478 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30], Loss: 1.1598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:36:19] Energy consumed for RAM : 0.002771 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:36:19] Energy consumed for all GPUs : 0.038375 kWh. Total GPU Power : 65.22346268957816 W\n",
            "[codecarbon INFO @ 22:36:19] Energy consumed for all CPUs : 0.024800 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:36:19] 0.065946 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:36:34] Energy consumed for RAM : 0.002791 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:36:34] Energy consumed for all GPUs : 0.038649 kWh. Total GPU Power : 65.6481049252694 W\n",
            "[codecarbon INFO @ 22:36:34] Energy consumed for all CPUs : 0.024977 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:36:34] 0.066416 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:36:49] Energy consumed for RAM : 0.002810 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:36:49] Energy consumed for all GPUs : 0.038923 kWh. Total GPU Power : 65.77225416676063 W\n",
            "[codecarbon INFO @ 22:36:49] Energy consumed for all CPUs : 0.025154 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:36:49] 0.066887 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:37:04] Energy consumed for RAM : 0.002830 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:37:04] Energy consumed for all GPUs : 0.039197 kWh. Total GPU Power : 65.88242171783223 W\n",
            "[codecarbon INFO @ 22:37:04] Energy consumed for all CPUs : 0.025331 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:37:04] 0.067358 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30], Loss: 1.0893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[codecarbon INFO @ 22:37:19] Energy consumed for RAM : 0.002850 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:37:19] Energy consumed for all GPUs : 0.039469 kWh. Total GPU Power : 65.37872001713211 W\n",
            "[codecarbon INFO @ 22:37:19] Energy consumed for all CPUs : 0.025508 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:37:19] 0.067828 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:37:19] 0.008392 g.CO2eq/s mean an estimation of 264.6383061892909 kg.CO2eq/year\n",
            "[codecarbon INFO @ 22:37:34] Energy consumed for RAM : 0.002870 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:37:34] Energy consumed for all GPUs : 0.039739 kWh. Total GPU Power : 64.86912935872267 W\n",
            "[codecarbon INFO @ 22:37:34] Energy consumed for all CPUs : 0.025685 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:37:34] 0.068294 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:37:49] Energy consumed for RAM : 0.002890 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:37:49] Energy consumed for all GPUs : 0.040013 kWh. Total GPU Power : 65.73733144477798 W\n",
            "[codecarbon INFO @ 22:37:49] Energy consumed for all CPUs : 0.025863 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:37:49] 0.068765 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:38:04] Energy consumed for RAM : 0.002909 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:38:04] Energy consumed for all GPUs : 0.040287 kWh. Total GPU Power : 65.71145032657306 W\n",
            "[codecarbon INFO @ 22:38:04] Energy consumed for all CPUs : 0.026040 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:38:04] 0.069236 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:38:19] Energy consumed for RAM : 0.002929 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:38:19] Energy consumed for all GPUs : 0.040562 kWh. Total GPU Power : 65.8759463079077 W\n",
            "[codecarbon INFO @ 22:38:19] Energy consumed for all CPUs : 0.026217 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:38:19] 0.069708 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 22:38:34] Energy consumed for RAM : 0.002948 kWh. RAM Power : 4.753036022186279 W\n",
            "[codecarbon INFO @ 22:38:34] Energy consumed for all GPUs : 0.040831 kWh. Total GPU Power : 66.14259013603159 W\n",
            "[codecarbon INFO @ 22:38:34] Energy consumed for all CPUs : 0.026390 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 22:38:34] 0.070169 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30], Loss: 1.0495\n",
            "\n",
            "--- Model Analysis ---\n",
            "Parameter Count: 128807306\n",
            "Model Size: 491.37 MB\n",
            "FLOPs: 0.27 GFLOPs\n",
            "Training Time: 2236.22 seconds\n",
            "Average Inference Time: 3.491727 ms\n",
            "\n",
            "--- Energy and Emissions Report ---\n",
            "CO2 Emissions (CodeCarbon): 0.018779 kg\n",
            "Average GPU Power Consumption: 68.28 W\n",
            "Total GPU Energy Consumption: 42.410667 kWh\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torchvision import models, datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from thop import profile\n",
        "from codecarbon import EmissionsTracker\n",
        "import time\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the transforms for the dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "full_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Split the full training dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders for the train, validation, and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Define the teacher model (VGG16) and load pre-trained weights\n",
        "teacher_model = models.vgg16(pretrained=False)\n",
        "teacher_last_layer = teacher_model.classifier[6].in_features\n",
        "teacher_model.classifier[6] = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(teacher_last_layer, 10)\n",
        ")\n",
        "teacher_model.load_state_dict(torch.load(\"trained_vgg16_model.pth\"))  # Load the downloaded teacher model\n",
        "teacher_model = teacher_model.to(device)\n",
        "teacher_model.eval()  # Set the teacher model to evaluation mode\n",
        "\n",
        "# Define the student model (VGG11)\n",
        "student_model = models.vgg11(pretrained=False)\n",
        "student_last_layer = student_model.classifier[6].in_features\n",
        "student_model.classifier[6] = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(student_last_layer, 10)\n",
        ")\n",
        "student_model = student_model.to(device)\n",
        "\n",
        "# Define the distillation loss\n",
        "class DistillationLoss(nn.Module):\n",
        "    def __init__(self, temperature=3.0, alpha=0.5):\n",
        "        super(DistillationLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.alpha = alpha\n",
        "        self.criterion_ce = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        distillation_loss = nn.KLDivLoss(reduction='batchmean')(\n",
        "            torch.log_softmax(student_logits / self.temperature, dim=1),\n",
        "            torch.softmax(teacher_logits / self.temperature, dim=1)\n",
        "        ) * (self.temperature ** 2)\n",
        "        student_loss = self.criterion_ce(student_logits, labels)\n",
        "        return self.alpha * distillation_loss + (1 - self.alpha) * student_loss\n",
        "\n",
        "criterion = DistillationLoss(temperature=3.0, alpha=0.5)\n",
        "\n",
        "# Define optimizer and scheduler\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# GPU power tracking\n",
        "def get_gpu_power():\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,nounits,noheader'],\n",
        "            stdout=subprocess.PIPE, text=True\n",
        "        )\n",
        "        power_draws = [float(p) for p in result.stdout.strip().split('\\n')]\n",
        "        return sum(power_draws) / len(power_draws) if power_draws else 0.0\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting GPU power: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# Energy tracking\n",
        "tracker = EmissionsTracker()\n",
        "tracker.start()\n",
        "\n",
        "# Training loop\n",
        "epochs = 30\n",
        "gpu_power_readings = []\n",
        "start_training_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    student_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Teacher predictions\n",
        "        with torch.no_grad():\n",
        "            teacher_logits = teacher_model(inputs)\n",
        "\n",
        "        # Student predictions and loss computation\n",
        "        student_logits = student_model(inputs)\n",
        "        loss = criterion(student_logits, teacher_logits, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        gpu_power_readings.append(get_gpu_power())\n",
        "\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "end_training_time = time.time()\n",
        "training_time = end_training_time - start_training_time\n",
        "\n",
        "emissions = tracker.stop()\n",
        "\n",
        "# Energy metrics\n",
        "avg_gpu_power = sum(gpu_power_readings) / len(gpu_power_readings) if gpu_power_readings else 0.0\n",
        "total_energy_consumption = (avg_gpu_power * training_time) / 3600  # kWh\n",
        "\n",
        "# Model analysis\n",
        "param_count = sum(p.numel() for p in student_model.parameters() if p.requires_grad)\n",
        "torch.save(student_model.state_dict(), \"student_model_vgg11_temp.pth\")\n",
        "model_size_mb = os.path.getsize(\"student_model_vgg11_temp.pth\") / (1024 * 1024)\n",
        "\n",
        "# FLOPs and inference time\n",
        "example_input = torch.randn(1, 3, 32, 32).to(device)\n",
        "flops, _ = profile(student_model, inputs=(example_input,), verbose=False)\n",
        "\n",
        "student_model.eval()\n",
        "with torch.no_grad():\n",
        "    start_time = torch.cuda.Event(enable_timing=True)\n",
        "    end_time = torch.cuda.Event(enable_timing=True)\n",
        "    start_time.record()\n",
        "    for _ in range(100):\n",
        "        _ = student_model(example_input)\n",
        "    end_time.record()\n",
        "    torch.cuda.synchronize()\n",
        "inference_time_ms = start_time.elapsed_time(end_time) / 100  # Average in milliseconds\n",
        "\n",
        "# Output results\n",
        "print(\"\\n--- Model Analysis ---\")\n",
        "print(f\"Parameter Count: {param_count}\")\n",
        "print(f\"Model Size: {model_size_mb:.2f} MB\")\n",
        "print(f\"FLOPs: {flops / 1e9:.2f} GFLOPs\")\n",
        "print(f\"Training Time: {training_time:.2f} seconds\")\n",
        "print(f\"Average Inference Time: {inference_time_ms:.6f} ms\")\n",
        "\n",
        "print(\"\\n--- Energy and Emissions Report ---\")\n",
        "print(f\"CO2 Emissions (CodeCarbon): {emissions:.6f} kg\")\n",
        "print(f\"Average GPU Power Consumption: {avg_gpu_power:.2f} W\")\n",
        "print(f\"Total GPU Energy Consumption: {total_energy_consumption:.6f} kWh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wp5KQXhLliVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af69e90-6511-4261-f36f-a87f88a0e04b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Model Test Accuracy: 83.18%\n"
          ]
        }
      ],
      "source": [
        "student_model.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = student_model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct_test / total_test\n",
        "print(f\"Student Model Test Accuracy: {test_accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}